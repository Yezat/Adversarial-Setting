{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from gradient_descent import sklearn_optimize\n",
    "from data import sample_weights\n",
    "import numpy as np\n",
    "# Let's see how well we do on the test set\n",
    "from theoretical import predict_erm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from data_model import CustomSpectra\n",
    "import pickle\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read the pickle file\n",
    "with open('data/fashion_mnist.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    X_train = np.array(data['X_train'])\n",
    "    y_train = np.array(data['y_train'])\n",
    "    X_test = np.array(data['X_test'])\n",
    "    y_test = np.array(data['y_test'])\n",
    "    # replace the -1 labels with 0\n",
    "    y_train[y_train == -1] = 0\n",
    "    y_test[y_test == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        # Input layer with 784 neurons\n",
    "        self.input_layer = nn.Linear(784, 1000, bias=False)\n",
    "        \n",
    "        # Three hidden layers with 1000 neurons and ReLU activation\n",
    "        # self.hidden1 = nn.Linear(1000, 1000)\n",
    "        self.hidden3 = nn.Linear(1000, 784, bias=False)\n",
    "        \n",
    "        # Output layer with 2 neurons and logistic (sigmoid) activation\n",
    "        self.output_layer = nn.Linear(784, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # self.sign = nn.Softsign()\n",
    "    \n",
    "    def almost_forward(self, x):\n",
    "        # Forward pass with ReLU activation for hidden layers\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        # x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden3(x))\n",
    "        \n",
    "        # Output layer with sigmoid activation\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.almost_forward(x)\n",
    "        x = self.output_layer(x) \n",
    "        # x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create an instance of the neural network\n",
    "net = MyNeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.FloatTensor(np.array(self.data[idx]))\n",
    "        label = torch.IntTensor(np.array([self.labels[idx]]))\n",
    "        return data, label\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "# Create custom data loaders\n",
    "batch_size = 64  # You can adjust this batch size according to your needs\n",
    "test_batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40] - Train Loss: 0.2832, Test Loss: 0.2554, Test Accuracy: 0.5000\n",
      "Epoch [2/40] - Train Loss: 0.2558, Test Loss: 0.2513, Test Accuracy: 0.5000\n",
      "Epoch [3/40] - Train Loss: 0.2532, Test Loss: 0.2524, Test Accuracy: 0.5000\n",
      "Epoch [4/40] - Train Loss: 0.2532, Test Loss: 0.2524, Test Accuracy: 0.5000\n",
      "Epoch [5/40] - Train Loss: 0.2536, Test Loss: 0.2580, Test Accuracy: 0.5000\n",
      "Epoch [6/40] - Train Loss: 0.2540, Test Loss: 0.2533, Test Accuracy: 0.5000\n",
      "Epoch [7/40] - Train Loss: 0.2537, Test Loss: 0.2514, Test Accuracy: 0.5000\n",
      "Epoch [8/40] - Train Loss: 0.2528, Test Loss: 0.2518, Test Accuracy: 0.5000\n",
      "Epoch [9/40] - Train Loss: 0.2533, Test Loss: 0.2516, Test Accuracy: 0.5000\n",
      "Epoch [10/40] - Train Loss: 0.2532, Test Loss: 0.2593, Test Accuracy: 0.5000\n",
      "Epoch [11/40] - Train Loss: 0.2540, Test Loss: 0.2523, Test Accuracy: 0.5000\n",
      "Epoch [12/40] - Train Loss: 0.2538, Test Loss: 0.2548, Test Accuracy: 0.5000\n",
      "Epoch [13/40] - Train Loss: 0.2565, Test Loss: 0.2509, Test Accuracy: 0.5000\n",
      "Epoch [14/40] - Train Loss: 0.2522, Test Loss: 0.2510, Test Accuracy: 0.5000\n",
      "Epoch [15/40] - Train Loss: 0.2530, Test Loss: 0.2550, Test Accuracy: 0.5000\n",
      "Epoch [16/40] - Train Loss: 0.2535, Test Loss: 0.2509, Test Accuracy: 0.5000\n",
      "Epoch [17/40] - Train Loss: 0.2519, Test Loss: 0.2506, Test Accuracy: 0.5000\n",
      "Epoch [18/40] - Train Loss: 0.2512, Test Loss: 0.2506, Test Accuracy: 0.5000\n",
      "Epoch [19/40] - Train Loss: 0.2525, Test Loss: 0.2507, Test Accuracy: 0.5000\n",
      "Epoch [20/40] - Train Loss: 0.2526, Test Loss: 0.2518, Test Accuracy: 0.5000\n",
      "Epoch [21/40] - Train Loss: 0.2520, Test Loss: 0.2519, Test Accuracy: 0.5000\n",
      "Epoch [22/40] - Train Loss: 0.2518, Test Loss: 0.2515, Test Accuracy: 0.5000\n",
      "Epoch [23/40] - Train Loss: 0.2528, Test Loss: 0.2508, Test Accuracy: 0.5000\n",
      "Epoch [24/40] - Train Loss: 0.2525, Test Loss: 0.2513, Test Accuracy: 0.5000\n",
      "Epoch [25/40] - Train Loss: 0.2527, Test Loss: 0.2507, Test Accuracy: 0.5000\n",
      "Epoch [26/40] - Train Loss: 0.2519, Test Loss: 0.2544, Test Accuracy: 0.5000\n",
      "Epoch [27/40] - Train Loss: 0.2515, Test Loss: 0.2527, Test Accuracy: 0.5000\n",
      "Epoch [28/40] - Train Loss: 0.2520, Test Loss: 0.2511, Test Accuracy: 0.5000\n",
      "Epoch [29/40] - Train Loss: 0.2515, Test Loss: 0.2506, Test Accuracy: 0.5000\n",
      "Epoch [30/40] - Train Loss: 0.2518, Test Loss: 0.2530, Test Accuracy: 0.5000\n",
      "Epoch [31/40] - Train Loss: 0.2524, Test Loss: 0.2512, Test Accuracy: 0.5000\n",
      "Epoch [32/40] - Train Loss: 0.2525, Test Loss: 0.2535, Test Accuracy: 0.5000\n",
      "Epoch [33/40] - Train Loss: 0.2517, Test Loss: 0.2527, Test Accuracy: 0.5000\n",
      "Epoch [34/40] - Train Loss: 0.2516, Test Loss: 0.2525, Test Accuracy: 0.5000\n",
      "Epoch [35/40] - Train Loss: 0.2518, Test Loss: 0.2508, Test Accuracy: 0.5000\n",
      "Epoch [36/40] - Train Loss: 0.2521, Test Loss: 0.2509, Test Accuracy: 0.5000\n",
      "Epoch [37/40] - Train Loss: 0.2518, Test Loss: 0.2520, Test Accuracy: 0.5000\n",
      "Epoch [38/40] - Train Loss: 0.2518, Test Loss: 0.2515, Test Accuracy: 0.5000\n",
      "Epoch [39/40] - Train Loss: 0.2519, Test Loss: 0.2514, Test Accuracy: 0.5000\n",
      "Epoch [40/40] - Train Loss: 0.2516, Test Loss: 0.2513, Test Accuracy: 0.5000\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define your neural network class (as previously defined)\n",
    "\n",
    "# Define a function to train the network\n",
    "def train(net, train_loader, test_loader, num_epochs=10, learning_rate=0.001):\n",
    "    net.to(device)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.BCELoss()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Lists to store training and test losses\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            # Reshape the labels to (batch_size)\n",
    "            labels = labels.reshape(-1)\n",
    "\n",
    "            # change the datatype to float64 for the labels\n",
    "            labels = labels.type(torch.float32)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # print the gradient values of inputs and labels\n",
    "            # print(\"input grad\",inputs.grad)\n",
    "            # print(\"label grad\", labels.grad)\n",
    "\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # print the gradient values of outputs\n",
    "            # print(\"outptu grad\", outputs.grad)\n",
    "\n",
    "            # print the output\n",
    "            # print(\"outputs\", outputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # print the gradient values of loss\n",
    "            # print(\"loss grad\",loss.grad)\n",
    "            # print(\"loss\", loss)\n",
    "            \n",
    "            # Backpropagation and optimization\n",
    "            loss.backward()\n",
    "\n",
    "            # print(\"loss grad\",loss.grad)\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate training loss for this epoch\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Testing phase\n",
    "        net.eval()\n",
    "        test_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for inputs, labels in test_loader:\n",
    "                \n",
    "                # inputs = inputs.reshape(-1)\n",
    "                # print(\"input shape\", inputs.shape)\n",
    "                # print(\"label shape\", labels.shape)\n",
    "\n",
    "                # Reshape the labels to (batch_size)\n",
    "                labels = labels.reshape(-1)\n",
    "\n",
    "                # change the datatype to float32 for the labels\n",
    "                labels = labels.type(torch.float32)\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                # count the number of correct predictions\n",
    "                correct += (predicted == labels).sum().item()     \n",
    "\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "            accuracy = correct / total\n",
    "        \n",
    "        # Calculate test loss for this epoch\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # Print training and test loss for this epoch\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    print('Training complete')\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "# Create an instance of your neural network\n",
    "net = MyNeuralNetwork()\n",
    "\n",
    "# Train the network and log the losses\n",
    "train_losses, test_losses = train(net, train_loader, test_loader, num_epochs=40, learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tensor(0.5878)\n",
      "min tensor(0.4666)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1])\n",
      "total 64\n",
      "correct 34\n",
      "max tensor(0.5652)\n",
      "min tensor(0.4638)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0])\n",
      "total 128\n",
      "correct 69\n",
      "max tensor(0.5608)\n",
      "min tensor(0.4948)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "total 192\n",
      "correct 102\n",
      "max tensor(0.5992)\n",
      "min tensor(0.4858)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0])\n",
      "total 256\n",
      "correct 135\n",
      "max tensor(0.6103)\n",
      "min tensor(0.3306)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0])\n",
      "total 320\n",
      "correct 163\n",
      "max tensor(0.6203)\n",
      "min tensor(0.4752)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1])\n",
      "total 384\n",
      "correct 191\n",
      "max tensor(0.5507)\n",
      "min tensor(0.4888)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0])\n",
      "total 448\n",
      "correct 217\n",
      "max tensor(0.6104)\n",
      "min tensor(0.4668)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0])\n",
      "total 512\n",
      "correct 258\n",
      "max tensor(0.6006)\n",
      "min tensor(0.4507)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0])\n",
      "total 576\n",
      "correct 292\n",
      "max tensor(0.5942)\n",
      "min tensor(0.5031)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0])\n",
      "total 640\n",
      "correct 318\n",
      "max tensor(0.5714)\n",
      "min tensor(0.3164)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0])\n",
      "total 704\n",
      "correct 348\n",
      "max tensor(0.5753)\n",
      "min tensor(0.2481)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0])\n",
      "total 768\n",
      "correct 377\n",
      "max tensor(0.5794)\n",
      "min tensor(0.4702)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0])\n",
      "total 832\n",
      "correct 415\n",
      "max tensor(0.5632)\n",
      "min tensor(0.4478)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1])\n",
      "total 896\n",
      "correct 449\n",
      "max tensor(0.5967)\n",
      "min tensor(0.4871)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1])\n",
      "total 960\n",
      "correct 482\n",
      "max tensor(0.6251)\n",
      "min tensor(0.4919)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1])\n",
      "total 1024\n",
      "correct 517\n",
      "max tensor(0.5658)\n",
      "min tensor(0.4633)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0])\n",
      "total 1088\n",
      "correct 550\n",
      "max tensor(0.5722)\n",
      "min tensor(0.4844)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
      "total 1152\n",
      "correct 582\n",
      "max tensor(0.6234)\n",
      "min tensor(0.4476)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0])\n",
      "total 1216\n",
      "correct 612\n",
      "max tensor(0.5946)\n",
      "min tensor(0.5037)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0])\n",
      "total 1280\n",
      "correct 640\n",
      "max tensor(0.6365)\n",
      "min tensor(0.4768)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1])\n",
      "total 1344\n",
      "correct 672\n",
      "max tensor(0.6175)\n",
      "min tensor(0.4286)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0])\n",
      "total 1408\n",
      "correct 703\n",
      "max tensor(0.5855)\n",
      "min tensor(0.5011)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1])\n",
      "total 1472\n",
      "correct 737\n",
      "max tensor(0.6783)\n",
      "min tensor(0.4457)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1])\n",
      "total 1536\n",
      "correct 765\n",
      "max tensor(0.5965)\n",
      "min tensor(0.3054)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "total 1600\n",
      "correct 802\n",
      "max tensor(0.5895)\n",
      "min tensor(0.4688)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1])\n",
      "total 1664\n",
      "correct 832\n",
      "max tensor(0.6136)\n",
      "min tensor(0.4957)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0])\n",
      "total 1728\n",
      "correct 862\n",
      "max tensor(0.7567)\n",
      "min tensor(0.3624)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0])\n",
      "total 1792\n",
      "correct 888\n",
      "max tensor(0.6009)\n",
      "min tensor(0.4713)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1])\n",
      "total 1856\n",
      "correct 926\n",
      "max tensor(0.6514)\n",
      "min tensor(0.3826)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1])\n",
      "total 1920\n",
      "correct 956\n",
      "max tensor(0.6330)\n",
      "min tensor(0.3536)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
      "total 1984\n",
      "correct 990\n",
      "max tensor(0.5470)\n",
      "min tensor(0.5071)\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1])\n",
      "total 2000\n",
      "correct 1000\n",
      "Accuracy of the network on all test images: 50 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the test accuracy on the entire test set\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        labels = labels.reshape(-1)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        # print max and min of outptus\n",
    "        print(\"max\", torch.max(outputs.data))\n",
    "        print(\"min\", torch.min(outputs.data))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        # count the number of correct predictions\n",
    "        correct += (predicted == labels).sum().item()       \n",
    "        # print the predicted and true labels\n",
    "        print(\"predicted\", predicted)\n",
    "        print(\"labels\", labels)\n",
    "\n",
    "        print(\"total\", total)\n",
    "        print(\"correct\", correct)\n",
    "\n",
    "    print('Accuracy of the network on all test images: %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay, so actually the net learns something\n",
    "# Let's prepare features and see if our logistic regression theory model can predict some stuff...\n",
    "\n",
    "net.eval()\n",
    "\n",
    "# Get the features for the training set\n",
    "def get_features(data_loader):\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            labels = labels.reshape(-1)\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # obtain the pre-acivation features\n",
    "            pre_activation = net.almost_forward(inputs)\n",
    "            # print(\"pre_activation\", pre_activation.shape)\n",
    "            train_features.append(pre_activation)\n",
    "            train_labels.append(labels)\n",
    "    return torch.cat(train_features).numpy(), torch.cat(train_labels).numpy()\n",
    "\n",
    "train_features, train_labels = get_features(train_loader)\n",
    "test_features, test_labels = get_features(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 784)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntot = train_features.shape[0]\n",
    "Omega = X_train.T @ X_train / ntot # student-student\n",
    "rho = y_train.dot(y_train) / ntot\n",
    "spec_Omega, U = np.linalg.eigh(Omega)\n",
    "diagUtPhiPhitU = np.diag(1/ntot * U.T @ X_train.T @ y_train.reshape(ntot,1) @ y_train.reshape(1,ntot) @ X_train @ U)\n",
    "\n",
    "\n",
    "# Creata a data json \n",
    "data = {\n",
    "    \"X_train\": list(train_features),\n",
    "    \"y_train\": list(train_labels),\n",
    "    \"X_test\": list(test_features),\n",
    "    \"y_test\": list(test_labels),\n",
    "    \"Omega\": Omega,\n",
    "    \"rho\": rho,\n",
    "    \"spec_Omega\": spec_Omega,\n",
    "    \"diagUtPhiPhitU\": diagUtPhiPhitU\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle data into a file called data/neural_fashion_mnist.pkl\n",
    "with open('data/neural_fashion_mnist.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNeuralNetwork(\n",
      "  (input_layer): Linear(in_features=784, out_features=1000, bias=False)\n",
      "  (hidden3): Linear(in_features=1000, out_features=30, bias=False)\n",
      "  (output_layer): Linear(in_features=30, out_features=1, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1000])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.hidden3.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.output_layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1571,  0.0267, -0.1033, -0.0523, -0.0406, -0.0783,  0.0081,  0.1119,\n",
       "          0.1114,  0.1510,  0.1318,  0.0194,  0.1265, -0.0053, -0.0883,  0.0053,\n",
       "         -0.1539,  0.0190, -0.0094, -0.0007, -0.0941,  0.0087,  0.1087, -0.0591,\n",
       "         -0.0703, -0.0339,  0.1623,  0.0011, -0.1586, -0.1684]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.output_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
