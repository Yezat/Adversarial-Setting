{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Enviromnet\n",
    "Create an environment where we can do meaninful profiling for the state evolution logistic regression integrals.\n",
    "For this we load a dataset and compute some artifical overlaps. Then we can timeit a few error metrics to get a sense of the speedup we can achieve using numba.\n",
    "At a later stage we will do the same for ERM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import owens_t\n",
    "import matplotlib.pyplot as plt\n",
    "# get a logger\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "from ERM import fair_adversarial_error_erm\n",
    "from state_evolution import OverlapSet, fair_adversarial_error_overlaps\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta:  [ 0.96313197 -0.26902939]\n",
      "w:  [0.66106533 0.75032835]\n"
     ]
    }
   ],
   "source": [
    "helper = np.random.uniform(0, 2*np.pi)\n",
    "theta = np.array([np.cos(helper), np.sin(helper)])\n",
    "helper = np.random.uniform(helper-np.pi/2, helper+np.pi/2)\n",
    "w = np.array([np.cos(helper), np.sin(helper)])\n",
    "print(\"theta: \", theta)\n",
    "print(\"w: \", w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_model import VanillaGaussianDataModel\n",
    "data_model = VanillaGaussianDataModel(2,logger,source_pickle_path=\"\")\n",
    "data_set = data_model.generate_data(10000,0)\n",
    "X = data_set.X\n",
    "X_original = X\n",
    "d = 2\n",
    "# We have our own teacher and must create the labels ourselves\n",
    "y_teacher = np.sign(X.dot(theta)/np.sqrt(d))\n",
    "y_student = np.sign(X.dot(w)/np.sqrt(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us fix a gamma\n",
    "gamma = 0.3\n",
    "\n",
    "# gamma describes two lines having margin gamma away from the teacher\n",
    "\n",
    "# let us fix an epsilon\n",
    "epsilon = 0.5\n",
    "\n",
    "# compute the overlaps\n",
    "q = np.dot(w,w) / d\n",
    "m = np.dot(theta,w) / d\n",
    "rho = np.dot(theta,theta) / d\n",
    "\n",
    "\n",
    "# epsilon*m/sqrt(d*q) describes another line parallel to the teacher\n",
    "\n",
    "# Let us define a Sigma_upsilon\n",
    "Sigma_upsilon = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "F = theta.dot(Sigma_upsilon@w) / d\n",
    "A = w.dot(Sigma_upsilon@w) / d\n",
    "\n",
    "# now epsilon*F/sqrt(2*q) describes another line parallel to the teacher\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object with a property Sigma_upsilon\n",
    "class DataModel:\n",
    "    def __init__(self, Sigma_upsilon, rho):\n",
    "        self.Sigma_upsilon = Sigma_upsilon\n",
    "        self.rho = rho \n",
    "        self.Sigma_w = np.eye(2)\n",
    "        self.Sigma_delta = np.eye(2)\n",
    "\n",
    "data_model = DataModel(Sigma_upsilon, rho)\n",
    "\n",
    "\n",
    "overlaps = OverlapSet()\n",
    "overlaps.A = A\n",
    "overlaps.F = F \n",
    "overlaps.q = q\n",
    "overlaps.m = m\n",
    "overlaps.N = q\n",
    "overlaps.sigma = 1\n",
    "\n",
    "from helpers import ProblemType\n",
    "\n",
    "class Task:\n",
    "    def __init__(self, epsilon, gamma, overlaps):\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.overlaps = overlaps\n",
    "        self.tau = 1\n",
    "        self.problem_type = ProblemType.Logistic\n",
    "        self.lam = 0.01\n",
    "        self.d = 2\n",
    "\n",
    "\n",
    "\n",
    "task = Task(epsilon, gamma, overlaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to evaluate test_loss and training error. The first does not use the proximal, the second does. We will start with the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution import LogisticObservables\n",
    "logistic_problem = LogisticObservables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 656 µs, sys: 974 µs, total: 1.63 ms\n",
      "Wall time: 273 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8610207984092665"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timeit \n",
    "%time logistic_problem.test_loss(task,overlaps, data_model,epsilon,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time logistic_problem.numba_test_loss(task,overlaps, data_model,epsilon,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so a speedup is possible! After compilation at least. Fair enough. Now how about a measure based on proximals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 ms, sys: 5.33 ms, total: 17.7 ms\n",
      "Wall time: 4.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17063038980874703"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time logistic_problem.training_error(task,overlaps, data_model,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time logistic_problem.numba_training_error(task,overlaps, data_model,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proximal really is a bit harder. root_scalar is a python function..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, so just use the scipy brentq source code. strongly adapt it to your problem. Compile the C source and use ctypes support in numba. Quite the speedup though :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next question is how to optimize ERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ERM import run_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.problem_type = ProblemType.Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 539 ms, sys: 154 ms, total: 693 ms\n",
      "Wall time: 124 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1.86170695, -1.84278529]), <ERM.LogisticProblem at 0x160000410>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time run_optimizer(task, data_model, data_set, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.problem_type = ProblemType.NumbaLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 847 ms, sys: 121 ms, total: 969 ms\n",
      "Wall time: 161 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.12748115, -0.4571405 ]), <ERM.LogisticProblem at 0x160062950>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time run_optimizer(task, data_model, data_set, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's even worse using numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we do better when putting the entire gradient expression to numba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalings\n",
    "This part is not for profiling but to test some scalings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_model import VanillaGaussianDataModel\n",
    "d = 100\n",
    "data_model = VanillaGaussianDataModel(d,logger,source_pickle_path=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = []\n",
    "\n",
    "# for i in range(1000):\n",
    "#     data_set = data_model.generate_data(100,0)\n",
    "#     n.append(np.mean((data_set.X @ data_set.theta/np.sqrt(d))**2))\n",
    "\n",
    "# print(np.mean(n), np.std(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
