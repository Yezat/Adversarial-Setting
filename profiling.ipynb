{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Enviromnet\n",
    "Create an environment where we can do meaninful profiling for the state evolution logistic regression integrals.\n",
    "For this we load a dataset and compute some artifical overlaps. Then we can timeit a few error metrics to get a sense of the speedup we can achieve using numba.\n",
    "At a later stage we will do the same for ERM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import owens_t\n",
    "import matplotlib.pyplot as plt\n",
    "# get a logger\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "from ERM import fair_adversarial_error_erm\n",
    "from state_evolution import OverlapSet, fair_adversarial_error_overlaps\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta:  [ 0.08730119 -0.99618196]\n",
      "w:  [ 0.51558496 -0.85683846]\n"
     ]
    }
   ],
   "source": [
    "helper = np.random.uniform(0, 2*np.pi)\n",
    "theta = np.array([np.cos(helper), np.sin(helper)])\n",
    "helper = np.random.uniform(helper-np.pi/2, helper+np.pi/2)\n",
    "w = np.array([np.cos(helper), np.sin(helper)])\n",
    "print(\"theta: \", theta)\n",
    "print(\"w: \", w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_model import VanillaGaussianDataModel\n",
    "data_model = VanillaGaussianDataModel(2,logger,source_pickle_path=\"\")\n",
    "data_set = data_model.generate_data(10000,0)\n",
    "X = data_set.X\n",
    "X_original = X\n",
    "d = 2\n",
    "# We have our own teacher and must create the labels ourselves\n",
    "y_teacher = np.sign(X.dot(theta)/np.sqrt(d))\n",
    "y_student = np.sign(X.dot(w)/np.sqrt(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us fix a gamma\n",
    "gamma = 0.3\n",
    "\n",
    "# gamma describes two lines having margin gamma away from the teacher\n",
    "\n",
    "# let us fix an epsilon\n",
    "epsilon = 0.5\n",
    "\n",
    "# compute the overlaps\n",
    "q = np.dot(w,w) / d\n",
    "m = np.dot(theta,w) / d\n",
    "rho = np.dot(theta,theta) / d\n",
    "\n",
    "\n",
    "# epsilon*m/sqrt(d*q) describes another line parallel to the teacher\n",
    "\n",
    "# Let us define a Sigma_upsilon\n",
    "Sigma_upsilon = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "F = theta.dot(Sigma_upsilon@w) / d\n",
    "A = w.dot(Sigma_upsilon@w) / d\n",
    "\n",
    "# now epsilon*F/sqrt(2*q) describes another line parallel to the teacher\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object with a property Sigma_upsilon\n",
    "class DataModel:\n",
    "    def __init__(self, Sigma_upsilon, rho):\n",
    "        self.Sigma_upsilon = Sigma_upsilon\n",
    "        self.rho = rho \n",
    "        self.Sigma_w = np.eye(2)\n",
    "        self.Sigma_delta = np.eye(2)\n",
    "\n",
    "data_model = DataModel(Sigma_upsilon, rho)\n",
    "\n",
    "\n",
    "overlaps = OverlapSet()\n",
    "overlaps.A = A\n",
    "overlaps.F = F \n",
    "overlaps.q = q\n",
    "overlaps.m = m\n",
    "overlaps.N = q\n",
    "overlaps.sigma = 1\n",
    "\n",
    "from helpers import ProblemType\n",
    "\n",
    "class Task:\n",
    "    def __init__(self, epsilon, gamma, overlaps):\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.overlaps = overlaps\n",
    "        self.tau = 1\n",
    "        self.problem_type = ProblemType.Logistic\n",
    "        self.lam = 0.01\n",
    "        self.d = 2\n",
    "\n",
    "\n",
    "\n",
    "task = Task(epsilon, gamma, overlaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to evaluate test_loss and training error. The first does not use the proximal, the second does. We will start with the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution import LogisticObservables\n",
    "logistic_problem = LogisticObservables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 121 ms, sys: 16.3 ms, total: 137 ms\n",
      "Wall time: 478 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7734151732388087"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timeit \n",
    "%time logistic_problem.test_loss(task,overlaps, data_model,epsilon,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time logistic_problem.numba_test_loss(task,overlaps, data_model,epsilon,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so a speedup is possible! After compilation at least. Fair enough. Now how about a measure based on proximals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 83 ms, sys: 2.11 ms, total: 85.2 ms\n",
      "Wall time: 489 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10314508866370942"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time logistic_problem.training_error(task,overlaps, data_model,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time logistic_problem.numba_training_error(task,overlaps, data_model,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proximal really is a bit harder. root_scalar is a python function..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, so just use the scipy brentq source code. strongly adapt it to your problem. Compile the C source and use ctypes support in numba. Quite the speedup though :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next question is how to optimize ERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ERM import run_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.problem_type = ProblemType.Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 s, sys: 414 ms, total: 1.42 s\n",
      "Wall time: 745 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.59985604, 2.12615471]), <ERM.LogisticProblem at 0x1623ca250>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time run_optimizer(task, data_model, data_set, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.problem_type = ProblemType.NumbaLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 s, sys: 2.08 s, total: 4.09 s\n",
      "Wall time: 3.33 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1281.58746221,   72.87683249]), <ERM.LogisticProblem at 0x1626cab50>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time run_optimizer(task, data_model, data_set, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's even worse using numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we do better when putting the entire gradient expression to numba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalings\n",
    "This part is not for profiling but to test some scalings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_model import VanillaGaussianDataModel\n",
    "d = 100\n",
    "data_model = VanillaGaussianDataModel(d,logger,source_pickle_path=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997929101898949 0.20565639579012499\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "\n",
    "for i in range(1000):\n",
    "    data_set = data_model.generate_data(100,0)\n",
    "    n.append(np.mean((data_set.X @ data_set.theta/np.sqrt(d))**2))\n",
    "\n",
    "print(np.mean(n), np.std(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
