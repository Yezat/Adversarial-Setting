"""
This module defines classes to generate data models and sample data for the experiments.
"""

import logging
import numpy as np
from dataclasses import field, dataclass
from DataModel.dataset import DataSet
from typing import Callable, Any


DataModelFactoryType = Callable[
    ..., tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]
]


@dataclass
class DataModel:
    """
    Data class for data models.

    Attributes:
        d (int): Dimension of the space.
        gamma (float): The aspect ratio of the student space to the teacher space p/d = 1.
        name (str): Optional name of the model, if defined. The pickle file name will contain this name. If the file already exists, an exception will be thrown.
        description (str): Optional description of the model, just a text to describe in words what the model is about.
        Σ_x (ndarray): The data covariance.
        Σ_ω (ndarray): The student weight prior (d,d).
        Σ_δ (ndarray): The student adversarial budget (d,d).
        Σ_ν (ndarray): The student adversarial budget (d,d).
        Σ_θ (ndarray): The teacher weight prior (d,d).
        θ (ndarray): The teacher weight prior (d,).
        ρ (float): The teacher-teacher overlap.
        ΦΦT (ndarray): The Σ_x^T θ θ^T Σ_x matrix (d,d).
        spec_ΦΦT (ndarray): The spectrum of ΦΦT (d,).
        spec_Σ_x (ndarray): The spectrum of Σ_x (d,).
        spec_Σ_δ (ndarray): The spectrum of Σ_δ (d,).
    """

    d: int
    normalize_matrices: bool

    data_model_factory: DataModelFactoryType
    factory_kwargs: dict[str, Any] = field(default_factory=dict)

    name: str = ""
    description: str = ""
    gamma: float = 1

    Σ_x: np.ndarray = field(init=False, repr=False)
    Σ_ω: np.ndarray = field(init=False, repr=False)
    Σ_δ: np.ndarray = field(init=False, repr=False)
    Σ_ν: np.ndarray = field(init=False, repr=False)
    θ: np.ndarray = field(init=False, repr=False)

    Σ_θ: np.ndarray = field(init=False, repr=False)
    ρ: float = field(init=False, repr=False)
    ΦΦT: np.ndarray = field(init=False, repr=False)
    spec_ΦΦT: np.ndarray = field(init=False, repr=False)
    spec_Σ_x: np.ndarray = field(init=False, repr=False)
    spec_Σ_δ: np.ndarray = field(init=False, repr=False)

    def __repr__(self):
        return f"DataModel(d={repr(self.d)}, normalize_matrices={repr(self.normalize_matrices)}, data_model_factory={self.data_model_factory.__name__}, factory_kwargs={repr(self.factory_kwargs)}, name={repr(self.name)}, description={repr(self.description)}, gamma={repr(self.gamma)})"

    def __post_init__(self):
        """
        Computes more attributes.

        Assumes that
        - Σ_x
        - θ
        - Σ_ω
        - Σ_δ
        - Σ_ν

        can be generated by the factory function.
        """
        logging.info("Initializing data model")

        self.Σ_x, self.θ, self.Σ_ω, self.Σ_δ, self.Σ_ν = self.data_model_factory(
            self.d, **self.factory_kwargs
        )

        # Check if the matrices are positive semi-definite
        assumption_1 = self.Σ_x - self.Σ_x.T @ np.linalg.inv(self.Σ_x) @ self.Σ_x
        min_eigval = np.min(np.linalg.eigvals(assumption_1))
        if min_eigval < 0:
            logging.warning(
                f"Assumption on Schur Complement failed: Matrix was not positive semi-definite; min eigval: {min_eigval}"
            )

        logging.info(f"d: {self.d}")

        # Compute Σ_θ
        self.Σ_θ = np.diag(self.θ)

        # Normalize all the matrices by dividing by the norm of the matrix
        logging.info(f"normalize_matrices: {self.normalize_matrices}")
        if self.normalize_matrices:
            logging.info("Normalizing the matrices")
            self.Σ_x = self.Σ_x / np.trace(self.Σ_x) * self.d
            self.Σ_ω = self.Σ_ω / np.trace(self.Σ_ω) * self.d
            self.Σ_δ = self.Σ_δ / np.trace(self.Σ_δ) * self.d
            self.Σ_ν = self.Σ_ν / np.trace(self.Σ_ν) * self.d
            self.Σ_θ = self.Σ_θ / np.trace(self.Σ_θ) * self.d

        self.spec_Σ_x = np.linalg.eigvals(self.Σ_x)
        self.spec_Σ_θ = np.linalg.eigvals(self.Σ_θ)

        # compute and log the ratio of the first eigenvalue to the last eigenvalue
        logging.info(
            f"Ratio of first to last eigenvalue of Σ_x: {self.spec_Σ_x[0] / self.spec_Σ_x[-1]}"
        )

        # Compute ΦΦT
        self.ΦΦT = np.diag(self.spec_Σ_x**2 * self.spec_Σ_θ)

        # Compute ρ
        self.ρ = np.mean(self.spec_Σ_x * self.spec_Σ_θ)

        # Compute FTerm
        self.FTerm = self.Σ_x.T * self.Σ_θ * self.Σ_ν + self.Σ_ν.T * self.Σ_θ * self.Σ_x

        # compute the spectra
        self.spec_ΦΦT = np.linalg.eigvals(self.ΦΦT)
        self.spec_Σ_δ = np.linalg.eigvals(self.Σ_δ)
        self.spec_Σ_ω = np.linalg.eigvals(self.Σ_ω)
        self.spec_Σ_ν = np.linalg.eigvals(self.Σ_ν)
        self.spec_FTerm = np.linalg.eigvals(self.FTerm)

        # log the spectra
        logging.info(f"Norm Σ_x: {np.trace(self.Σ_x)}")
        logging.info(f"Norm Σ_ω: {np.trace(self.Σ_ω)}")
        logging.info(f"Norm Σ_δ: {np.trace(self.Σ_δ)}")
        logging.info(f"Norm Σ_ν: {np.trace(self.Σ_ν)}")
        # log entries of Σ_x
        logging.info(f"Σ_x: {self.Σ_x}")
        logging.info(f"Σ_ω: {self.Σ_ω}")
        logging.info(f"Σ_δ: {self.Σ_δ}")
        logging.info(f"Σ_ν: {self.Σ_ν}")

        # value count the entries of Σ_x
        logging.info(f"Σ_x value counts: {np.unique(self.Σ_x, return_counts=True)}")
        logging.info(f"Σ_ω value counts: {np.unique(self.Σ_ω, return_counts=True)}")
        logging.info(f"Σ_δ value counts: {np.unique(self.Σ_δ, return_counts=True)}")
        logging.info(f"Σ_ν value counts: {np.unique(self.Σ_ν, return_counts=True)}")

        # log ρ
        logging.info(f"ρ: {self.ρ}")

        # log the spec_Σ_δ
        logging.info(f"Σ_δ eigenvalues: {self.spec_Σ_δ}")

        # Assert that the shapes of the matrices are correct
        assert self.Σ_x.shape == (self.d, self.d)
        assert self.Σ_θ.shape == (self.d, self.d)
        assert self.Σ_ω.shape == (self.d, self.d)
        assert self.Σ_δ.shape == (self.d, self.d)
        assert self.Σ_ν.shape == (self.d, self.d)


def generate_data(model: DataModel, n: int, tau: float) -> DataSet:
    """
    Generates n training data X, y, and test data X_test, y_test and a teacher weight vector w using noise-level tau.

    Args:
        n (int): Number of training samples.
        tau (float): Noise level.
    """
    rng = np.random.default_rng(seed=42)

    θ = rng.multivariate_normal(np.zeros(model.d), model.Σ_θ, 1, method="cholesky")[0]

    X = rng.multivariate_normal(np.zeros(model.d), model.Σ_x, n, method="cholesky")
    y = np.sign(X @ θ / np.sqrt(model.d) + tau * np.random.normal(0, 1, (n,)))

    X_test = rng.multivariate_normal(
        np.zeros(model.d), model.Σ_x, 10000, method="cholesky"
    )
    y_test = np.sign(
        X_test @ θ / np.sqrt(model.d) + tau * np.random.normal(0, 1, (10000,))
    )

    return DataSet(X, y, X_test, y_test, θ)


@dataclass
class KFeaturesModelDefinition:
    """
    This dataclass specifies KFeatures diagonal matrices.
    """

    diagonal: list[tuple[int, int]] = field(
        default_factory=list
    )  # list of tuples (feature_value, feature_size)

    def get_nd_array(self, d: int) -> np.ndarray:
        """
        Returns the diagonal matrix of the KFeaturesModel.
        """
        M = np.zeros(d)
        c = 0
        for feature_value, feature_size in self.diagonal:
            M[c : c + feature_size] = feature_value
            c += feature_size
        return M

    def get_nd_matrix(self, d: int) -> np.ndarray:
        return np.diag(self.get_nd_array(d))


def k_features_factory(
    d: int,
    x_diagonal: KFeaturesModelDefinition,
    θ_diagonal: KFeaturesModelDefinition,
    ω_diagonal: KFeaturesModelDefinition,
    δ_diagonal: KFeaturesModelDefinition,
    ν_diagonal: KFeaturesModelDefinition,
) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Factory function for KFeaturesModel.
    """
    Σ_x = x_diagonal.get_nd_matrix(d)
    Σ_ω = ω_diagonal.get_nd_matrix(d)
    Σ_δ = δ_diagonal.get_nd_matrix(d)
    Σ_ν = ν_diagonal.get_nd_matrix(d)
    θ = θ_diagonal.get_nd_array(d)
    return Σ_x, θ, Σ_ω, Σ_δ, Σ_ν


# class KFeaturesModel(DataModel):
#     def __init__(
#         self,
#         d,
#         logger,
#         delete_existing=False,
#         normalize_matrices=True,
#         attack_equal_defense=False,
#         source_pickle_path="../",
#         Σ_ω_content=None,
#         Σ_δ_content=None,
#         Σ_ν_content=None,
#         name="",
#         description="",
#         feature_ratios=None,
#         features_x=None,
#         features_θ=None,
#         process_sigma_type: SigmaDeltaProcessType = SigmaDeltaProcessType.UseContent,
#     ) -> None:
#         """
#         k = len(feature_ratios)
#         feature_ratios = np.array([2,d-2]) # must sum to d and be of length k
#         features_x = np.array([100,1]) # must be of length k and contains each features size for the data covariance X
#         features_θ = np.array([1,1]) # must be of length k and contains each features size for the teacher prior
#         """

#         self.d = d

#         if feature_ratios is None:
#             feature_ratios = np.array([1 / d, 1 - 1 / d])
#         if features_x is None:
#             features_x = np.array([10, 1])
#         if features_θ is None:
#             features_θ = np.array([1, 1])

#         self.model_type = DataModelType.KFeaturesModel
#         super().__init__(
#             d,
#             logger,
#             delete_existing=delete_existing,
#             normalize_matrices=normalize_matrices,
#             source_pickle_path=source_pickle_path,
#             name=name,
#             description=description,
#         )

#         if not self.loaded_from_pickle:
#             k = len(feature_ratios)

#             # transform the feature ratios to feature sizes
#             feature_sizes = np.floor(feature_ratios * d).astype(int)

#             θ = np.zeros(d)
#             spec_Omega0 = np.zeros(d)
#             for i in range(k):
#                 θ[sum(feature_sizes[:i]) : sum(feature_sizes[: i + 1])] = (
#                     features_θ[i]
#                 )
#                 spec_Omega0[sum(feature_sizes[:i]) : sum(feature_sizes[: i + 1])] = (
#                     features_x[i]
#                 )
#             self.Σ_x = np.diag(spec_Omega0)

#             self.feature_sizes = feature_sizes

#             self.ρ = np.mean(spec_Omega0 * θ)
#             self.ΦΦT = np.diag(spec_Omega0**2 * θ)
#             self.Σ_θ = np.diag(θ)

#             Σ_ω = np.zeros(d)
#             Σ_δ = np.zeros(d)
#             Σ_ν = np.zeros(d)

#             logging.info(f"d: {d}")
#             logging.info(f"feature_sizes: {feature_sizes}")
#             logging.info(f"feature_ratios: {feature_ratios}")
#             logging.info(f"features_x: {features_x}")
#             logging.info(f"features_θ: {features_θ}")
#             logging.info(f"Σ_ω_content: {Σ_ω_content}")
#             logging.info(f"Σ_δ_content: {Σ_δ_content}")
#             logging.info(f"Σ_ν_content: {Σ_ν_content}")

#             for i in range(k):
#                 Σ_ω[sum(feature_sizes[:i]) : sum(feature_sizes[: i + 1])] = (
#                     Σ_ω_content[i]
#                 )
#                 Σ_δ[sum(feature_sizes[:i]) : sum(feature_sizes[: i + 1])] = (
#                     Σ_δ_content[i]
#                 )
#                 Σ_ν[sum(feature_sizes[:i]) : sum(feature_sizes[: i + 1])] = (
#                     Σ_ν_content[i]
#                 )
#             self.Σ_ω = np.diag(Σ_ω)
#             self.Σ_δ = np.diag(Σ_δ)
#             self.Σ_ν = np.diag(Σ_ν)

#             self.V_i = np.ones(d)

#             if (
#                 process_sigma_type == SigmaDeltaProcessType.ComputeTeacherOrthogonal
#                 or process_sigma_type == SigmaDeltaProcessType.ComputeTeacherDirection
#             ):
#                 if process_sigma_type == SigmaDeltaProcessType.ComputeTeacherOrthogonal:
#                     vprime = np.random.normal(0, 1, d)

#                     # chose v = vprime - <vprime,θ> θ / ||θ||^2

#                     v = (
#                         vprime
#                         - np.dot(vprime, θ) * θ / np.linalg.norm(θ) ** 2
#                     )

#                     # normalize v
#                     v = v / np.linalg.norm(v)

#                     Σ_δ_content = v

#                     # log in this case v dot θ
#                     logging.info(f"v dot θ: {np.dot(v,θ)}")

#                 elif (
#                     process_sigma_type == SigmaDeltaProcessType.ComputeTeacherDirection
#                 ):
#                     v = θ
#                     v = v / np.linalg.norm(v)
#                     Σ_δ_content = v

#                     # log in this case v dot θ
#                     logging.info(f"v dot θ: {np.dot(v,θ)}")

#                 # Only for the Optimal Defense Experiment
#                 self.Σ_δ = np.outer(Σ_δ_content, Σ_δ_content)

#                 # sample a random covariance matrix
#                 random_matrix = np.random.normal(0, 0.0001, (d, d))
#                 self.Σ_δ = (
#                     random_matrix.T @ random_matrix + self.Σ_δ * 10000
#                 )

#                 self.V_i = Σ_δ_content

#             if attack_equal_defense:
#                 self.Σ_ν = self.Σ_δ

#             # log the eigenvalues of Σ_δ
#             logging.info(
#                 f"Σ_δ eigenvalues: {np.linalg.eigvals(self.Σ_δ)}"
#             )

#             if self.Σ_ω is None:
#                 self.Σ_ω = np.eye(self.d)
#             if self.Σ_δ is None:
#                 self.Σ_δ = np.eye(self.d)
#             if self.Σ_ν is None:
#                 self.Σ_ν = np.eye(self.d)

#             # Compute FTerm
#             self.FTerm = (
#                 self.Σ_x.T * self.Σ_θ * self.Σ_ν
#                 + self.Σ_ν.T * self.Σ_θ * self.Σ_x
#             )

#             self._finish_initialization()

#     def generate_data(self, n, tau) -> DataSet:
#         θ = np.random.default_rng().multivariate_normal(
#             np.zeros(self.d), self.Σ_θ, 1, method="cholesky"
#         )[0]
#         X = np.random.default_rng().multivariate_normal(
#             np.zeros(self.d), self.Σ_x, n, method="cholesky"
#         )

#         y = np.sign(X @ θ / np.sqrt(self.d) + tau * np.random.normal(0, 1, (n,)))

#         X_test = np.random.default_rng().multivariate_normal(
#             np.zeros(self.d), self.Σ_x, 10000, method="cholesky"
#         )
#         y_test = np.sign(
#             X_test @ θ / np.sqrt(self.d) + tau * np.random.normal(0, 1, (10000,))
#         )

#         return DataSet(X, y, X_test, y_test, θ)


# class SourceCapacityDataModel(AbstractDataModel):
#     def __init__(
#         self,
#         d,
#         logger,
#         delete_existing=False,
#         normalize_matrices=True,
#         source_pickle_path="../",
#         Σ_ω=None,
#         Σ_δ=None,
#         Σ_ν=None,
#         name="",
#         description="",
#     ) -> None:
#         self.model_type = DataModelType.SourceCapacity
#         super().__init__(
#             d,
#             logger,
#             delete_existing=delete_existing,
#             normalize_matrices=normalize_matrices,
#             source_pickle_path=source_pickle_path,
#             name=name,
#             description=description,
#         )

#         if not self.loaded_from_pickle:
#             alph = 1.2
#             r = 0.3

#             spec_Omega0 = np.array([self.d / (k + 1) ** alph for k in range(self.d)])
#             self.Σ_x = np.diag(spec_Omega0)

#             θ = np.sqrt(
#                 np.array(
#                     [1 / (k + 1) ** (1 + alph * (2 * r - 1)) for k in range(self.d)]
#                 )
#             )

#             self.ρ = np.mean(spec_Omega0 * θ**2)
#             self.ΦΦT = np.diag(spec_Omega0**2 * θ**2)
#             self.Σ_θ = np.diag(θ**2)

#             self.Σ_ω = Σ_ω
#             self.Σ_δ = Σ_δ
#             self.Σ_ν = Σ_ν
#             if self.Σ_ω is None:
#                 self.Σ_ω = np.eye(self.d)
#             if self.Σ_δ is None:
#                 self.Σ_δ = np.eye(self.d)
#             if self.Σ_ν is None:
#                 self.Σ_ν = np.eye(self.d)

#             self.FTerm = (
#                 self.Σ_x.T * self.Σ_θ * self.Σ_ν
#                 + self.Σ_ν.T * self.Σ_θ * self.Σ_x
#             )

#             self._finish_initialization()

#     def generate_data(self, n, tau) -> DataSet:
#         θ = np.random.default_rng().multivariate_normal(
#             np.zeros(self.d), self.Σ_θ, 1, method="cholesky"
#         )[0]
#         X = np.random.default_rng().multivariate_normal(
#             np.zeros(self.d), self.Σ_x, n, method="cholesky"
#         )

#         y = np.sign(X @ θ / np.sqrt(self.d) + tau * np.random.normal(0, 1, (n,)))

#         X_test = np.random.default_rng().multivariate_normal(
#             np.zeros(self.d), self.Σ_x, 10000, method="cholesky"
#         )
#         y_test = np.sign(
#             X_test @ θ / np.sqrt(self.d) + tau * np.random.normal(0, 1, (10000,))
#         )

#         return DataSet(X, y, X_test, y_test, θ)


# class MarginGaussianDataModel(AbstractDataModel):
#     def __init__(
#         self,
#         d,
#         logger,
#         delete_existing=False,
#         normalize_matrices=True,
#         source_pickle_path="../",
#         Σ_ω=None,
#         Σ_δ=None,
#         Σ_ν=None,
#         name="",
#         description="",
#     ) -> None:
#         self.model_type = DataModelType.MarginGaussian
#         super().__init__(
#             d,
#             logger,
#             delete_existing=delete_existing,
#             normalize_matrices=normalize_matrices,
#             source_pickle_path=source_pickle_path,
#             name=name,
#             description=description,
#         )

#         if not self.loaded_from_pickle:
#             """
#             Warning, these matrices can be anything as this model is not meant to work with the state evolution as it is a mixed gaussian model!
#             """

#             self.Σ_x = np.eye(self.d)
#             self.Σ_θ = np.eye(self.d)

#             self.Σ_ω = Σ_ω
#             self.Σ_δ = Σ_δ
#             self.Σ_ν = Σ_ν
#             if self.Σ_ω is None:
#                 self.Σ_ω = np.eye(self.d)
#             if self.Σ_δ is None:
#                 self.Σ_δ = np.eye(self.d)
#             if self.Σ_ν is None:
#                 self.Σ_ν = np.eye(self.d)

#             self.FTerm = (
#                 self.Σ_x.T * self.Σ_θ * self.Σ_ν
#                 + self.Σ_ν.T * self.Σ_θ * self.Σ_x
#             )

#             self.ρ = 1
#             self.ΦΦT = np.eye(self.d)

#             self._finish_initialization()

#     def generate_data(self, n, tau) -> DataSet:
#         # We fix the teacher to be the first eigenvector in a d-dimensional space
#         the = np.zeros(self.d)
#         the[0] = 1
#         r = 2.0

#         # create the labels
#         n_half = np.floor(n / 2)
#         # convert to int
#         n_half = n_half.astype(int)
#         n_test_half = np.floor(100000 / 2)
#         n_test_half = n_test_half.astype(int)
#         y = np.concatenate([np.ones(n_half), -np.ones(n_half)])
#         y_test = np.concatenate([np.ones(n_test_half), -np.ones(n_test_half)])

#         # create the data
#         X = np.random.normal(0, 1, (n_half * 2, self.d))
#         X_test = np.random.normal(0, 1, (n_test_half * 2, self.d))

#         # change the first dimension of each dataset according to r*y*the
#         X[:, 0] = r * y * the[0]
#         X_test[:, 0] = r * y_test * the[0]

#         return DataSet(X, y, X_test, y_test, the)
