{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0, \"../experiments\")\n",
    "\n",
    "\n",
    "from experiment_information import *\n",
    "from experiment_setup import *\n",
    "from data import *\n",
    "from helpers import *\n",
    "from data_loading import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code assumes that you have defined and run an experiment before using `define_experiment.ipynb` in the `experiments` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current code version, 113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>problem_types</th>\n",
       "      <th>code_version</th>\n",
       "      <th>date</th>\n",
       "      <th>state_evolution_repetitions</th>\n",
       "      <th>erm_repetitions</th>\n",
       "      <th>alphas</th>\n",
       "      <th>epsilons</th>\n",
       "      <th>...</th>\n",
       "      <th>taus</th>\n",
       "      <th>ps</th>\n",
       "      <th>dp</th>\n",
       "      <th>d</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>completed</th>\n",
       "      <th>data_model_types</th>\n",
       "      <th>data_model_names</th>\n",
       "      <th>data_model_descriptions</th>\n",
       "      <th>gamma_fair_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>e0455cbf-d8d4-4db5-a1ae-fd56eb40e292</td>\n",
       "      <td>DifferentSigmaW</td>\n",
       "      <td>23.567899</td>\n",
       "      <td>[\"Logistic\"]</td>\n",
       "      <td>113</td>\n",
       "      <td>2024-07-01 17:07:22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001, 0.0015, 0.0021, 0.0031, 0.0044, 0.0064...</td>\n",
       "      <td>[0.0, 0.1, 0.2, 0.3, 0.4]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.05]</td>\n",
       "      <td>null</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>Sweep</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...</td>\n",
       "      <td>[\"KFeaturesModel_TwoFeatures_NonuniformProtect...</td>\n",
       "      <td>[\"2 Features, Theta Identity, Sigma_upsilon Id...</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>97bab239-8528-47c0-ab8c-bcfccc890913</td>\n",
       "      <td>DifferentSigmaW</td>\n",
       "      <td>16.709738</td>\n",
       "      <td>[\"Logistic\"]</td>\n",
       "      <td>113</td>\n",
       "      <td>2024-07-01 15:53:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001, 0.0015, 0.0021, 0.0031, 0.0044, 0.0064...</td>\n",
       "      <td>[0.0, 0.1, 0.2, 0.3, 0.4]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.05]</td>\n",
       "      <td>null</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>Sweep</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...</td>\n",
       "      <td>[\"KFeaturesModel_TwoFeatures_NonuniformProtect...</td>\n",
       "      <td>[\"2 Features, Theta Identity, Sigma_upsilon Id...</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>9c0b9876-2fef-46ff-81dd-d5b5518514c2</td>\n",
       "      <td>DifferentSigmaW</td>\n",
       "      <td>16.650080</td>\n",
       "      <td>[\"Logistic\"]</td>\n",
       "      <td>113</td>\n",
       "      <td>2024-07-01 14:54:39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001, 0.0014, 0.0021, 0.003, 0.0043, 0.0061,...</td>\n",
       "      <td>[0.0, 0.1, 0.2, 0.3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.05]</td>\n",
       "      <td>null</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>Sweep</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...</td>\n",
       "      <td>[\"KFeaturesModel_TwoFeatures_NonuniformProtect...</td>\n",
       "      <td>[\"2 Features, Theta Identity, Sigma_upsilon Id...</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>29363a8c-c89c-4eda-a059-b8ba743bcb53</td>\n",
       "      <td>DifferentSigmaW</td>\n",
       "      <td>10.998375</td>\n",
       "      <td>[\"Logistic\"]</td>\n",
       "      <td>113</td>\n",
       "      <td>2024-07-01 11:22:04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001, 0.0014, 0.0021, 0.003, 0.0043, 0.0061,...</td>\n",
       "      <td>[0.0, 0.1, 0.2, 0.3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.05]</td>\n",
       "      <td>null</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>Sweep</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...</td>\n",
       "      <td>[\"KFeaturesModel_TwoFeatures_NonuniformProtect...</td>\n",
       "      <td>[\"2 Features, Theta Identity, Sigma_upsilon Id...</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>c02b94b1-cac0-4ebe-9592-3487c3555d08</td>\n",
       "      <td>DifferentSigmaW</td>\n",
       "      <td>45.117960</td>\n",
       "      <td>[\"Logistic\"]</td>\n",
       "      <td>113</td>\n",
       "      <td>2024-07-01 11:18:27</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.001, 0.0014, 0.0021, 0.003, 0.0043, 0.0061,...</td>\n",
       "      <td>[0.0, 0.1, 0.2, 0.3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.05]</td>\n",
       "      <td>null</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>Sweep</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...</td>\n",
       "      <td>[\"KFeaturesModel_TwoFeatures_NonuniformProtect...</td>\n",
       "      <td>[\"2 Features, Theta Identity, Sigma_upsilon Id...</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           experiment_id  experiment_name   duration  \\\n",
       "55  e0455cbf-d8d4-4db5-a1ae-fd56eb40e292  DifferentSigmaW  23.567899   \n",
       "54  97bab239-8528-47c0-ab8c-bcfccc890913  DifferentSigmaW  16.709738   \n",
       "53  9c0b9876-2fef-46ff-81dd-d5b5518514c2  DifferentSigmaW  16.650080   \n",
       "52  29363a8c-c89c-4eda-a059-b8ba743bcb53  DifferentSigmaW  10.998375   \n",
       "50  c02b94b1-cac0-4ebe-9592-3487c3555d08  DifferentSigmaW  45.117960   \n",
       "\n",
       "   problem_types code_version                 date  \\\n",
       "55  [\"Logistic\"]          113  2024-07-01 17:07:22   \n",
       "54  [\"Logistic\"]          113  2024-07-01 15:53:20   \n",
       "53  [\"Logistic\"]          113  2024-07-01 14:54:39   \n",
       "52  [\"Logistic\"]          113  2024-07-01 11:22:04   \n",
       "50  [\"Logistic\"]          113  2024-07-01 11:18:27   \n",
       "\n",
       "    state_evolution_repetitions  erm_repetitions  \\\n",
       "55                            1                0   \n",
       "54                            1                0   \n",
       "53                            1                0   \n",
       "52                            1                0   \n",
       "50                            1               10   \n",
       "\n",
       "                                               alphas  \\\n",
       "55  [0.001, 0.0015, 0.0021, 0.0031, 0.0044, 0.0064...   \n",
       "54  [0.001, 0.0015, 0.0021, 0.0031, 0.0044, 0.0064...   \n",
       "53  [0.001, 0.0014, 0.0021, 0.003, 0.0043, 0.0061,...   \n",
       "52  [0.001, 0.0014, 0.0021, 0.003, 0.0043, 0.0061,...   \n",
       "50  [0.001, 0.0014, 0.0021, 0.003, 0.0043, 0.0061,...   \n",
       "\n",
       "                     epsilons  ...    taus    ps    dp    d  experiment_type  \\\n",
       "55  [0.0, 0.1, 0.2, 0.3, 0.4]  ...  [0.05]  null  0.01  500            Sweep   \n",
       "54  [0.0, 0.1, 0.2, 0.3, 0.4]  ...  [0.05]  null  0.01  500            Sweep   \n",
       "53       [0.0, 0.1, 0.2, 0.3]  ...  [0.05]  null  0.01  500            Sweep   \n",
       "52       [0.0, 0.1, 0.2, 0.3]  ...  [0.05]  null  0.01  500            Sweep   \n",
       "50       [0.0, 0.1, 0.2, 0.3]  ...  [0.05]  null  0.01  500            Sweep   \n",
       "\n",
       "    completed                                   data_model_types  \\\n",
       "55          1  [\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...   \n",
       "54          1  [\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...   \n",
       "53          1  [\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...   \n",
       "52          1  [\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...   \n",
       "50          1  [\"KFeaturesModel\", \"KFeaturesModel\", \"KFeature...   \n",
       "\n",
       "                                     data_model_names  \\\n",
       "55  [\"KFeaturesModel_TwoFeatures_NonuniformProtect...   \n",
       "54  [\"KFeaturesModel_TwoFeatures_NonuniformProtect...   \n",
       "53  [\"KFeaturesModel_TwoFeatures_NonuniformProtect...   \n",
       "52  [\"KFeaturesModel_TwoFeatures_NonuniformProtect...   \n",
       "50  [\"KFeaturesModel_TwoFeatures_NonuniformProtect...   \n",
       "\n",
       "                              data_model_descriptions gamma_fair_error  \n",
       "55  [\"2 Features, Theta Identity, Sigma_upsilon Id...           0.0001  \n",
       "54  [\"2 Features, Theta Identity, Sigma_upsilon Id...           0.0001  \n",
       "53  [\"2 Features, Theta Identity, Sigma_upsilon Id...           0.0001  \n",
       "52  [\"2 Features, Theta Identity, Sigma_upsilon Id...           0.0001  \n",
       "50  [\"2 Features, Theta Identity, Sigma_upsilon Id...           0.0001  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_experiments, df_state_evolution, df_erm = obtain_dataframes(logger)\n",
    "df_experiments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29363a8c-c89c-4eda-a059-b8ba743bcb53\n",
      "Sweep\n",
      "KFeaturesModel\n",
      "KFeaturesModel\n",
      "KFeaturesModel\n",
      "['KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 1]___DifferentSigmaW', 'KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[2 1]___DifferentSigmaW', 'KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 2]___DifferentSigmaW']\n",
      "[\"2 Features, Theta Identity, Sigma_upsilon Identity, Sigma_delta Non Id, Sigma w Id\", \"2 Features, Theta Identity, Sigma_upsilon Identity, Sigma_delta Non Id, Sigma w Non Id\", \"2 Features, Theta Identity, Sigma_upsilon Identity, Sigma_delta Non Id, Sigma w Non Id\"]\n",
      "DifferentSigmaW\n",
      "['Logistic']\n"
     ]
    }
   ],
   "source": [
    "experiment_loc = 3\n",
    "\n",
    "# extract and print the top experiment_id\n",
    "experiment_id = df_experiments.iloc[experiment_loc][\"experiment_id\"]\n",
    "print(experiment_id)\n",
    "\n",
    "# extract and print the experiment type\n",
    "experiment_type = df_experiments.iloc[experiment_loc][\"experiment_type\"]\n",
    "print(experiment_type)\n",
    "\n",
    "# extract and print the data model type and data_model name used\n",
    "data_model_types = df_experiments.iloc[experiment_loc][\"data_model_types\"]\n",
    "# convert it to the enum\n",
    "data_model_types = [DataModelType[data_model_type] for data_model_type in json.loads(data_model_types)]\n",
    "data_model_names = [name for name in json.loads(df_experiments.iloc[experiment_loc][\"data_model_names\"])]\n",
    "data_model_descriptions = df_experiments.iloc[experiment_loc][\"data_model_descriptions\"]\n",
    "for data_model_type in data_model_types:\n",
    "    print(data_model_type.name)\n",
    "print(data_model_names)\n",
    "print(data_model_descriptions)\n",
    "\n",
    "# print the experiment name\n",
    "experiment_name = df_experiments.iloc[experiment_loc][\"experiment_name\"]\n",
    "print(experiment_name)\n",
    "\n",
    "# print the experiment problem types\n",
    "experiment_problem_types = df_experiments.iloc[experiment_loc][\"problem_types\"]\n",
    "experiment_problem_types = json.loads(experiment_problem_types)\n",
    "print(experiment_problem_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name for the plots ----\n",
    "data_model_name_dict = {}\n",
    "data_model_name_dict[\"VanillaGaussian\"] = \"Vanilla Gaussian\"\n",
    "data_model_name_dict[\"2_VanillaGaussian\"] = \"Vanilla Gaussian\"\n",
    "data_model_name_dict[\"VanillaGaussianThetaFirst\"] = \"Vanilla Gaussian - Teacher 10:1\"\n",
    "data_model_name_dict[\"VanillaGaussianTimes10\"] = \"Vanilla Gaussian x10\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[10  1]_[1 1]\"] = \"Strong Weak 10:1\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5 1]_[1 1]\"] = \"Strong Weak 5:1\"\n",
    "data_model_name_dict[\"2_KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5 1]_[1 1]\"] = \"Strong Weak 5:1\"\n",
    "data_model_name_dict[\"2_KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[10  1]_[1 1]\"] = \"Strong Weak 10:1\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5 1]_[10  1]\"] = \"Strong Weak 5:1 - Teacher 10:1\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[10  1]_[10  1]\"] = \"Strong Weak 10:1 - Teacher 10:1\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5 1]_[ 1 10]\"] = \"Strong Weak 5:1 - Teacher 1:10\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[10  1]_[ 1 10]\"] = \"Strong Weak 10:1 - Teacher 1:10\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[1 1]_[1 1]_SD_1_1_SU_1_1___RhoNormalisationSweepAllFeatureCombinations\"] = \"Non-Robust Non-Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[5 5]_[5 5]_SD_1_1_SU_1_1___RhoNormalisationSweepAllFeatureCombinations\"] = \"Robust Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[1 1]_[5 5]_SD_1_1_SU_1_1___RhoNormalisationSweepAllFeatureCombinations\"] = \"Non-Robust Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[5 5]_[1 1]_SD_1_1_SU_1_1___RhoNormalisationSweepAllFeatureCombinations\"] = \"Robust Non-Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[1 1]_[1 1]_SD_1_1_SU_1_1\"] = \"Non-Robust Non-Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[5 5]_[5 5]_SD_1_1_SU_1_1\"] = \"Robust Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[1 1]_[5 5]_SD_1_1_SU_1_1\"] = \"Non-Robust Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[5 5]_[1 1]_SD_1_1_SU_1_1\"] = \"Robust Non-Useful\"\n",
    "\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[2 2]_[2 2]_SD_1_1_SU_1_1\"] = \"Robust Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[1 1]_[4 4]_SD_1_1_SU_1_1\"] = \"Non-Robust Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[2 2]_[0.5 0.5]_SD_1_1_SU_1_1\"] = \"Robust Non-Useful\"\n",
    "\n",
    "\n",
    "data_model_name_dict['KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[0.5 0.5]_[2 2]_SD_1_1_SU_1_1'] = \"Non-Robust Non-Useful\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[0.5 0.5]_[8 8]_SD_1_1_SU_1_1\"] = \"Non-Robust Useful\"\n",
    "\n",
    "\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[2.  0.5]_[1 1]_SD_1_1_SU_1_1\"] = \"Invariant Defence\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingFirstStronger_AttackingIdentity_[0.5 0.5]_[2.  0.5]_[1 1]_SD_2_1_SU_1_1\"] = \"Protecting Robust\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[2.  0.5]_[1 1]_SD_1_2_SU_1_1\"] = \"Protecting Non-Robust\"\n",
    "\n",
    "\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5.  0.2]_[1 1]_SD_1_1_SU_1_1\"] = \"Invariant Defence\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingFirstStronger_AttackingIdentity_[0.5 0.5]_[5.  0.2]_[1 1]_SD_2_1_SU_1_1\"] = \"Protecting Robust\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[5.  0.2]_[1 1]_SD_1_2_SU_1_1\"] = \"Protecting Non-Robust\"\n",
    "\n",
    "\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5.  0.2]_[0.2 5. ]_SD_1_1_SU_1_1\"] = \"Invariant Defence\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingFirstStronger_AttackingIdentity_[0.5 0.5]_[5.  0.2]_[0.2 5. ]_SD_2_1_SU_1_1\"] = \"Protecting Robust\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[5.  0.2]_[0.2 5. ]_SD_1_2_SU_1_1\"] = \"Protecting Non-Robust\"\n",
    "\n",
    "# 'KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1.  1.5]_SU_1_1_Sw_[1 1]',\n",
    "#        'KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1.  1.5]_SU_1_1_Sw_[1.5 1. ]',\n",
    "#        'KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1.  1.5]_SU_1_1_Sw_[1.  1.5]'\n",
    "\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1.  1.5]_SU_1_1_Sw_[1 1]\"] = \"Uniform Regularisation\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1.  1.5]_SU_1_1_Sw_[1.5 1. ]\"] = \"Opposite Regularisation\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1.  1.5]_SU_1_1_Sw_[1.  1.5]\"] = \"Same Regularisation\"\n",
    "\n",
    "# KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 5]_SU_1_1_Sw_[1 1]\n",
    "#        'KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 5]_SU_1_1_Sw_[5 1]',\n",
    "#        'KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 5]_SU_1_1_Sw_[1 5]'\n",
    "\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 5]_SU_1_1_Sw_[1 1]\"] = \"Uniform Regularisation\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 5]_SU_1_1_Sw_[5 1]\"] = \"Opposite Regularisation\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 5]_SU_1_1_Sw_[1 5]\"] = \"Same Regularisation\"\n",
    "\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 1]\"] = \"Uniform Regularisation\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[2 1]\"] = \"Opposite Regularisation\"\n",
    "data_model_name_dict[\"KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 2]\"] = \"Same Regularisation\"\n",
    "\n",
    "# 'KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5.  0.2]_[0.2 5. ]_SD_1_1_SU_1_1___Defence Sweep', 'KFeaturesModel_TwoFeatures_ProtectingFirstStronger_AttackingIdentity_[0.5 0.5]_[5.  0.2]_[0.2 5. ]_SD_2_1_SU_1_1___Defence Sweep', 'KFeaturesModel_TwoFeatures_ProtectingSecondStronger_AttackingIdentity_[0.5 0.5]_[5.  0.2]_[0.2 5. ]_SD_1_2_SU_1_1___Defence Sweep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/6t_sjl4j16nd3xx4b0t7wd280000gn/T/ipykernel_42480/3541688095.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  state_evolution[\"subspace_overlaps\"] = state_evolution[\"subspace_overlaps\"].apply(lambda x: str(x))\n",
      "/var/folders/vl/6t_sjl4j16nd3xx4b0t7wd280000gn/T/ipykernel_42480/3541688095.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  state_evolution[\"subspace_overlaps\"] = state_evolution[\"subspace_overlaps\"].apply(lambda x: json.loads(x))\n"
     ]
    }
   ],
   "source": [
    "state_evolution = df_state_evolution[df_state_evolution[\"experiment_id\" ] == experiment_id]\n",
    "gd = df_erm[df_erm[\"experiment_id\" ] == experiment_id]\n",
    "# make the column subspace_overlaps to string\n",
    "state_evolution[\"subspace_overlaps\"] = state_evolution[\"subspace_overlaps\"].apply(lambda x: str(x))\n",
    "gd[\"subspace_overlaps\"] = gd[\"subspace_overlaps\"].apply(lambda x: str(x))\n",
    "\n",
    "# create a json colum\n",
    "state_evolution[\"subspace_overlaps\"] = state_evolution[\"subspace_overlaps\"].apply(lambda x: json.loads(x))\n",
    "gd[\"subspace_overlaps\"] = gd[\"subspace_overlaps\"].apply(lambda x: json.loads(x))\n",
    "from pandas import json_normalize\n",
    "# normalize the json column\n",
    "normalized = json_normalize(state_evolution[\"subspace_overlaps\"])\n",
    "normalized_gd = json_normalize(gd[\"subspace_overlaps\"])\n",
    "\n",
    "\n",
    "\n",
    "def explode_array_column(row, col):\n",
    "    return pd.Series(row[col])\n",
    "\n",
    "# reset the index of the original dataframe\n",
    "state_evolution = state_evolution.reset_index(drop=True)\n",
    "gd = gd.reset_index(drop=True)\n",
    "\n",
    "for col in normalized.columns:\n",
    "    expanded_cols = normalized.apply(lambda x: explode_array_column(x,col), axis=1)\n",
    "    col = col[:-1]\n",
    "    expanded_cols.columns = [col+'_{}'.format(i) for i in range(expanded_cols.shape[1])]\n",
    "    # reset the index of the expanded columns\n",
    "    expanded_cols = expanded_cols.reset_index(drop=True)\n",
    "    state_evolution = pd.concat([state_evolution, expanded_cols], axis=1)\n",
    "\n",
    "for col in normalized_gd.columns:\n",
    "    expanded_cols = normalized_gd.apply(lambda x: explode_array_column(x,col), axis=1)\n",
    "    col = col[:-1]\n",
    "    expanded_cols.columns = [col+'_{}'.format(i) for i in range(expanded_cols.shape[1])]\n",
    "    # reset the index of the expanded columns\n",
    "    expanded_cols = expanded_cols.reset_index(drop=True)\n",
    "\n",
    "    gd = pd.concat([gd, expanded_cols], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_evolution[\"subspace_overlaps_ratio\"] = state_evolution[\"subspace_overlaps_ratio\"].apply(lambda x: str(x))\n",
    "state_evolution[\"subspace_overlaps_ratio\"] = state_evolution[\"subspace_overlaps_ratio\"].apply(lambda x: json.loads(x))\n",
    "normalized = json_normalize(state_evolution[\"subspace_overlaps_ratio\"])\n",
    "# rename the columns of the normalized dataframe\n",
    "for column in normalized.columns:\n",
    "    normalized = normalized.rename(columns={column:column+\"_ratio\"})\n",
    "# merge the normalized dataframe with the original dataframe\n",
    "state_evolution = pd.concat([state_evolution, normalized], axis=1)\n",
    "# drop the original subspace_overlaps column\n",
    "state_evolution = state_evolution.drop(columns=[\"subspace_overlaps_ratio\"])\n",
    "\n",
    "gd[\"subspace_overlaps_ratio\"] = gd[\"subspace_overlaps_ratio\"].apply(lambda x: str(x))\n",
    "gd[\"subspace_overlaps_ratio\"] = gd[\"subspace_overlaps_ratio\"].apply(lambda x: json.loads(x))\n",
    "normalized = json_normalize(gd[\"subspace_overlaps_ratio\"])\n",
    "# rename the columns of the normalized dataframe\n",
    "for column in normalized.columns:\n",
    "    normalized = normalized.rename(columns={column:column+\"_ratio\"})\n",
    "# merge the normalized dataframe with the original dataframe\n",
    "gd = pd.concat([gd, normalized], axis=1)\n",
    "# drop the original subspace_overlaps column\n",
    "gd = gd.drop(columns=[\"subspace_overlaps_ratio\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_mu_usefulness(row):\n",
    "#     rho = row[\"rho\"]\n",
    "#     tau = row[\"tau\"]\n",
    "\n",
    "#     rho = float(rho)\n",
    "#     tau = float(tau)\n",
    "\n",
    "#     return np.sqrt(2 / np.pi) * rho / np.sqrt( rho + tau**2 )\n",
    "\n",
    "# def compute_gamma_robustness(row):\n",
    "#     rho = row[\"rho\"]\n",
    "#     tau = row[\"tau\"]\n",
    "\n",
    "\n",
    "#     rho = float(rho)\n",
    "#     tau = float(tau)\n",
    "\n",
    "#     return np.sqrt(2 / np.pi) * tau / np.sqrt( rho + tau**2 )\n",
    "\n",
    "# def compute_mu_usefulness_ratio(row):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for the difference between the adversarial_generalization_error and the generalization_error for both the state evolution and the erm\n",
    "state_evolution[\"difference_adv_gen\"] = state_evolution[\"adversarial_generalization_error\"] - state_evolution[\"generalization_error\"]\n",
    "gd[\"difference_adv_gen\"] = gd[\"adversarial_generalization_error\"] - gd[\"generalization_error_erm\"]\n",
    "\n",
    "\n",
    "state_evolution[\"ratio_adv_gen\"] = state_evolution[\"adversarial_generalization_error\"] / state_evolution[\"generalization_error\"]\n",
    "gd[\"ratio_adv_gen\"] = gd[\"adversarial_generalization_error\"] / gd[\"generalization_error_erm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for the noise contribution\n",
    "def noise_contribution(rho: float, tau: float) -> float:\n",
    "    if tau == 0:\n",
    "        tau = 1e-10\n",
    "    return 0.5 - np.arctan( np.sqrt( rho / tau**2 ) ) / np.pi\n",
    "\n",
    "state_evolution[\"noise_contribution\"] = state_evolution.apply(lambda x: noise_contribution(x[\"rho\"], x[\"tau\"]), axis=1)\n",
    "gd[\"noise_contribution\"] = gd.apply(lambda x: noise_contribution(x[\"rho\"], x[\"tau\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for the noiseless generalization error without the noise contribution\n",
    "state_evolution[\"noiseless_generalization_error\"] = state_evolution[\"generalization_error\"] - state_evolution[\"noise_contribution\"]\n",
    "gd[\"noiseless_generalization_error_erm\"] = gd[\"generalization_error_erm\"] - gd[\"noise_contribution\"]\n",
    "\n",
    "# create a column for the adversarial noiseless generalization error without the noise contribution\n",
    "state_evolution[\"noiseless_adversarial_generalization_error\"] = state_evolution[\"adversarial_generalization_error\"] - state_evolution[\"noise_contribution\"]\n",
    "gd[\"noiseless_adversarial_generalization_error\"] = gd[\"adversarial_generalization_error\"] - gd[\"noise_contribution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseless_angle_to_generalisation(angle):\n",
    "    return np.arccos(angle) / np.pi\n",
    "\n",
    "state_evolution[\"noiseless_angle_to_generalisation\"] = state_evolution.apply(lambda x: noiseless_angle_to_generalisation(x[\"angle\"]), axis=1)\n",
    "gd[\"noiseless_angle_to_generalisation\"] = gd.apply(lambda x: noiseless_angle_to_generalisation(x[\"angle\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for the A/sqrt(q*N) for both the state evolution and the erm\n",
    "state_evolution[\"A_over_sqrt_qN\"] = state_evolution[\"A\"] / np.sqrt(state_evolution[\"q\"] * state_evolution[\"N\"])\n",
    "gd[\"A_over_sqrt_qN\"] = gd[\"A\"] / np.sqrt(gd[\"q\"] * gd[\"N\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for m/sqrt( rho*q - m**2 ) vs A/sqrt(q*N) for both the state evolution and the erm\n",
    "state_evolution[\"m_over_sqrt_rhoq_minus_m2\"] = state_evolution[\"m\"] / np.sqrt(state_evolution[\"rho\"] * state_evolution[\"q\"] - state_evolution[\"m\"]**2)\n",
    "gd[\"m_over_sqrt_rhoq_minus_m2\"] = gd[\"m\"] / np.sqrt(gd[\"rho\"] * gd[\"q\"] - gd[\"m\"]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip the data_model_name if there is a sequence ___text at the end\n",
    "def strip_data_model_name(data_model_name):\n",
    "    return re.sub(r\"___.*\",\"\",data_model_name)\n",
    "state_evolution[\"data_model_name\"] = state_evolution[\"data_model_name\"].apply(strip_data_model_name)\n",
    "gd[\"data_model_name\"] = gd[\"data_model_name\"].apply(strip_data_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_theta_ratio(data_model_name):\n",
    "    # a typical data_model_name looks like \"\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5 1]_[1. 1.]_SD_1_1_SU_1_1\"\"\n",
    "    # we want to extract the digits in within the last square brackets\n",
    "    theta_part = data_model_name.split(\"[\")[-1].split(\"]\")[0]\n",
    "    # remove any spaces in the end\n",
    "    theta_part = theta_part.strip()\n",
    "    \n",
    "\n",
    "    # concatenate multiple spaces into one space\n",
    "    theta_part = re.sub(r\"\\s+\",\" \",theta_part)\n",
    "\n",
    "    # determine whether the two values are split by \" \" or by \"  \"\n",
    "    if \"  \" in theta_part:\n",
    "        splitter = \"  \"\n",
    "    else:\n",
    "        splitter = \" \"\n",
    "\n",
    "    theta_first = float(theta_part.split(splitter)[0])\n",
    "    theta_second = float(theta_part.split(splitter)[1])\n",
    "    return theta_second # / theta_first  \n",
    "\n",
    "\n",
    "state_evolution[\"theta_ratio\"] = state_evolution[\"data_model_name\"].apply(extract_theta_ratio)\n",
    "gd[\"theta_ratio\"] = gd[\"data_model_name\"].apply(extract_theta_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sigmax_ratio(data_model_name):\n",
    "    # a typical data_model_name looks like \"\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5 1]_[1. 1.]_SD_1_1_SU_1_1\"\"\n",
    "    # we want to extract the digits in within the last square brackets\n",
    "    theta_part = data_model_name.split(\"[\")[-2].split(\"]\")[0]\n",
    "    # remove any spaces in the end\n",
    "    theta_part = theta_part.strip()\n",
    "\n",
    "    # concatenate multiple spaces into one space\n",
    "    theta_part = re.sub(r\"\\s+\",\" \",theta_part)\n",
    "\n",
    "    # determine whether the two values are split by \" \" or by \"  \"\n",
    "    if \"  \" in theta_part:\n",
    "        splitter = \"  \"\n",
    "    else:\n",
    "        splitter = \" \"\n",
    "\n",
    "    theta_first = float(theta_part.split(splitter)[0])\n",
    "    theta_second = float(theta_part.split(splitter)[1])\n",
    "    return theta_first # / theta_second\n",
    "\n",
    "\n",
    "state_evolution[\"sigmax_ratio\"] = state_evolution[\"data_model_name\"].apply(extract_sigmax_ratio)\n",
    "gd[\"sigmax_ratio\"] = gd[\"data_model_name\"].apply(extract_sigmax_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sigmadelta_ratio(data_model_name):\n",
    "    # a typical data_model_name looks like \"\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5 1]_[1. 1.]_SD_1_1_SU_1_1\"\"\n",
    "    # we want to extract the digits after the SD_ only\n",
    "    theta_part = data_model_name.split(\"SD\")[-1].split(\"SU\")[0]\n",
    "    # print(\"Post SD: \", theta_part)\n",
    "\n",
    "\n",
    "    # remove leading _ and ending _\n",
    "    theta_part = theta_part.strip(\"_\")\n",
    "    # print(\"Post strip: \", theta_part)\n",
    "\n",
    "    # concatenate multiple spaces into one space\n",
    "    theta_part = re.sub(r\"\\s+\",\" \",theta_part)\n",
    "\n",
    "    # define the spliter to be \"_\"\n",
    "    splitter = \"_\"\n",
    "\n",
    "    theta_first = float(theta_part.split(splitter)[0])\n",
    "    theta_second = float(theta_part.split(splitter)[1])\n",
    "    # print(\"Theta first: \", theta_first)\n",
    "    # print(\"Theta second: \", theta_second)\n",
    "    return theta_second  #/ theta_first\n",
    "\n",
    "def extract_sigmadelta_scale(data_model_name):\n",
    "    # a typical data_model_name looks like \"\"KFeaturesModel_TwoFeatures_ProtectingIdentity_AttackingIdentity_[0.5 0.5]_[5 1]_[1. 1.]_SD_1_1_SU_1_1\"\"\n",
    "    # we want to extract the digits after the SD_ only\n",
    "    theta_part = data_model_name.split(\"SD\")[-1].split(\"SU\")[0]\n",
    "    # print(\"Post SD: \", theta_part)\n",
    "\n",
    "\n",
    "    # remove leading _ and ending _\n",
    "    theta_part = theta_part.strip(\"_\")\n",
    "    # print(\"Post strip: \", theta_part)\n",
    "\n",
    "    # concatenate multiple spaces into one space\n",
    "    theta_part = re.sub(r\"\\s+\",\" \",theta_part)\n",
    "\n",
    "    # define the spliter to be \"_\"\n",
    "    splitter = \"_\"\n",
    "\n",
    "    theta_first = float(theta_part.split(splitter)[0])\n",
    "    theta_second = float(theta_part.split(splitter)[1])\n",
    "    # print(\"Theta first: \", theta_first)\n",
    "    # print(\"Theta second: \", theta_second)\n",
    "    return theta_first\n",
    "\n",
    "\n",
    "# state_evolution[\"sigmadelta_ratio\"] = state_evolution[\"data_model_name\"].apply(extract_sigmadelta_ratio)\n",
    "# gd[\"sigmadelta_ratio\"] = gd[\"data_model_name\"].apply(extract_sigmadelta_ratio)\n",
    "\n",
    "# state_evolution[\"sigmadelta_scale\"] = state_evolution[\"data_model_name\"].apply(extract_sigmadelta_scale)\n",
    "# gd[\"sigmadelta_scale\"] = gd[\"data_model_name\"].apply(extract_sigmadelta_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">index_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duration_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">generalization_error_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_loss_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_error_state_evolution</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_generalization_error_erm_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_adversarial_generalization_error_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_angle_to_generalisation_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">A_over_sqrt_qN_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">m_over_sqrt_rhoq_minus_m2_erm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>tau</th>\n",
       "      <th>lam</th>\n",
       "      <th>problem_type</th>\n",
       "      <th>attack_epsilon</th>\n",
       "      <th>sigmax_ratio</th>\n",
       "      <th>theta_ratio</th>\n",
       "      <th>data_model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 1]</th>\n",
       "      <td>65015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[2 1]</th>\n",
       "      <td>65477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 2]</th>\n",
       "      <td>66008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 1]</th>\n",
       "      <td>65016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[2 1]</th>\n",
       "      <td>65478.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2.000</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.010</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[2 1]</th>\n",
       "      <td>66036.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.723257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 2]</th>\n",
       "      <td>66540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.685349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.3</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 1]</th>\n",
       "      <td>65500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.602024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[2 1]</th>\n",
       "      <td>66037.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.723257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 2]</th>\n",
       "      <td>66541.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.685349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1584 rows Ã— 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 index_state_evolution  \\\n",
       "                                                                                                                                                  mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                            \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...               65015.0   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...               65477.0   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...               66008.0   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...               65016.0   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...               65478.0   \n",
       "...                                                                                                                                                ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...               66036.0   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...               66540.0   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...               65500.0   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...               66037.0   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...               66541.0   \n",
       "\n",
       "                                                                                                                                      \\\n",
       "                                                                                                                                 std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "...                                                                                                                               ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "\n",
       "                                                                                                                                 duration_state_evolution  \\\n",
       "                                                                                                                                                     mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.939471   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.045371   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.045563   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.939471   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.045371   \n",
       "...                                                                                                                                                   ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.158255   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.156284   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.156897   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.158255   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                 0.156284   \n",
       "\n",
       "                                                                                                                                      \\\n",
       "                                                                                                                                 std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "...                                                                                                                               ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "\n",
       "                                                                                                                                 generalization_error_state_evolution  \\\n",
       "                                                                                                                                                                 mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                                           \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.491990   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.492401   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.492401   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.491990   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.492401   \n",
       "...                                                                                                                                                               ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.176296   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.179420   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.177281   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.176296   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                             0.179420   \n",
       "\n",
       "                                                                                                                                      \\\n",
       "                                                                                                                                 std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "...                                                                                                                               ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "\n",
       "                                                                                                                                 training_loss_state_evolution  \\\n",
       "                                                                                                                                                          mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                                    \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                      0.005260   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                      0.004764   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                      0.004764   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                      0.005260   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                      0.004764   \n",
       "...                                                                                                                                                        ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                      3.723257   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                      3.685349   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                      3.602024   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                      3.723257   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                      3.685349   \n",
       "\n",
       "                                                                                                                                      \\\n",
       "                                                                                                                                 std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "...                                                                                                                               ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "\n",
       "                                                                                                                                 training_error_state_evolution  \\\n",
       "                                                                                                                                                           mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                                     \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000000   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000000   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000000   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000000   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000000   \n",
       "...                                                                                                                                                         ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000123   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000123   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000125   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000123   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                       0.000123   \n",
       "\n",
       "                                                                                                                                      \\\n",
       "                                                                                                                                 std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "...                                                                                                                               ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "\n",
       "                                                                                                                                  ...  \\\n",
       "                                                                                                                                  ...   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                     ...   \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "...                                                                                                                               ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...  ...   \n",
       "\n",
       "                                                                                                                                 noiseless_generalization_error_erm_erm  \\\n",
       "                                                                                                                                                                   mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                                             \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "...                                                                                                                                                                 ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                    NaN   \n",
       "\n",
       "                                                                                                                                      \\\n",
       "                                                                                                                                 std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "...                                                                                                                               ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "\n",
       "                                                                                                                                 noiseless_adversarial_generalization_error_erm  \\\n",
       "                                                                                                                                                                           mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                                                     \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "...                                                                                                                                                                         ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                            NaN   \n",
       "\n",
       "                                                                                                                                      \\\n",
       "                                                                                                                                 std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "...                                                                                                                               ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "\n",
       "                                                                                                                                 noiseless_angle_to_generalisation_erm  \\\n",
       "                                                                                                                                                                  mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                                            \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "...                                                                                                                                                                ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                                   NaN   \n",
       "\n",
       "                                                                                                                                      \\\n",
       "                                                                                                                                 std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "...                                                                                                                               ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "\n",
       "                                                                                                                                 A_over_sqrt_qN_erm  \\\n",
       "                                                                                                                                               mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                         \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "...                                                                                                                                             ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                NaN   \n",
       "\n",
       "                                                                                                                                      \\\n",
       "                                                                                                                                 std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "...                                                                                                                               ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN   \n",
       "\n",
       "                                                                                                                                 m_over_sqrt_rhoq_minus_m2_erm  \\\n",
       "                                                                                                                                                          mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                                                    \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "...                                                                                                                                                        ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection...                           NaN   \n",
       "\n",
       "                                                                                                                                      \n",
       "                                                                                                                                 std  \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon sigmax_ratio theta_ratio data_model_name                                         \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "                                      0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "...                                                                                                                               ..  \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "                                      0.3            1.0          1.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "                                                                              KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "                                                                  2.0         KFeaturesModel_TwoFeatures_NonuniformProtection... NaN  \n",
       "\n",
       "[1584 rows x 214 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd = gd.set_index([\"alpha\",\"epsilon\",\"tau\",\"lam\",\"problem_type\",\"attack_epsilon\",\"sigmax_ratio\",\"theta_ratio\",\"data_model_name\"]) #,\"p_calibration\"\n",
    "state_evolution = state_evolution.set_index([\"alpha\",\"epsilon\",\"tau\",\"lam\",\"problem_type\",\"attack_epsilon\",\"sigmax_ratio\",\"theta_ratio\",\"data_model_name\"]) #,\"p_calibration\"\n",
    "\n",
    "# drop id, code_version, experiment_id, date, initial_condition, test_against_epsilons, calibrations, abs_tol, min_iter,max_iter,blend_fpe,int_lims,subspace_overlaps\n",
    "state_evolution = state_evolution.drop(columns=[\"id\",\"code_version\",\"experiment_id\",\"date\",\"initial_condition\",\"test_against_epsilons\",\"calibrations\",\"abs_tol\",\"min_iter\",\"max_iter\",\"blend_fpe\",\"int_lims\",\"subspace_overlaps\",\"data_model_type\",\"data_model_description\"])\n",
    "# drop id, code_version, experiment_id, test_against_epsilons, date, subspace_overlaps, analytical_calibrations, erm_calibrations, \n",
    "gd = gd.drop(columns=[\"id\",\"code_version\",\"experiment_id\",\"test_against_epsilons\",\"date\",\"subspace_overlaps\",\"analytical_calibrations\",\"erm_calibrations\",\"data_model_type\",\"data_model_description\"])\n",
    "\n",
    "state_evolution.columns = [col+\"_state_evolution\" for col in state_evolution.columns]\n",
    "gd.columns = [col+\"_erm\" for col in gd.columns]\n",
    "\n",
    "state_evolution = state_evolution.groupby(level=[0,1,2,3,4,5,6,7,8]).agg([\"mean\",\"std\"]) #,4\n",
    "gd = gd.groupby(level=[0,1,2,3,4,5,6,7,8]).agg([\"mean\",\"std\"]) #,4\n",
    "df = state_evolution.join(gd, how=\"outer\")\n",
    "df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_rho_norm_usefulness(row):\n",
    "#     # extract sigmax_ratio from the index\n",
    "#     sigmax_ratio = row[\"sigmax_ratio\"]\n",
    "#     sigmatheta_ratio = row[\"theta_ratio\"]\n",
    "\n",
    "#     sigmax_ratio = float(sigmax_ratio)\n",
    "#     sigmatheta_ratio = float(sigmatheta_ratio)\n",
    "\n",
    "#     norm = (sigmax_ratio + sigmatheta_ratio**2) * 0.5\n",
    "\n",
    "#     subspace_rho_1 = sigmax_ratio / (2 * norm)\n",
    "\n",
    "#     usefulness = subspace_rho_1 / ( 1 - subspace_rho_1 )\n",
    "\n",
    "#     subspace_rho_2 = sigmatheta_ratio**2 / (2*norm)\n",
    "\n",
    "#     assert subspace_rho_1 + subspace_rho_2 - 1 < 1e-5, \"Subspace rho 1 and 2 should sum to 1 but they are {} and {}\".format(subspace_rho_1, subspace_rho_2)\n",
    "\n",
    "\n",
    "#     return usefulness\n",
    "\n",
    "# def extract_trace_norm_usefulness(row):\n",
    "#     sigmax_ratio = row[\"sigmax_ratio\"]\n",
    "#     sigmatheta_ratio = row[\"theta_ratio\"]\n",
    "#     rho = row[\"rho_state_evolution\"][\"mean\"]\n",
    "\n",
    "#     sigmax_ratio = float(sigmax_ratio)\n",
    "#     sigmatheta_ratio = float(sigmatheta_ratio)\n",
    "#     rho = float(rho)\n",
    "\n",
    "#     norm = (1/4) * (1 + sigmax_ratio) * ( 1 + sigmatheta_ratio**2)\n",
    "\n",
    "#     subspace_1 = 0.5 * sigmax_ratio / norm\n",
    "#     subspace_2 = 0.5 * sigmatheta_ratio**2 / norm\n",
    "\n",
    "#     # assert subspace_1 + subspace_2 - rho < 1e-5, \"Subspace rho 1 and 2 should sum to 1 but they are {} and {}\".format(subspace_1, subspace_2)\n",
    "\n",
    "#     usefulness = subspace_1 / ( rho - subspace_1 )\n",
    "\n",
    "#     return usefulness\n",
    "\n",
    "# def extract_relative_usefulness(row):\n",
    "#     sigmax_ratio = row[\"sigmax_ratio\"]\n",
    "#     sigmatheta_ratio = row[\"theta_ratio\"]\n",
    "\n",
    "#     sigmax_ratio = float(sigmax_ratio)\n",
    "#     sigmatheta_ratio = float(sigmatheta_ratio)\n",
    "\n",
    "#     return sigmax_ratio / sigmatheta_ratio**2\n",
    "\n",
    "# def extract_usefulness(row):\n",
    "#     rho = row[\"rho_state_evolution\"][\"mean\"]\n",
    "#     rho = float(rho)\n",
    "#     return rho\n",
    "\n",
    "\n",
    "# df2 = df.reset_index()\n",
    "\n",
    "\n",
    "# df2[\"total_usefulness\"] = df2.apply(extract_usefulness, axis=1)\n",
    "\n",
    "# # # apply mean and std to the new column\n",
    "# # df_result = df2[\"total_usefulness\"].apply(lambda x: pd.Series({\"mean\":x, \"std\":0}))\n",
    "# # multiindex = pd.MultiIndex.from_product([['total_usefulness'], ['mean', 'std']], names=['', ''])\n",
    "# # df_result.columns = multiindex\n",
    "# # # Concatenate the original DataFrame with the computed values DataFrame\n",
    "# # df2 = pd.concat([df2, df_result], axis=1)\n",
    "\n",
    "\n",
    "# df2[\"rho_usefulness\"] = df2.apply(extract_rho_norm_usefulness, axis=1)\n",
    "\n",
    "\n",
    "# # apply mean and std to the new column\n",
    "# df_result = df2[\"rho_usefulness\"].apply(lambda x: pd.Series({\"mean\":x, \"std\":0}))\n",
    "# multiindex = pd.MultiIndex.from_product([['rho_usefulness'], ['mean', 'std']], names=['', ''])\n",
    "# df_result.columns = multiindex\n",
    "# # Concatenate the original DataFrame with the computed values DataFrame\n",
    "# df2 = pd.concat([df2, df_result], axis=1)\n",
    "\n",
    "# df2[\"trace_usefulness\"] = df2.apply(extract_trace_norm_usefulness, axis=1)\n",
    "\n",
    "# # apply mean and std to the new column\n",
    "# df_result = df2[\"trace_usefulness\"].apply(lambda x: pd.Series({\"mean\":x, \"std\":0}))\n",
    "# multiindex = pd.MultiIndex.from_product([['trace_usefulness'], ['mean', 'std']], names=['', ''])\n",
    "# df_result.columns = multiindex\n",
    "# # Concatenate the original DataFrame with the computed values DataFrame\n",
    "# df2 = pd.concat([df2, df_result], axis=1)\n",
    "\n",
    "# df2[\"relative_usefulness\"] = df2.apply(extract_relative_usefulness, axis=1)\n",
    "\n",
    "# # apply mean and std to the new column\n",
    "# # df_result = df2[\"relative_usefulness\"].apply(lambda x: pd.Series({\"mean\":x, \"std\":0}))\n",
    "# # multiindex = pd.MultiIndex.from_product([['relative_usefulness'], ['mean', 'std']], names=['', ''])\n",
    "# # df_result.columns = multiindex\n",
    "# # Concatenate the original DataFrame with the computed values DataFrame\n",
    "# df2 = pd.concat([df2, df_result], axis=1)\n",
    "\n",
    "# # # apply mean and std to the column \"theta_ratio\"\n",
    "# # df_result = df2[\"theta_ratio\"].apply(lambda x: pd.Series({\"mean\":x, \"std\":0}))\n",
    "# # multiindex = pd.MultiIndex.from_product([['theta_ratio'], ['mean', 'std']], names=['', ''])\n",
    "# # df_result.columns = multiindex\n",
    "# # # Concatenate the original DataFrame with the computed values DataFrame\n",
    "# # df2 = pd.concat([df2, df_result], axis=1)\n",
    "\n",
    "# # df_result = df2[\"sigmax_ratio\"].apply(lambda x: pd.Series({\"mean\":x, \"std\":0}))\n",
    "# # multiindex = pd.MultiIndex.from_product([['sigmax_ratio'], ['mean', 'std']], names=['', ''])\n",
    "# # df_result.columns = multiindex\n",
    "# # # Concatenate the original DataFrame with the computed values DataFrame\n",
    "# # df2 = pd.concat([df2, df_result], axis=1)\n",
    "\n",
    "\n",
    "# # set all quantities from the df index in df2 as index\n",
    "# # df = df2.set_index([\"alpha\",\"epsilon\",\"tau\",\"lam\",\"problem_type\",\"attack_epsilon\",\"sigmax_ratio\",\"sigmadelta_ratio\",\"relative_usefulness\",\"data_model_name\"]) #,\"p_calibration\"\n",
    "# # df = df2.set_index([\"alpha\",\"epsilon\",\"tau\",\"lam\",\"problem_type\",\"attack_epsilon\",\"sigmax_ratio\",\"sigmadelta_ratio\",\"total_usefulness\",\"data_model_name\"]) \n",
    "# df = df2.set_index([\"alpha\",\"epsilon\",\"tau\",\"lam\",\"problem_type\",\"attack_epsilon\",\"theta_ratio\",\"sigmax_ratio\",\"sigmadelta_ratio\",\"total_usefulness\",\"data_model_name\"]) #,\"p_calibration\"\n",
    "\n",
    "\n",
    "# # sort index\n",
    "# df.sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 1]',\n",
       "       'KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[2 1]',\n",
       "       'KFeaturesModel_TwoFeatures_NonuniformProtection_[0.5 0.5]_[1 1]_[1 1]_SD_[1 2]_SU_1_1_Sw_[1 2]'],\n",
       "      dtype='object', name='data_model_name')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.get_level_values(\"data_model_name\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">index_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duration_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">generalization_error_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_loss_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_error_state_evolution</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_generalization_error_erm_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_adversarial_generalization_error_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_angle_to_generalisation_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">A_over_sqrt_qN_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">m_over_sqrt_rhoq_minus_m2_erm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>tau</th>\n",
       "      <th>lam</th>\n",
       "      <th>problem_type</th>\n",
       "      <th>attack_epsilon</th>\n",
       "      <th>theta_ratio</th>\n",
       "      <th>sigmax_ratio</th>\n",
       "      <th>data_model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Opposite Regularisation</th>\n",
       "      <td>65477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniform Regularisation</th>\n",
       "      <td>65015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>Same Regularisation</th>\n",
       "      <td>66008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Opposite Regularisation</th>\n",
       "      <td>65478.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniform Regularisation</th>\n",
       "      <td>65016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2.000</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.010</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>Uniform Regularisation</th>\n",
       "      <td>65499.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.602024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>Same Regularisation</th>\n",
       "      <td>66540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.685349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Opposite Regularisation</th>\n",
       "      <td>66037.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.723257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniform Regularisation</th>\n",
       "      <td>65500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.602024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>Same Regularisation</th>\n",
       "      <td>66541.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.685349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1584 rows Ã— 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      index_state_evolution  \\\n",
       "                                                                                                                       mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                 \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation               65477.0   \n",
       "                                                                              Uniform Regularisation                65015.0   \n",
       "                                                     2.0         1.0          Same Regularisation                   66008.0   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation               65478.0   \n",
       "                                                                              Uniform Regularisation                65016.0   \n",
       "...                                                                                                                     ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                65499.0   \n",
       "                                                     2.0         1.0          Same Regularisation                   66540.0   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation               66037.0   \n",
       "                                                                              Uniform Regularisation                65500.0   \n",
       "                                                     2.0         1.0          Same Regularisation                   66541.0   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      duration_state_evolution  \\\n",
       "                                                                                                                          mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                    \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation                 0.045371   \n",
       "                                                                              Uniform Regularisation                  0.939471   \n",
       "                                                     2.0         1.0          Same Regularisation                     0.045563   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation                 0.045371   \n",
       "                                                                              Uniform Regularisation                  0.939471   \n",
       "...                                                                                                                        ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                  0.156897   \n",
       "                                                     2.0         1.0          Same Regularisation                     0.156284   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation                 0.158255   \n",
       "                                                                              Uniform Regularisation                  0.156897   \n",
       "                                                     2.0         1.0          Same Regularisation                     0.156284   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      generalization_error_state_evolution  \\\n",
       "                                                                                                                                      mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                                \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation                             0.492401   \n",
       "                                                                              Uniform Regularisation                              0.491990   \n",
       "                                                     2.0         1.0          Same Regularisation                                 0.492401   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation                             0.492401   \n",
       "                                                                              Uniform Regularisation                              0.491990   \n",
       "...                                                                                                                                    ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                              0.177281   \n",
       "                                                     2.0         1.0          Same Regularisation                                 0.179420   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation                             0.176296   \n",
       "                                                                              Uniform Regularisation                              0.177281   \n",
       "                                                     2.0         1.0          Same Regularisation                                 0.179420   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      training_loss_state_evolution  \\\n",
       "                                                                                                                               mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                         \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation                      0.004764   \n",
       "                                                                              Uniform Regularisation                       0.005260   \n",
       "                                                     2.0         1.0          Same Regularisation                          0.004764   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation                      0.004764   \n",
       "                                                                              Uniform Regularisation                       0.005260   \n",
       "...                                                                                                                             ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                       3.602024   \n",
       "                                                     2.0         1.0          Same Regularisation                          3.685349   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation                      3.723257   \n",
       "                                                                              Uniform Regularisation                       3.602024   \n",
       "                                                     2.0         1.0          Same Regularisation                          3.685349   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      training_error_state_evolution  \\\n",
       "                                                                                                                                mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation                       0.000000   \n",
       "                                                                              Uniform Regularisation                        0.000000   \n",
       "                                                     2.0         1.0          Same Regularisation                           0.000000   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation                       0.000000   \n",
       "                                                                              Uniform Regularisation                        0.000000   \n",
       "...                                                                                                                              ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                        0.000125   \n",
       "                                                     2.0         1.0          Same Regularisation                           0.000123   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation                       0.000123   \n",
       "                                                                              Uniform Regularisation                        0.000125   \n",
       "                                                     2.0         1.0          Same Regularisation                           0.000123   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                       ...  \\\n",
       "                                                                                                       ...   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name          ...   \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation  ...   \n",
       "                                                                              Uniform Regularisation   ...   \n",
       "                                                     2.0         1.0          Same Regularisation      ...   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation  ...   \n",
       "                                                                              Uniform Regularisation   ...   \n",
       "...                                                                                                    ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation   ...   \n",
       "                                                     2.0         1.0          Same Regularisation      ...   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation  ...   \n",
       "                                                                              Uniform Regularisation   ...   \n",
       "                                                     2.0         1.0          Same Regularisation      ...   \n",
       "\n",
       "                                                                                                      noiseless_generalization_error_erm_erm  \\\n",
       "                                                                                                                                        mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                                  \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation                                    NaN   \n",
       "                                                                              Uniform Regularisation                                     NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                        NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation                                    NaN   \n",
       "                                                                              Uniform Regularisation                                     NaN   \n",
       "...                                                                                                                                      ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                                     NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                        NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation                                    NaN   \n",
       "                                                                              Uniform Regularisation                                     NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                        NaN   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      noiseless_adversarial_generalization_error_erm  \\\n",
       "                                                                                                                                                mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation                                            NaN   \n",
       "                                                                              Uniform Regularisation                                             NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                                NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation                                            NaN   \n",
       "                                                                              Uniform Regularisation                                             NaN   \n",
       "...                                                                                                                                              ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                                             NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                                NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation                                            NaN   \n",
       "                                                                              Uniform Regularisation                                             NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                                NaN   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      noiseless_angle_to_generalisation_erm  \\\n",
       "                                                                                                                                       mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                                 \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation                                   NaN   \n",
       "                                                                              Uniform Regularisation                                    NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                       NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation                                   NaN   \n",
       "                                                                              Uniform Regularisation                                    NaN   \n",
       "...                                                                                                                                     ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                                    NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                       NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation                                   NaN   \n",
       "                                                                              Uniform Regularisation                                    NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                       NaN   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      A_over_sqrt_qN_erm  \\\n",
       "                                                                                                                    mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                              \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation                NaN   \n",
       "                                                                              Uniform Regularisation                 NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                    NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation                NaN   \n",
       "                                                                              Uniform Regularisation                 NaN   \n",
       "...                                                                                                                  ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                 NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                    NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation                NaN   \n",
       "                                                                              Uniform Regularisation                 NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                    NaN   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                                              Uniform Regularisation  NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      m_over_sqrt_rhoq_minus_m2_erm  \\\n",
       "                                                                                                                               mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                         \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation                           NaN   \n",
       "                                                                              Uniform Regularisation                            NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                               NaN   \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation                           NaN   \n",
       "                                                                              Uniform Regularisation                            NaN   \n",
       "...                                                                                                                             ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation                            NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                               NaN   \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation                           NaN   \n",
       "                                                                              Uniform Regularisation                            NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                               NaN   \n",
       "\n",
       "                                                                                                           \n",
       "                                                                                                      std  \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name              \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Opposite Regularisation NaN  \n",
       "                                                                              Uniform Regularisation  NaN  \n",
       "                                                     2.0         1.0          Same Regularisation     NaN  \n",
       "                                      0.2            1.0         1.0          Opposite Regularisation NaN  \n",
       "                                                                              Uniform Regularisation  NaN  \n",
       "...                                                                                                    ..  \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Uniform Regularisation  NaN  \n",
       "                                                     2.0         1.0          Same Regularisation     NaN  \n",
       "                                      0.3            1.0         1.0          Opposite Regularisation NaN  \n",
       "                                                                              Uniform Regularisation  NaN  \n",
       "                                                     2.0         1.0          Same Regularisation     NaN  \n",
       "\n",
       "[1584 rows x 214 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # try replacing data_model_name in df with data_model_name_dict\n",
    "df = df.reset_index()\n",
    "df[\"data_model_name\"] = df[\"data_model_name\"].apply(lambda x: data_model_name_dict[x])\n",
    "df = df.set_index([\"alpha\",\"epsilon\",\"tau\",\"lam\",\"problem_type\",\"attack_epsilon\",\"theta_ratio\",\"sigmax_ratio\",\"data_model_name\"]) #,\"p_calibration\"\n",
    "df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lambdas = load_csv_to_object_dictionary(OptimalLambdaResult(0,0,0,0,None,None,None),path=\"experiments/\")\n",
    "def extract_optimal_lambda(alpha, epsilon, tau, data_model_type, data_model_name, problem_type):\n",
    "    # extract or compute optimal lamba and plot it as a vertical line\n",
    "    optimal_result = OptimalLambdaResult(alpha,epsilon,tau,1,data_model_type,data_model_name, problem_type)\n",
    "    if optimal_result.get_key() in optimal_lambdas:\n",
    "        optimal_lambda = optimal_lambdas[optimal_result.get_key()]\n",
    "        return optimal_lambda\n",
    "    else:   \n",
    "        print(\"Optimal lambda not found for \", optimal_result.get_key())\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Uniform Regularisation', 'Opposite Regularisation',\n",
       "       'Same Regularisation'],\n",
       "      dtype='object', name='data_model_name')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract unique data_model_name from index\n",
    "data_model_names = df.index.get_level_values(\"data_model_name\").unique()\n",
    "data_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataframe as a pickle file\n",
    "if not os.path.exists(\"Pickles\"):\n",
    "    os.makedirs(\"Pickles\")\n",
    "if not os.path.exists(\"Pickles/defence_sweep.pkl\"):\n",
    "    df.to_pickle(\"Pickles/defence_sweep.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickle\n",
    "# df = pd.read_pickle(\"Pickles/defence_sweep.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">index_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duration_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">generalization_error_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_loss_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_error_state_evolution</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_generalization_error_erm_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_adversarial_generalization_error_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_angle_to_generalisation_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">A_over_sqrt_qN_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">m_over_sqrt_rhoq_minus_m2_erm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>tau</th>\n",
       "      <th>lam</th>\n",
       "      <th>problem_type</th>\n",
       "      <th>attack_epsilon</th>\n",
       "      <th>theta_ratio</th>\n",
       "      <th>sigmax_ratio</th>\n",
       "      <th>data_model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Uniform Regularisation</th>\n",
       "      <td>65015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opposite Regularisation</th>\n",
       "      <td>65477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>Same Regularisation</th>\n",
       "      <td>66008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Uniform Regularisation</th>\n",
       "      <td>65016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opposite Regularisation</th>\n",
       "      <td>65478.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2.000</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.010</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>Opposite Regularisation</th>\n",
       "      <td>66036.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.723257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>Same Regularisation</th>\n",
       "      <td>66540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.685349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Uniform Regularisation</th>\n",
       "      <td>65500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.602024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opposite Regularisation</th>\n",
       "      <td>66037.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.723257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>Same Regularisation</th>\n",
       "      <td>66541.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.685349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1584 rows Ã— 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      index_state_evolution  \\\n",
       "                                                                                                                       mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                 \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                65015.0   \n",
       "                                                                              Opposite Regularisation               65477.0   \n",
       "                                                     2.0         1.0          Same Regularisation                   66008.0   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                65016.0   \n",
       "                                                                              Opposite Regularisation               65478.0   \n",
       "...                                                                                                                     ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation               66036.0   \n",
       "                                                     2.0         1.0          Same Regularisation                   66540.0   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                65500.0   \n",
       "                                                                              Opposite Regularisation               66037.0   \n",
       "                                                     2.0         1.0          Same Regularisation                   66541.0   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      duration_state_evolution  \\\n",
       "                                                                                                                          mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                    \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                  0.939471   \n",
       "                                                                              Opposite Regularisation                 0.045371   \n",
       "                                                     2.0         1.0          Same Regularisation                     0.045563   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                  0.939471   \n",
       "                                                                              Opposite Regularisation                 0.045371   \n",
       "...                                                                                                                        ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation                 0.158255   \n",
       "                                                     2.0         1.0          Same Regularisation                     0.156284   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                  0.156897   \n",
       "                                                                              Opposite Regularisation                 0.158255   \n",
       "                                                     2.0         1.0          Same Regularisation                     0.156284   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      generalization_error_state_evolution  \\\n",
       "                                                                                                                                      mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                                \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                              0.491990   \n",
       "                                                                              Opposite Regularisation                             0.492401   \n",
       "                                                     2.0         1.0          Same Regularisation                                 0.492401   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                              0.491990   \n",
       "                                                                              Opposite Regularisation                             0.492401   \n",
       "...                                                                                                                                    ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation                             0.176296   \n",
       "                                                     2.0         1.0          Same Regularisation                                 0.179420   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                              0.177281   \n",
       "                                                                              Opposite Regularisation                             0.176296   \n",
       "                                                     2.0         1.0          Same Regularisation                                 0.179420   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      training_loss_state_evolution  \\\n",
       "                                                                                                                               mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                         \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                       0.005260   \n",
       "                                                                              Opposite Regularisation                      0.004764   \n",
       "                                                     2.0         1.0          Same Regularisation                          0.004764   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                       0.005260   \n",
       "                                                                              Opposite Regularisation                      0.004764   \n",
       "...                                                                                                                             ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation                      3.723257   \n",
       "                                                     2.0         1.0          Same Regularisation                          3.685349   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                       3.602024   \n",
       "                                                                              Opposite Regularisation                      3.723257   \n",
       "                                                     2.0         1.0          Same Regularisation                          3.685349   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      training_error_state_evolution  \\\n",
       "                                                                                                                                mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                        0.000000   \n",
       "                                                                              Opposite Regularisation                       0.000000   \n",
       "                                                     2.0         1.0          Same Regularisation                           0.000000   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                        0.000000   \n",
       "                                                                              Opposite Regularisation                       0.000000   \n",
       "...                                                                                                                              ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation                       0.000123   \n",
       "                                                     2.0         1.0          Same Regularisation                           0.000123   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                        0.000125   \n",
       "                                                                              Opposite Regularisation                       0.000123   \n",
       "                                                     2.0         1.0          Same Regularisation                           0.000123   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                       ...  \\\n",
       "                                                                                                       ...   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name          ...   \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation   ...   \n",
       "                                                                              Opposite Regularisation  ...   \n",
       "                                                     2.0         1.0          Same Regularisation      ...   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation   ...   \n",
       "                                                                              Opposite Regularisation  ...   \n",
       "...                                                                                                    ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation  ...   \n",
       "                                                     2.0         1.0          Same Regularisation      ...   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation   ...   \n",
       "                                                                              Opposite Regularisation  ...   \n",
       "                                                     2.0         1.0          Same Regularisation      ...   \n",
       "\n",
       "                                                                                                      noiseless_generalization_error_erm_erm  \\\n",
       "                                                                                                                                        mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                                  \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                                     NaN   \n",
       "                                                                              Opposite Regularisation                                    NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                        NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                                     NaN   \n",
       "                                                                              Opposite Regularisation                                    NaN   \n",
       "...                                                                                                                                      ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation                                    NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                        NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                                     NaN   \n",
       "                                                                              Opposite Regularisation                                    NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                        NaN   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      noiseless_adversarial_generalization_error_erm  \\\n",
       "                                                                                                                                                mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                                          \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                                             NaN   \n",
       "                                                                              Opposite Regularisation                                            NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                                NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                                             NaN   \n",
       "                                                                              Opposite Regularisation                                            NaN   \n",
       "...                                                                                                                                              ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation                                            NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                                NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                                             NaN   \n",
       "                                                                              Opposite Regularisation                                            NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                                NaN   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      noiseless_angle_to_generalisation_erm  \\\n",
       "                                                                                                                                       mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                                 \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                                    NaN   \n",
       "                                                                              Opposite Regularisation                                   NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                       NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                                    NaN   \n",
       "                                                                              Opposite Regularisation                                   NaN   \n",
       "...                                                                                                                                     ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation                                   NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                       NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                                    NaN   \n",
       "                                                                              Opposite Regularisation                                   NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                                       NaN   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      A_over_sqrt_qN_erm  \\\n",
       "                                                                                                                    mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                              \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                 NaN   \n",
       "                                                                              Opposite Regularisation                NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                    NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                 NaN   \n",
       "                                                                              Opposite Regularisation                NaN   \n",
       "...                                                                                                                  ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation                NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                    NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                 NaN   \n",
       "                                                                              Opposite Regularisation                NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                    NaN   \n",
       "\n",
       "                                                                                                           \\\n",
       "                                                                                                      std   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name               \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "...                                                                                                    ..   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN   \n",
       "                                                                              Opposite Regularisation NaN   \n",
       "                                                     2.0         1.0          Same Regularisation     NaN   \n",
       "\n",
       "                                                                                                      m_over_sqrt_rhoq_minus_m2_erm  \\\n",
       "                                                                                                                               mean   \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name                                         \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation                            NaN   \n",
       "                                                                              Opposite Regularisation                           NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                               NaN   \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation                            NaN   \n",
       "                                                                              Opposite Regularisation                           NaN   \n",
       "...                                                                                                                             ...   \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation                           NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                               NaN   \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation                            NaN   \n",
       "                                                                              Opposite Regularisation                           NaN   \n",
       "                                                     2.0         1.0          Same Regularisation                               NaN   \n",
       "\n",
       "                                                                                                           \n",
       "                                                                                                      std  \n",
       "alpha epsilon tau  lam   problem_type attack_epsilon theta_ratio sigmax_ratio data_model_name              \n",
       "0.001 0.0     0.05 0.001 Logistic     0.1            1.0         1.0          Uniform Regularisation  NaN  \n",
       "                                                                              Opposite Regularisation NaN  \n",
       "                                                     2.0         1.0          Same Regularisation     NaN  \n",
       "                                      0.2            1.0         1.0          Uniform Regularisation  NaN  \n",
       "                                                                              Opposite Regularisation NaN  \n",
       "...                                                                                                    ..  \n",
       "2.000 0.3     0.05 0.010 Logistic     0.2            1.0         1.0          Opposite Regularisation NaN  \n",
       "                                                     2.0         1.0          Same Regularisation     NaN  \n",
       "                                      0.3            1.0         1.0          Uniform Regularisation  NaN  \n",
       "                                                                              Opposite Regularisation NaN  \n",
       "                                                     2.0         1.0          Same Regularisation     NaN  \n",
       "\n",
       "[1584 rows x 214 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 0.001, 0.0014, 0.0021,  0.003, 0.0043, 0.0061, 0.0088, 0.0126, 0.0181,\n",
       "        0.026, 0.0373, 0.0536,  0.077, 0.1105, 0.1587,  0.228, 0.3274, 0.4702,\n",
       "       0.6752, 0.9697, 1.3926,    2.0],\n",
       "      dtype='float64', name='alpha')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract unique epsilons\n",
    "epsilons = df.index.get_level_values(\"epsilon\").unique()\n",
    "epsilons\n",
    "\n",
    "alphas = df.index.get_level_values(\"alpha\").unique()\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0.001, 0.01], dtype='float64', name='lam')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_params = df.index.get_level_values(\"lam\").unique()\n",
    "reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.3, 0.2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defence_eps = df.index.get_level_values(\"epsilon\").unique()\n",
    "attack_eps = df.index.get_level_values(\"attack_epsilon\").unique()\n",
    "\n",
    "common_eps = list(set(defence_eps).intersection(attack_eps))\n",
    "common_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Uniform Regularisation', 'Opposite Regularisation',\n",
       "       'Same Regularisation'],\n",
       "      dtype='object', name='data_model_name')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_names = df.index.get_level_values(\"data_model_name\").unique()\n",
    "data_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(                         'index_state_evolution', 'mean'),\n",
       "            (                         'index_state_evolution',  'std'),\n",
       "            (                      'duration_state_evolution', 'mean'),\n",
       "            (                      'duration_state_evolution',  'std'),\n",
       "            (          'generalization_error_state_evolution', 'mean'),\n",
       "            (          'generalization_error_state_evolution',  'std'),\n",
       "            (                 'training_loss_state_evolution', 'mean'),\n",
       "            (                 'training_loss_state_evolution',  'std'),\n",
       "            (                'training_error_state_evolution', 'mean'),\n",
       "            (                'training_error_state_evolution',  'std'),\n",
       "            ...\n",
       "            (        'noiseless_generalization_error_erm_erm', 'mean'),\n",
       "            (        'noiseless_generalization_error_erm_erm',  'std'),\n",
       "            ('noiseless_adversarial_generalization_error_erm', 'mean'),\n",
       "            ('noiseless_adversarial_generalization_error_erm',  'std'),\n",
       "            (         'noiseless_angle_to_generalisation_erm', 'mean'),\n",
       "            (         'noiseless_angle_to_generalisation_erm',  'std'),\n",
       "            (                            'A_over_sqrt_qN_erm', 'mean'),\n",
       "            (                            'A_over_sqrt_qN_erm',  'std'),\n",
       "            (                 'm_over_sqrt_rhoq_minus_m2_erm', 'mean'),\n",
       "            (                 'm_over_sqrt_rhoq_minus_m2_erm',  'std')],\n",
       "           length=214)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "\n",
    "for data_model_name in data_model_names:\n",
    "\n",
    "    df_data_model = df.xs(data_model_name, level=\"data_model_name\")\n",
    "\n",
    "    eps_dict = {}\n",
    "\n",
    "    for e in common_eps:\n",
    "        \n",
    "        eps_df = df_data_model.xs((e, e, 0.001), level=[\"epsilon\", \"attack_epsilon\", \"lam\"])\n",
    "\n",
    "        alphas = eps_df.index.get_level_values(\"alpha\").unique()\n",
    "        adversarial_error_0 = eps_df[\"adversarial_generalization_error_state_evolution\"][\"mean\"].values\n",
    "        generalization_error_0 = eps_df[\"generalization_error_state_evolution\"][\"mean\"].values\n",
    "        boundary_error_0 = eps_df[\"difference_adv_gen_state_evolution\"][\"mean\"].values\n",
    "        # class_preserving = eps_df[\"fair_adversarial_error_state_evolution\"][\"mean\"].values\n",
    "        training_error_0 = eps_df[\"training_error_state_evolution\"][\"mean\"].values\n",
    "\n",
    "        alphas = np.array(alphas)\n",
    "        adversarial_error_0 = np.array(adversarial_error_0)\n",
    "        generalization_error_0 = np.array(generalization_error_0)\n",
    "        boundary_error_0 = np.array(boundary_error_0)\n",
    "\n",
    "        eps_0_dict = {}\n",
    "        eps_0_dict[\"alphas\"] = alphas\n",
    "        eps_0_dict[\"adversarial_error\"] = adversarial_error_0\n",
    "        eps_0_dict[\"generalization_error\"] = generalization_error_0\n",
    "        eps_0_dict[\"boundary_error\"] = boundary_error_0\n",
    "        eps_0_dict[\"training_error\"] = training_error_0\n",
    "\n",
    "        eps_dict[e] = eps_0_dict\n",
    "\n",
    "\n",
    "    df_dict[data_model_name] = eps_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dict['Uniform Regularisation'][0.1][\"adversarial_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_DIRECTORY = \"./Assets/different_w\"\n",
    "if not os.path.exists(IMG_DIRECTORY):\n",
    "    os.makedirs(IMG_DIRECTORY)\n",
    "\n",
    "\n",
    "def save_plot(fig, name, formats=[\"pdf\",\"jpg\"], date=False):\n",
    "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    for f in formats:        \n",
    "        path = \"{}\".format(name) + \"_{}\".format(current_date) + \".\" + f\n",
    "        if not date:\n",
    "            path = \"{}\".format(name) + \".\" + f\n",
    "        fig.savefig(            \n",
    "            os.path.join(IMG_DIRECTORY, path),\n",
    "            format=f,\n",
    "        )\n",
    "\n",
    "\n",
    "def set_size(width, fraction=1, subplots=(1, 1)):\n",
    "    if width == \"thesis\":\n",
    "        width_pt = 426.79135\n",
    "    elif width == \"beamer\":\n",
    "        width_pt = 307.28987\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    golden_ratio = (5**0.5 - 1) / 2\n",
    "\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    fig_height_in = fig_width_in * (golden_ratio) * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 317.309x196.108 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# width = 2.5 * 458.63788\n",
    "\n",
    "width = 458.63788\n",
    "\n",
    "plt.style.use(\"../latex_ready.mplstyle\")\n",
    "\n",
    "tuple_size = set_size(width, fraction=0.5, subplots=(1, 1))\n",
    "# tuple_size = (3 * 8.5 / 4, 2.4)\n",
    "\n",
    "multiplier = 1.25\n",
    "second_multiplier = 0.6\n",
    "\n",
    "# import Line2D for custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    figsize=(tuple_size[0], tuple_size[1]),\n",
    "    gridspec_kw={\"hspace\": 0, \"wspace\": 0},\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(left=0.15, right=0.95, top=0.95, bottom=0.15)\n",
    "\n",
    "# Create a custom legend\n",
    "custom_legend = []\n",
    "linestyles = [\"solid\", \"dashed\", \"dashdot\", \"dotted\"]\n",
    "\n",
    "for df_idx, (key, value) in enumerate(df_dict.items()):\n",
    "\n",
    "    data_model_name = key\n",
    "\n",
    "    for idx, (epsilon, eps_dict) in enumerate(value.items()):\n",
    "        if epsilon == 0.4:\n",
    "            continue\n",
    "\n",
    "        alphas = eps_dict[\"alphas\"]\n",
    "        adversarial_error = eps_dict[\"adversarial_error\"]\n",
    "        generalization_error = eps_dict[\"generalization_error\"]\n",
    "        boundary_error = eps_dict[\"boundary_error\"]\n",
    "        tra = eps_dict[\"training_error\"]\n",
    "\n",
    "        adversarial_lines = ax.plot(\n",
    "            alphas, adversarial_error, linestyle=linestyles[df_idx], color=f\"C{idx}\"\n",
    "        )\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(r\"$E_{\\mathrm{adv}}$\", labelpad=2.0)\n",
    "ax.set_xlabel(r\"$\\alpha$\", labelpad=2.0)\n",
    "ax.set_xlim([0.001, 1])\n",
    "ax.set_ylim([0.25, 0.65])\n",
    "ax.grid(which=\"both\", axis=\"both\", alpha=0.5)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", direction=\"in\")\n",
    "ax.tick_params(axis=\"both\", which=\"minor\", direction=\"in\")\n",
    "\n",
    "\n",
    "data_model_legend = []\n",
    "\n",
    "data_model_legend_dict = {\n",
    "    \"Uniform Regularisation\": r\"$\\boldsymbol{1}$\",\n",
    "    \"Opposite Regularisation\": r\"$\\boldsymbol{\\Sigma}_{\\delta}^{-1}$\",\n",
    "    \"Same Regularisation\": r\"$\\boldsymbol{\\Sigma}_{\\delta}$\",\n",
    "    # \"Uniform Regularisation\": r\"$\\boldsymbol{\\Sigma}_{w} = \\boldsymbol{1}$\",\n",
    "    # \"Opposite Regularisation\": r\"$\\boldsymbol{\\Sigma}_{w} = \\boldsymbol{\\Sigma}_{\\delta}^{-1}$\",\n",
    "    # \"Same Regularisation\": r\"$\\boldsymbol{\\Sigma}_{w} = \\boldsymbol{\\Sigma}_{\\delta}$\",\n",
    "}\n",
    "\n",
    "for idx, (key, value) in enumerate(df_dict.items()):\n",
    "    data_model_legend.append(\n",
    "        Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            color=\"black\",\n",
    "            linestyle=linestyles[idx],\n",
    "            label=data_model_legend_dict[key],\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.legend(\n",
    "    handles=data_model_legend,\n",
    "    handlelength=1.7,\n",
    "    bbox_to_anchor=(0.65,0.4),\n",
    "    ncol=3,\n",
    "    columnspacing=0.4\n",
    ")\n",
    "\n",
    "\n",
    "epsilon_legend = []\n",
    "\n",
    "for idx, epsilon in enumerate(common_eps):\n",
    "    if epsilon == 0.4:\n",
    "        continue\n",
    "    epsilon_legend.append(\n",
    "        Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            color=f\"C{idx}\",\n",
    "            linestyle=\"solid\",\n",
    "            label=r\"$\\varepsilon_t={}$\".format(epsilon),\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.legend(\n",
    "    handles=epsilon_legend,\n",
    "    handlelength=1,\n",
    "    bbox_to_anchor=(0.85,0.3),\n",
    "    ncol=3,\n",
    "    columnspacing=0.5\n",
    ")\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    save_plot(\n",
    "        fig,\n",
    "        f\"different_sigma_w_sweep\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_to_save' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save data_to_save using pickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_eps_0.15.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mdata_to_save\u001b[49m, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_to_save' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save data_to_save using pickle\n",
    "with open('data_eps_0.15.pickle', 'wb') as f:\n",
    "    pickle.dump(data_to_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_idx, (key, value) in enumerate(df_dict.items()):\n",
    "\n",
    "    data_model_name = key\n",
    "\n",
    "    for idx, (epsilon, eps_dict) in enumerate(value.items()):\n",
    "\n",
    "\n",
    "        alphas = eps_dict[\"alphas\"]\n",
    "        adversarial_error = eps_dict[\"adversarial_error\"]\n",
    "        generalization_error = eps_dict[\"generalization_error\"]\n",
    "        boundary_error = eps_dict[\"boundary_error\"]\n",
    "        class_preserving = eps_dict[\"class_preserving\"]\n",
    "        tra = eps_dict[\"training_error\"]\n",
    "\n",
    "        adversarial_error_erm = eps_dict[\"adversarial_error_erm\"]\n",
    "        generalization_error_erm = eps_dict[\"generalization_error_erm\"]\n",
    "        boundary_error_erm = eps_dict[\"boundary_error_erm\"]\n",
    "        class_preserving_erm = eps_dict[\"class_preserving_erm\"]\n",
    "\n",
    "        adversarial_error_erm_std = eps_dict[\"adversarial_error_erm_std\"]\n",
    "        generalization_error_erm_std = eps_dict[\"generalization_error_erm_std\"]\n",
    "        boundary_error_erm_std = eps_dict[\"boundary_error_erm_std\"]\n",
    "        class_preserving_erm_std = eps_dict[\"class_preserving_erm_std\"]\n",
    "\n",
    "        plt.plot(\n",
    "            alphas, adversarial_error, label=df_idx, linestyle=linestyles[idx]\n",
    "        )\n",
    "\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the legend separately, put the custom legend into a figure\n",
    "figlegend = plt.figure(figsize=( tuple_size[0], 0.1 * tuple_size[0]))\n",
    "plt.style.use(\"../latex_ready.mplstyle\")\n",
    "legend_ax = figlegend.add_axes([0, 0, 1, 1])\n",
    "legend_ax.axis('off')  # Turn off the axes for the legend figure\n",
    "\n",
    "figlegend.legend(\n",
    "    handles=custom_legend,\n",
    "    handlelength=1,\n",
    "    loc=\"center\",\n",
    "    ncol=4,\n",
    ")\n",
    "\n",
    "figlegend.savefig(\n",
    "    os.path.join(IMG_DIRECTORY, \"legend.pdf\"),\n",
    "    format=\"pdf\",\n",
    "    # bbox_inches=\"tight\",\n",
    ")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the legend separately, put the custom legend into a figure\n",
    "figlegend = plt.figure(figsize=( 0.1*tuple_size[0], 0.5*tuple_size[1]))\n",
    "plt.style.use(\"../latex_ready.mplstyle\")\n",
    "legend_ax = figlegend.add_axes([0, 0, 1, 1])\n",
    "legend_ax.axis('off')  # Turn off the axes for the legend figure\n",
    "\n",
    "# display figure size\n",
    "print(\"Figure size in inches: \", figlegend.get_size_inches())\n",
    "\n",
    "error_legend = []\n",
    "\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{adv}}$\",color=\"C0\"))\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{gen}}$\",color=\"C1\"))\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{bound}}$\",color=\"C2\"))\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{CP}}$\",color=\"C3\"))\n",
    "\n",
    "epsilon_legend = []\n",
    "\n",
    "for idx, epsilon in enumerate(epsilons):\n",
    "    epsilon_legend.append(Line2D([0],[0],color=\"black\", linestyle=linestyles[idx], label=r\"$\\varepsilon_t={}$\".format(epsilons[idx]))) \n",
    "\n",
    "\n",
    "# merge the two legends by concatenating the lists\n",
    "custom_legend = error_legend + epsilon_legend\n",
    "\n",
    "\n",
    "figlegend.legend(\n",
    "    handles=custom_legend,\n",
    "    handlelength=1,\n",
    "    loc=\"center\",\n",
    "    ncol=1,\n",
    ")\n",
    "\n",
    "figlegend.savefig(\n",
    "    os.path.join(IMG_DIRECTORY, \"vertical_legend.pdf\"),\n",
    "    format=\"pdf\",\n",
    "    # bbox_inches=\"tight\",\n",
    ")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
