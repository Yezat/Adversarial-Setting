{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import inspect\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "\n",
    "from experiment_information import *\n",
    "from data import *\n",
    "from helpers import *\n",
    "from _version import __version__\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import pprint\n",
    "import re\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "# mpl.rcParams['lines.linewidth'] = 1\n",
    "# mpl.rcParams['legend.fontsize'] = 13\n",
    "\n",
    "# mpl.rcParams['axes.titlesize'] = 15\n",
    "# mpl.rcParams['axes.labelsize'] = 13\n",
    "# mpl.rcParams['xtick.labelsize'] = 10\n",
    "# mpl.rcParams['ytick.labelsize'] = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current code version,  101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from _version import __version__\n",
    "df_experiments = None\n",
    "df_state_evolution = None\n",
    "df_erm = None\n",
    "logger = logging.getLogger()\n",
    "# with DatabaseHandler(logger,\"experiments/experiments.db\") as dbHandler:\n",
    "with DatabaseHandler(logger,\"../experiments/experiments.db\") as dbHandler:\n",
    "\n",
    "    df_experiments = dbHandler.get_experiments()\n",
    "    df_state_evolution = dbHandler.get_state_evolutions()\n",
    "    df_state_evolution[\"calibrations\"] = df_state_evolution[\"calibrations\"].apply(lambda x: json.loads(x))\n",
    "    df_erm = dbHandler.get_erms()\n",
    "    df_erm[\"analytical_calibrations\"] = df_erm[\"analytical_calibrations\"].apply(lambda x: json.loads(x))\n",
    "    df_erm[\"erm_calibrations\"] = df_erm[\"erm_calibrations\"].apply(lambda x: json.loads(x))\n",
    "    # delete incomplete experiments (bad, deletes running experiments...)\n",
    "    # dbHandler.delete_incomplete_experiments()\n",
    "\n",
    "# def explode_calibrations(df):\n",
    "#     a = df[\"calibrations\"].apply(pd.Series)\n",
    "#     # drop the original calibrations column\n",
    "#     df = df.drop(columns=[\"calibrations\"])\n",
    "#     # concat the original dataframe with the new dataframe containing the exploded calibrations column\n",
    "#     df = pd.concat([df,a],axis=1)\n",
    "#     # explode both calibrations and ps columns\n",
    "#     df = df.explode([\"calibrations\",\"ps\"])\n",
    "#     # rename the exploded columns\n",
    "#     df = df.rename(columns={\"calibrations\":\"calibration\",\"ps\":\"p_calibration\"})\n",
    "#     return df\n",
    "# df_state_evolution = explode_calibrations(df_state_evolution)\n",
    "# def explode_erm_calibrations(df):\n",
    "#     a = df[\"erm_calibrations\"].apply(pd.Series)\n",
    "#     # drop the original calibrations column\n",
    "#     df = df.drop(columns=[\"erm_calibrations\"])\n",
    "#     b = df[\"analytical_calibrations\"].apply(pd.Series)\n",
    "#     # drop the original calibrations column\n",
    "#     df = df.drop(columns=[\"analytical_calibrations\"])\n",
    "#     # drop the dp and ps columns from b\n",
    "#     b = b.drop(columns=[\"dp\",\"ps\"])\n",
    "#     # rename the columns of b\n",
    "#     b = b.rename(columns={\"calibrations\":\"analytical_calibration\"})\n",
    "#     # rename the columns of a\n",
    "#     a = a.rename(columns={\"calibrations\":\"erm_calibration\"})\n",
    "#     # concat the original dataframe with the new dataframe containing the exploded calibrations column\n",
    "#     df = pd.concat([df,a],axis=1)\n",
    "#     df = pd.concat([df,b],axis=1)\n",
    "#     # explode both calibrations and ps columns\n",
    "#     df = df.explode([\"erm_calibration\",\"analytical_calibration\",\"ps\"])\n",
    "#     # rename the exploded columns\n",
    "#     df = df.rename(columns={\"ps\":\"p_calibration\"})\n",
    "#     return df\n",
    "# df_erm = explode_erm_calibrations(df_erm)\n",
    "\n",
    "def explode_measures(df, new_columns, columns):\n",
    "    for column in columns:\n",
    "        def transform(column):\n",
    "            # replace NaN in the column string by 0\n",
    "            column = column.replace(\"NaN\",\"0\")\n",
    "            # replace null in the column string by 0\n",
    "            column = column.replace(\"null\",\"0\")\n",
    "            # replace Infinity in the column string by np.inf\n",
    "            column = column.replace(\"Infinity\",\"np.inf\")\n",
    "            return eval(column)\n",
    "        df[column] = df[column].apply(transform)\n",
    "\n",
    "    exploded = df.explode(columns).reset_index(drop=True)\n",
    "\n",
    "    for new_column, column in zip(new_columns, columns):\n",
    "        if len(exploded[column].tolist()) > 0:\n",
    "            exploded[[\"attack_epsilon\",new_column]] = pd.DataFrame(exploded[column].tolist(), index=exploded.index)\n",
    "        else:\n",
    "            exploded[new_column] = np.nan\n",
    "            # set attack_epsilon\n",
    "            exploded[\"attack_epsilon\"] = np.nan\n",
    "\n",
    "    exploded = exploded.drop(columns=columns)\n",
    "    return exploded\n",
    "\n",
    "\n",
    "def explode_erm_measures(df):\n",
    "    columns = [\"adversarial_generalization_errors\",\"adversarial_generalization_errors_teacher\",\"adversarial_generalization_errors_overlap\",\"fair_adversarial_errors\",\"test_losses\",\"boundary_loss_test_es\"]\n",
    "    new_columns = [\"adversarial_generalization_error\",\"adversarial_generalization_error_teacher\",\"adversarial_generalization_error_overlap\",\"fair_adversarial_error\",\"test_loss\",\"boundary_loss_test\"]\n",
    "    return explode_measures(df, new_columns, columns)\n",
    "\n",
    "def explode_state_evolution_measures(df):\n",
    "    columns = [\"adversarial_generalization_errors\",\"adversarial_generalization_errors_teacher\",\"fair_adversarial_errors\",\"first_term_fair_errors\",\"second_term_fair_errors\",\"third_term_fair_errors\",\"test_losses\",\"data_model_adversarial_generalization_errors\",\"gamma_robustness_es\",\"boundary_loss_test_es\"]\n",
    "    new_columns = [\"adversarial_generalization_error\",\"adversarial_generalization_error_teacher\",\"fair_adversarial_error\",\"first_term_fair_error\",\"second_term_fair_error\",\"third_term_fair_error\",\"test_loss\",\"data_model_adversarial_generalization_error\",\"gamma_robustness\",\"boundary_loss_test\"] #\n",
    "    # columns = [\"adversarial_generalization_errors\",\"adversarial_generalization_errors_teacher\",\"fair_adversarial_errors\",\"second_term_fair_errors\",\"test_losses\",\"data_model_adversarial_generalization_errors\"]\n",
    "    # new_columns = [\"adversarial_generalization_error\",\"adversarial_generalization_error_teacher\",\"fair_adversarial_error\",\"second_term_fair_error\",\"test_loss\",\"data_model_adversarial_generalization_error\"] #\n",
    "    return explode_measures(df, new_columns, columns)\n",
    "    \n",
    "\n",
    "df_erm = explode_erm_measures(df_erm)\n",
    "\n",
    "df_state_evolution = explode_state_evolution_measures(df_state_evolution)\n",
    "    \n",
    "\n",
    "print(\"Current code version, \", __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the pickle file\n",
    "df_powerlaw = pd.read_pickle(\"Pickles/powerlaw.pkl\")\n",
    "df_powerlaw_beta = pd.read_pickle(\"Pickles/powerlaw_beta.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">index_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duration_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">generalization_error_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_loss_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_error_state_evolution</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_generalization_error_erm_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_adversarial_generalization_error_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_angle_to_generalisation_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">A_over_sqrt_qN_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">m_over_sqrt_rhoq_minus_m2_erm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>tau</th>\n",
       "      <th>lam</th>\n",
       "      <th>problem_type</th>\n",
       "      <th>attack_epsilon</th>\n",
       "      <th>beta</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"57\" valign=\"top\">1000000.0</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.2</th>\n",
       "      <th>1.0100</th>\n",
       "      <td>2554.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.394917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0786</th>\n",
       "      <td>2576.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.229608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1472</th>\n",
       "      <td>2562.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.833769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2159</th>\n",
       "      <td>2579.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.150451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2845</th>\n",
       "      <td>2580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.734781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.3531</th>\n",
       "      <td>2559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.605435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4217</th>\n",
       "      <td>2563.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.049522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4903</th>\n",
       "      <td>2569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.688163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5590</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.599281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6276</th>\n",
       "      <td>2573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.424234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6962</th>\n",
       "      <td>2552.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.246767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7648</th>\n",
       "      <td>2557.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.474566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.8334</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.728134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9021</th>\n",
       "      <td>2561.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.755066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9707</th>\n",
       "      <td>2555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.398739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0393</th>\n",
       "      <td>2556.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.512595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1079</th>\n",
       "      <td>2564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.063672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1766</th>\n",
       "      <td>2574.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.778338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2452</th>\n",
       "      <td>2553.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.329678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3138</th>\n",
       "      <td>2565.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.423140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3824</th>\n",
       "      <td>2566.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.160854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4510</th>\n",
       "      <td>2567.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.186757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5197</th>\n",
       "      <td>2568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.171784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5883</th>\n",
       "      <td>2577.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.196321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6569</th>\n",
       "      <td>2570.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.087158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7255</th>\n",
       "      <td>2572.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.113260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7941</th>\n",
       "      <td>2575.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.068408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8628</th>\n",
       "      <td>2578.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.239524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.9314</th>\n",
       "      <td>2581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.360811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0000</th>\n",
       "      <td>2582.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.014006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"27\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"27\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"27\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"27\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"27\" valign=\"top\">0.2</th>\n",
       "      <th>1.0100</th>\n",
       "      <td>2526.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.291322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0786</th>\n",
       "      <td>2529.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.276258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.249811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1472</th>\n",
       "      <td>2527.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.246571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2159</th>\n",
       "      <td>2530.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.272475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.237205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2845</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.418728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.3531</th>\n",
       "      <td>2528.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.232853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.219647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4217</th>\n",
       "      <td>2531.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.290087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.209334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4903</th>\n",
       "      <td>2532.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.384158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5590</th>\n",
       "      <td>2534.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.522384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6276</th>\n",
       "      <td>2535.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.637439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6962</th>\n",
       "      <td>2536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.869876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.165584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7648</th>\n",
       "      <td>2537.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.033793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.155522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9021</th>\n",
       "      <td>2538.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.593936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9707</th>\n",
       "      <td>2539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.928123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0393</th>\n",
       "      <td>2540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.282654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1079</th>\n",
       "      <td>2541.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.676319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.116148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1766</th>\n",
       "      <td>2542.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2452</th>\n",
       "      <td>2543.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.098448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3138</th>\n",
       "      <td>2544.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.268554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5197</th>\n",
       "      <td>2545.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.234128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5883</th>\n",
       "      <td>2546.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.753136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6569</th>\n",
       "      <td>2547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.346455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7255</th>\n",
       "      <td>2548.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.802316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7941</th>\n",
       "      <td>2549.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.186970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8628</th>\n",
       "      <td>2550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.354544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.9314</th>\n",
       "      <td>2551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.424250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0000</th>\n",
       "      <td>2571.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.509024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                index_state_evolution  \\\n",
       "                                                                                 mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                           \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                2554.0   \n",
       "                                                         1.0786                2576.0   \n",
       "                                                         1.1472                2562.0   \n",
       "                                                         1.2159                2579.0   \n",
       "                                                         1.2845                2580.0   \n",
       "                                                         1.3531                2559.0   \n",
       "                                                         1.4217                2563.0   \n",
       "                                                         1.4903                2569.0   \n",
       "                                                         1.5590                2558.0   \n",
       "                                                         1.6276                2573.0   \n",
       "                                                         1.6962                2552.0   \n",
       "                                                         1.7648                2557.0   \n",
       "                                                         1.8334                2560.0   \n",
       "                                                         1.9021                2561.0   \n",
       "                                                         1.9707                2555.0   \n",
       "                                                         2.0393                2556.0   \n",
       "                                                         2.1079                2564.0   \n",
       "                                                         2.1766                2574.0   \n",
       "                                                         2.2452                2553.0   \n",
       "                                                         2.3138                2565.0   \n",
       "                                                         2.3824                2566.0   \n",
       "                                                         2.4510                2567.0   \n",
       "                                                         2.5197                2568.0   \n",
       "                                                         2.5883                2577.0   \n",
       "                                                         2.6569                2570.0   \n",
       "                                                         2.7255                2572.0   \n",
       "                                                         2.7941                2575.0   \n",
       "                                                         2.8628                2578.0   \n",
       "                                                         2.9314                2581.0   \n",
       "                                                         3.0000                2582.0   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                2526.0   \n",
       "                                                         1.0786                2529.0   \n",
       "                                                         1.1472                2527.0   \n",
       "                                                         1.2159                2530.0   \n",
       "                                                         1.2845                2533.0   \n",
       "                                                         1.3531                2528.0   \n",
       "                                                         1.4217                2531.0   \n",
       "                                                         1.4903                2532.0   \n",
       "                                                         1.5590                2534.0   \n",
       "                                                         1.6276                2535.0   \n",
       "                                                         1.6962                2536.0   \n",
       "                                                         1.7648                2537.0   \n",
       "                                                         1.9021                2538.0   \n",
       "                                                         1.9707                2539.0   \n",
       "                                                         2.0393                2540.0   \n",
       "                                                         2.1079                2541.0   \n",
       "                                                         2.1766                2542.0   \n",
       "                                                         2.2452                2543.0   \n",
       "                                                         2.3138                2544.0   \n",
       "                                                         2.5197                2545.0   \n",
       "                                                         2.5883                2546.0   \n",
       "                                                         2.6569                2547.0   \n",
       "                                                         2.7255                2548.0   \n",
       "                                                         2.7941                2549.0   \n",
       "                                                         2.8628                2550.0   \n",
       "                                                         2.9314                2551.0   \n",
       "                                                         3.0000                2571.0   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                duration_state_evolution  \\\n",
       "                                                                                    mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                              \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                17.394917   \n",
       "                                                         1.0786                18.229608   \n",
       "                                                         1.1472                17.833769   \n",
       "                                                         1.2159                21.150451   \n",
       "                                                         1.2845                22.734781   \n",
       "                                                         1.3531                17.605435   \n",
       "                                                         1.4217                18.049522   \n",
       "                                                         1.4903                18.688163   \n",
       "                                                         1.5590                17.599281   \n",
       "                                                         1.6276                19.424234   \n",
       "                                                         1.6962                17.246767   \n",
       "                                                         1.7648                17.474566   \n",
       "                                                         1.8334                17.728134   \n",
       "                                                         1.9021                17.755066   \n",
       "                                                         1.9707                17.398739   \n",
       "                                                         2.0393                17.512595   \n",
       "                                                         2.1079                18.063672   \n",
       "                                                         2.1766                19.778338   \n",
       "                                                         2.2452                17.329678   \n",
       "                                                         2.3138                18.423140   \n",
       "                                                         2.3824                16.160854   \n",
       "                                                         2.4510                16.186757   \n",
       "                                                         2.5197                16.171784   \n",
       "                                                         2.5883                18.196321   \n",
       "                                                         2.6569                16.087158   \n",
       "                                                         2.7255                16.113260   \n",
       "                                                         2.7941                16.068408   \n",
       "                                                         2.8628                16.239524   \n",
       "                                                         2.9314                17.360811   \n",
       "                                                         3.0000                16.014006   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                 2.291322   \n",
       "                                                         1.0786                 2.276258   \n",
       "                                                         1.1472                 2.246571   \n",
       "                                                         1.2159                 2.272475   \n",
       "                                                         1.2845                 2.418728   \n",
       "                                                         1.3531                 2.232853   \n",
       "                                                         1.4217                 2.290087   \n",
       "                                                         1.4903                 2.384158   \n",
       "                                                         1.5590                 2.522384   \n",
       "                                                         1.6276                 2.637439   \n",
       "                                                         1.6962                 2.869876   \n",
       "                                                         1.7648                 3.033793   \n",
       "                                                         1.9021                 3.593936   \n",
       "                                                         1.9707                 3.928123   \n",
       "                                                         2.0393                 4.282654   \n",
       "                                                         2.1079                 4.676319   \n",
       "                                                         2.1766                 5.098309   \n",
       "                                                         2.2452                 6.098448   \n",
       "                                                         2.3138                 5.268554   \n",
       "                                                         2.5197                 6.234128   \n",
       "                                                         2.5883                 6.753136   \n",
       "                                                         2.6569                 7.346455   \n",
       "                                                         2.7255                 7.802316   \n",
       "                                                         2.7941                 8.186970   \n",
       "                                                         2.8628                 8.354544   \n",
       "                                                         2.9314                 9.424250   \n",
       "                                                         3.0000                 9.509024   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                generalization_error_state_evolution  \\\n",
       "                                                                                                mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                          \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                             0.015902   \n",
       "                                                         1.0786                             0.015902   \n",
       "                                                         1.1472                             0.015902   \n",
       "                                                         1.2159                             0.015902   \n",
       "                                                         1.2845                             0.015902   \n",
       "                                                         1.3531                             0.015902   \n",
       "                                                         1.4217                             0.015902   \n",
       "                                                         1.4903                             0.015902   \n",
       "                                                         1.5590                             0.015902   \n",
       "                                                         1.6276                             0.015902   \n",
       "                                                         1.6962                             0.015902   \n",
       "                                                         1.7648                             0.015902   \n",
       "                                                         1.8334                             0.015902   \n",
       "                                                         1.9021                             0.015902   \n",
       "                                                         1.9707                             0.015902   \n",
       "                                                         2.0393                             0.015902   \n",
       "                                                         2.1079                             0.015902   \n",
       "                                                         2.1766                             0.015902   \n",
       "                                                         2.2452                             0.015902   \n",
       "                                                         2.3138                             0.015902   \n",
       "                                                         2.3824                             0.015902   \n",
       "                                                         2.4510                             0.015902   \n",
       "                                                         2.5197                             0.015902   \n",
       "                                                         2.5883                             0.015902   \n",
       "                                                         2.6569                             0.015902   \n",
       "                                                         2.7255                             0.015902   \n",
       "                                                         2.7941                             0.015902   \n",
       "                                                         2.8628                             0.015902   \n",
       "                                                         2.9314                             0.015902   \n",
       "                                                         3.0000                             0.015902   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                             0.031410   \n",
       "                                                         1.0786                             0.034129   \n",
       "                                                         1.1472                             0.036942   \n",
       "                                                         1.2159                             0.039666   \n",
       "                                                         1.2845                             0.042035   \n",
       "                                                         1.3531                             0.043783   \n",
       "                                                         1.4217                             0.044709   \n",
       "                                                         1.4903                             0.044758   \n",
       "                                                         1.5590                             0.044022   \n",
       "                                                         1.6276                             0.042686   \n",
       "                                                         1.6962                             0.040959   \n",
       "                                                         1.7648                             0.039023   \n",
       "                                                         1.9021                             0.035052   \n",
       "                                                         1.9707                             0.033184   \n",
       "                                                         2.0393                             0.031453   \n",
       "                                                         2.1079                             0.029875   \n",
       "                                                         2.1766                             0.028453   \n",
       "                                                         2.2452                             0.027180   \n",
       "                                                         2.3138                             0.026064   \n",
       "                                                         2.5197                             0.023431   \n",
       "                                                         2.5883                             0.022756   \n",
       "                                                         2.6569                             0.022161   \n",
       "                                                         2.7255                             0.021636   \n",
       "                                                         2.7941                             0.021173   \n",
       "                                                         2.8628                             0.020762   \n",
       "                                                         2.9314                             0.020397   \n",
       "                                                         3.0000                             0.020072   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                training_loss_state_evolution  \\\n",
       "                                                                                         mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                   \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                      0.036130   \n",
       "                                                         1.0786                      0.036130   \n",
       "                                                         1.1472                      0.036130   \n",
       "                                                         1.2159                      0.036130   \n",
       "                                                         1.2845                      0.036130   \n",
       "                                                         1.3531                      0.036130   \n",
       "                                                         1.4217                      0.036130   \n",
       "                                                         1.4903                      0.036130   \n",
       "                                                         1.5590                      0.036130   \n",
       "                                                         1.6276                      0.036130   \n",
       "                                                         1.6962                      0.036130   \n",
       "                                                         1.7648                      0.036130   \n",
       "                                                         1.8334                      0.036130   \n",
       "                                                         1.9021                      0.036130   \n",
       "                                                         1.9707                      0.036130   \n",
       "                                                         2.0393                      0.036130   \n",
       "                                                         2.1079                      0.036130   \n",
       "                                                         2.1766                      0.036130   \n",
       "                                                         2.2452                      0.036130   \n",
       "                                                         2.3138                      0.036130   \n",
       "                                                         2.3824                      0.036130   \n",
       "                                                         2.4510                      0.036130   \n",
       "                                                         2.5197                      0.036130   \n",
       "                                                         2.5883                      0.036130   \n",
       "                                                         2.6569                      0.036130   \n",
       "                                                         2.7255                      0.036130   \n",
       "                                                         2.7941                      0.036130   \n",
       "                                                         2.8628                      0.036130   \n",
       "                                                         2.9314                      0.036130   \n",
       "                                                         3.0000                      0.036130   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                      0.254386   \n",
       "                                                         1.0786                      0.249811   \n",
       "                                                         1.1472                      0.244130   \n",
       "                                                         1.2159                      0.237205   \n",
       "                                                         1.2845                      0.229016   \n",
       "                                                         1.3531                      0.219647   \n",
       "                                                         1.4217                      0.209334   \n",
       "                                                         1.4903                      0.198417   \n",
       "                                                         1.5590                      0.187255   \n",
       "                                                         1.6276                      0.176225   \n",
       "                                                         1.6962                      0.165584   \n",
       "                                                         1.7648                      0.155522   \n",
       "                                                         1.9021                      0.137527   \n",
       "                                                         1.9707                      0.129672   \n",
       "                                                         2.0393                      0.122560   \n",
       "                                                         2.1079                      0.116148   \n",
       "                                                         2.1766                      0.110378   \n",
       "                                                         2.2452                      0.105211   \n",
       "                                                         2.3138                      0.100579   \n",
       "                                                         2.5197                      0.089351   \n",
       "                                                         2.5883                      0.086340   \n",
       "                                                         2.6569                      0.083625   \n",
       "                                                         2.7255                      0.081171   \n",
       "                                                         2.7941                      0.078947   \n",
       "                                                         2.8628                      0.076924   \n",
       "                                                         2.9314                      0.075084   \n",
       "                                                         3.0000                      0.073404   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                training_error_state_evolution  \\\n",
       "                                                                                          mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                    \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                       0.015902   \n",
       "                                                         1.0786                       0.015902   \n",
       "                                                         1.1472                       0.015902   \n",
       "                                                         1.2159                       0.015902   \n",
       "                                                         1.2845                       0.015902   \n",
       "                                                         1.3531                       0.015902   \n",
       "                                                         1.4217                       0.015902   \n",
       "                                                         1.4903                       0.015902   \n",
       "                                                         1.5590                       0.015902   \n",
       "                                                         1.6276                       0.015902   \n",
       "                                                         1.6962                       0.015902   \n",
       "                                                         1.7648                       0.015902   \n",
       "                                                         1.8334                       0.015902   \n",
       "                                                         1.9021                       0.015902   \n",
       "                                                         1.9707                       0.015902   \n",
       "                                                         2.0393                       0.015902   \n",
       "                                                         2.1079                       0.015902   \n",
       "                                                         2.1766                       0.015902   \n",
       "                                                         2.2452                       0.015902   \n",
       "                                                         2.3138                       0.015902   \n",
       "                                                         2.3824                       0.015902   \n",
       "                                                         2.4510                       0.015902   \n",
       "                                                         2.5197                       0.015902   \n",
       "                                                         2.5883                       0.015902   \n",
       "                                                         2.6569                       0.015902   \n",
       "                                                         2.7255                       0.015902   \n",
       "                                                         2.7941                       0.015902   \n",
       "                                                         2.8628                       0.015902   \n",
       "                                                         2.9314                       0.015902   \n",
       "                                                         3.0000                       0.015902   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                       0.031410   \n",
       "                                                         1.0786                       0.034129   \n",
       "                                                         1.1472                       0.036942   \n",
       "                                                         1.2159                       0.039666   \n",
       "                                                         1.2845                       0.042035   \n",
       "                                                         1.3531                       0.043783   \n",
       "                                                         1.4217                       0.044709   \n",
       "                                                         1.4903                       0.044758   \n",
       "                                                         1.5590                       0.044022   \n",
       "                                                         1.6276                       0.042686   \n",
       "                                                         1.6962                       0.040959   \n",
       "                                                         1.7648                       0.039023   \n",
       "                                                         1.9021                       0.035052   \n",
       "                                                         1.9707                       0.033184   \n",
       "                                                         2.0393                       0.031453   \n",
       "                                                         2.1079                       0.029875   \n",
       "                                                         2.1766                       0.028453   \n",
       "                                                         2.2452                       0.027180   \n",
       "                                                         2.3138                       0.026064   \n",
       "                                                         2.5197                       0.023431   \n",
       "                                                         2.5883                       0.022756   \n",
       "                                                         2.6569                       0.022161   \n",
       "                                                         2.7255                       0.021636   \n",
       "                                                         2.7941                       0.021173   \n",
       "                                                         2.8628                       0.020762   \n",
       "                                                         2.9314                       0.020397   \n",
       "                                                         3.0000                       0.020072   \n",
       "\n",
       "                                                                     ...  \\\n",
       "                                                                std  ...   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta        ...   \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN  ...   \n",
       "                                                         1.0786 NaN  ...   \n",
       "                                                         1.1472 NaN  ...   \n",
       "                                                         1.2159 NaN  ...   \n",
       "                                                         1.2845 NaN  ...   \n",
       "                                                         1.3531 NaN  ...   \n",
       "                                                         1.4217 NaN  ...   \n",
       "                                                         1.4903 NaN  ...   \n",
       "                                                         1.5590 NaN  ...   \n",
       "                                                         1.6276 NaN  ...   \n",
       "                                                         1.6962 NaN  ...   \n",
       "                                                         1.7648 NaN  ...   \n",
       "                                                         1.8334 NaN  ...   \n",
       "                                                         1.9021 NaN  ...   \n",
       "                                                         1.9707 NaN  ...   \n",
       "                                                         2.0393 NaN  ...   \n",
       "                                                         2.1079 NaN  ...   \n",
       "                                                         2.1766 NaN  ...   \n",
       "                                                         2.2452 NaN  ...   \n",
       "                                                         2.3138 NaN  ...   \n",
       "                                                         2.3824 NaN  ...   \n",
       "                                                         2.4510 NaN  ...   \n",
       "                                                         2.5197 NaN  ...   \n",
       "                                                         2.5883 NaN  ...   \n",
       "                                                         2.6569 NaN  ...   \n",
       "                                                         2.7255 NaN  ...   \n",
       "                                                         2.7941 NaN  ...   \n",
       "                                                         2.8628 NaN  ...   \n",
       "                                                         2.9314 NaN  ...   \n",
       "                                                         3.0000 NaN  ...   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN  ...   \n",
       "                                                         1.0786 NaN  ...   \n",
       "                                                         1.1472 NaN  ...   \n",
       "                                                         1.2159 NaN  ...   \n",
       "                                                         1.2845 NaN  ...   \n",
       "                                                         1.3531 NaN  ...   \n",
       "                                                         1.4217 NaN  ...   \n",
       "                                                         1.4903 NaN  ...   \n",
       "                                                         1.5590 NaN  ...   \n",
       "                                                         1.6276 NaN  ...   \n",
       "                                                         1.6962 NaN  ...   \n",
       "                                                         1.7648 NaN  ...   \n",
       "                                                         1.9021 NaN  ...   \n",
       "                                                         1.9707 NaN  ...   \n",
       "                                                         2.0393 NaN  ...   \n",
       "                                                         2.1079 NaN  ...   \n",
       "                                                         2.1766 NaN  ...   \n",
       "                                                         2.2452 NaN  ...   \n",
       "                                                         2.3138 NaN  ...   \n",
       "                                                         2.5197 NaN  ...   \n",
       "                                                         2.5883 NaN  ...   \n",
       "                                                         2.6569 NaN  ...   \n",
       "                                                         2.7255 NaN  ...   \n",
       "                                                         2.7941 NaN  ...   \n",
       "                                                         2.8628 NaN  ...   \n",
       "                                                         2.9314 NaN  ...   \n",
       "                                                         3.0000 NaN  ...   \n",
       "\n",
       "                                                                noiseless_generalization_error_erm_erm  \\\n",
       "                                                                                                  mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                            \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                                    NaN   \n",
       "                                                         1.0786                                    NaN   \n",
       "                                                         1.1472                                    NaN   \n",
       "                                                         1.2159                                    NaN   \n",
       "                                                         1.2845                                    NaN   \n",
       "                                                         1.3531                                    NaN   \n",
       "                                                         1.4217                                    NaN   \n",
       "                                                         1.4903                                    NaN   \n",
       "                                                         1.5590                                    NaN   \n",
       "                                                         1.6276                                    NaN   \n",
       "                                                         1.6962                                    NaN   \n",
       "                                                         1.7648                                    NaN   \n",
       "                                                         1.8334                                    NaN   \n",
       "                                                         1.9021                                    NaN   \n",
       "                                                         1.9707                                    NaN   \n",
       "                                                         2.0393                                    NaN   \n",
       "                                                         2.1079                                    NaN   \n",
       "                                                         2.1766                                    NaN   \n",
       "                                                         2.2452                                    NaN   \n",
       "                                                         2.3138                                    NaN   \n",
       "                                                         2.3824                                    NaN   \n",
       "                                                         2.4510                                    NaN   \n",
       "                                                         2.5197                                    NaN   \n",
       "                                                         2.5883                                    NaN   \n",
       "                                                         2.6569                                    NaN   \n",
       "                                                         2.7255                                    NaN   \n",
       "                                                         2.7941                                    NaN   \n",
       "                                                         2.8628                                    NaN   \n",
       "                                                         2.9314                                    NaN   \n",
       "                                                         3.0000                                    NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                                    NaN   \n",
       "                                                         1.0786                                    NaN   \n",
       "                                                         1.1472                                    NaN   \n",
       "                                                         1.2159                                    NaN   \n",
       "                                                         1.2845                                    NaN   \n",
       "                                                         1.3531                                    NaN   \n",
       "                                                         1.4217                                    NaN   \n",
       "                                                         1.4903                                    NaN   \n",
       "                                                         1.5590                                    NaN   \n",
       "                                                         1.6276                                    NaN   \n",
       "                                                         1.6962                                    NaN   \n",
       "                                                         1.7648                                    NaN   \n",
       "                                                         1.9021                                    NaN   \n",
       "                                                         1.9707                                    NaN   \n",
       "                                                         2.0393                                    NaN   \n",
       "                                                         2.1079                                    NaN   \n",
       "                                                         2.1766                                    NaN   \n",
       "                                                         2.2452                                    NaN   \n",
       "                                                         2.3138                                    NaN   \n",
       "                                                         2.5197                                    NaN   \n",
       "                                                         2.5883                                    NaN   \n",
       "                                                         2.6569                                    NaN   \n",
       "                                                         2.7255                                    NaN   \n",
       "                                                         2.7941                                    NaN   \n",
       "                                                         2.8628                                    NaN   \n",
       "                                                         2.9314                                    NaN   \n",
       "                                                         3.0000                                    NaN   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                noiseless_adversarial_generalization_error_erm  \\\n",
       "                                                                                                          mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                                    \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                                            NaN   \n",
       "                                                         1.0786                                            NaN   \n",
       "                                                         1.1472                                            NaN   \n",
       "                                                         1.2159                                            NaN   \n",
       "                                                         1.2845                                            NaN   \n",
       "                                                         1.3531                                            NaN   \n",
       "                                                         1.4217                                            NaN   \n",
       "                                                         1.4903                                            NaN   \n",
       "                                                         1.5590                                            NaN   \n",
       "                                                         1.6276                                            NaN   \n",
       "                                                         1.6962                                            NaN   \n",
       "                                                         1.7648                                            NaN   \n",
       "                                                         1.8334                                            NaN   \n",
       "                                                         1.9021                                            NaN   \n",
       "                                                         1.9707                                            NaN   \n",
       "                                                         2.0393                                            NaN   \n",
       "                                                         2.1079                                            NaN   \n",
       "                                                         2.1766                                            NaN   \n",
       "                                                         2.2452                                            NaN   \n",
       "                                                         2.3138                                            NaN   \n",
       "                                                         2.3824                                            NaN   \n",
       "                                                         2.4510                                            NaN   \n",
       "                                                         2.5197                                            NaN   \n",
       "                                                         2.5883                                            NaN   \n",
       "                                                         2.6569                                            NaN   \n",
       "                                                         2.7255                                            NaN   \n",
       "                                                         2.7941                                            NaN   \n",
       "                                                         2.8628                                            NaN   \n",
       "                                                         2.9314                                            NaN   \n",
       "                                                         3.0000                                            NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                                            NaN   \n",
       "                                                         1.0786                                            NaN   \n",
       "                                                         1.1472                                            NaN   \n",
       "                                                         1.2159                                            NaN   \n",
       "                                                         1.2845                                            NaN   \n",
       "                                                         1.3531                                            NaN   \n",
       "                                                         1.4217                                            NaN   \n",
       "                                                         1.4903                                            NaN   \n",
       "                                                         1.5590                                            NaN   \n",
       "                                                         1.6276                                            NaN   \n",
       "                                                         1.6962                                            NaN   \n",
       "                                                         1.7648                                            NaN   \n",
       "                                                         1.9021                                            NaN   \n",
       "                                                         1.9707                                            NaN   \n",
       "                                                         2.0393                                            NaN   \n",
       "                                                         2.1079                                            NaN   \n",
       "                                                         2.1766                                            NaN   \n",
       "                                                         2.2452                                            NaN   \n",
       "                                                         2.3138                                            NaN   \n",
       "                                                         2.5197                                            NaN   \n",
       "                                                         2.5883                                            NaN   \n",
       "                                                         2.6569                                            NaN   \n",
       "                                                         2.7255                                            NaN   \n",
       "                                                         2.7941                                            NaN   \n",
       "                                                         2.8628                                            NaN   \n",
       "                                                         2.9314                                            NaN   \n",
       "                                                         3.0000                                            NaN   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                noiseless_angle_to_generalisation_erm  \\\n",
       "                                                                                                 mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                           \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                                   NaN   \n",
       "                                                         1.0786                                   NaN   \n",
       "                                                         1.1472                                   NaN   \n",
       "                                                         1.2159                                   NaN   \n",
       "                                                         1.2845                                   NaN   \n",
       "                                                         1.3531                                   NaN   \n",
       "                                                         1.4217                                   NaN   \n",
       "                                                         1.4903                                   NaN   \n",
       "                                                         1.5590                                   NaN   \n",
       "                                                         1.6276                                   NaN   \n",
       "                                                         1.6962                                   NaN   \n",
       "                                                         1.7648                                   NaN   \n",
       "                                                         1.8334                                   NaN   \n",
       "                                                         1.9021                                   NaN   \n",
       "                                                         1.9707                                   NaN   \n",
       "                                                         2.0393                                   NaN   \n",
       "                                                         2.1079                                   NaN   \n",
       "                                                         2.1766                                   NaN   \n",
       "                                                         2.2452                                   NaN   \n",
       "                                                         2.3138                                   NaN   \n",
       "                                                         2.3824                                   NaN   \n",
       "                                                         2.4510                                   NaN   \n",
       "                                                         2.5197                                   NaN   \n",
       "                                                         2.5883                                   NaN   \n",
       "                                                         2.6569                                   NaN   \n",
       "                                                         2.7255                                   NaN   \n",
       "                                                         2.7941                                   NaN   \n",
       "                                                         2.8628                                   NaN   \n",
       "                                                         2.9314                                   NaN   \n",
       "                                                         3.0000                                   NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                                   NaN   \n",
       "                                                         1.0786                                   NaN   \n",
       "                                                         1.1472                                   NaN   \n",
       "                                                         1.2159                                   NaN   \n",
       "                                                         1.2845                                   NaN   \n",
       "                                                         1.3531                                   NaN   \n",
       "                                                         1.4217                                   NaN   \n",
       "                                                         1.4903                                   NaN   \n",
       "                                                         1.5590                                   NaN   \n",
       "                                                         1.6276                                   NaN   \n",
       "                                                         1.6962                                   NaN   \n",
       "                                                         1.7648                                   NaN   \n",
       "                                                         1.9021                                   NaN   \n",
       "                                                         1.9707                                   NaN   \n",
       "                                                         2.0393                                   NaN   \n",
       "                                                         2.1079                                   NaN   \n",
       "                                                         2.1766                                   NaN   \n",
       "                                                         2.2452                                   NaN   \n",
       "                                                         2.3138                                   NaN   \n",
       "                                                         2.5197                                   NaN   \n",
       "                                                         2.5883                                   NaN   \n",
       "                                                         2.6569                                   NaN   \n",
       "                                                         2.7255                                   NaN   \n",
       "                                                         2.7941                                   NaN   \n",
       "                                                         2.8628                                   NaN   \n",
       "                                                         2.9314                                   NaN   \n",
       "                                                         3.0000                                   NaN   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                A_over_sqrt_qN_erm  \\\n",
       "                                                                              mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                        \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                NaN   \n",
       "                                                         1.0786                NaN   \n",
       "                                                         1.1472                NaN   \n",
       "                                                         1.2159                NaN   \n",
       "                                                         1.2845                NaN   \n",
       "                                                         1.3531                NaN   \n",
       "                                                         1.4217                NaN   \n",
       "                                                         1.4903                NaN   \n",
       "                                                         1.5590                NaN   \n",
       "                                                         1.6276                NaN   \n",
       "                                                         1.6962                NaN   \n",
       "                                                         1.7648                NaN   \n",
       "                                                         1.8334                NaN   \n",
       "                                                         1.9021                NaN   \n",
       "                                                         1.9707                NaN   \n",
       "                                                         2.0393                NaN   \n",
       "                                                         2.1079                NaN   \n",
       "                                                         2.1766                NaN   \n",
       "                                                         2.2452                NaN   \n",
       "                                                         2.3138                NaN   \n",
       "                                                         2.3824                NaN   \n",
       "                                                         2.4510                NaN   \n",
       "                                                         2.5197                NaN   \n",
       "                                                         2.5883                NaN   \n",
       "                                                         2.6569                NaN   \n",
       "                                                         2.7255                NaN   \n",
       "                                                         2.7941                NaN   \n",
       "                                                         2.8628                NaN   \n",
       "                                                         2.9314                NaN   \n",
       "                                                         3.0000                NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                NaN   \n",
       "                                                         1.0786                NaN   \n",
       "                                                         1.1472                NaN   \n",
       "                                                         1.2159                NaN   \n",
       "                                                         1.2845                NaN   \n",
       "                                                         1.3531                NaN   \n",
       "                                                         1.4217                NaN   \n",
       "                                                         1.4903                NaN   \n",
       "                                                         1.5590                NaN   \n",
       "                                                         1.6276                NaN   \n",
       "                                                         1.6962                NaN   \n",
       "                                                         1.7648                NaN   \n",
       "                                                         1.9021                NaN   \n",
       "                                                         1.9707                NaN   \n",
       "                                                         2.0393                NaN   \n",
       "                                                         2.1079                NaN   \n",
       "                                                         2.1766                NaN   \n",
       "                                                         2.2452                NaN   \n",
       "                                                         2.3138                NaN   \n",
       "                                                         2.5197                NaN   \n",
       "                                                         2.5883                NaN   \n",
       "                                                         2.6569                NaN   \n",
       "                                                         2.7255                NaN   \n",
       "                                                         2.7941                NaN   \n",
       "                                                         2.8628                NaN   \n",
       "                                                         2.9314                NaN   \n",
       "                                                         3.0000                NaN   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                m_over_sqrt_rhoq_minus_m2_erm  \\\n",
       "                                                                                         mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                   \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                           NaN   \n",
       "                                                         1.0786                           NaN   \n",
       "                                                         1.1472                           NaN   \n",
       "                                                         1.2159                           NaN   \n",
       "                                                         1.2845                           NaN   \n",
       "                                                         1.3531                           NaN   \n",
       "                                                         1.4217                           NaN   \n",
       "                                                         1.4903                           NaN   \n",
       "                                                         1.5590                           NaN   \n",
       "                                                         1.6276                           NaN   \n",
       "                                                         1.6962                           NaN   \n",
       "                                                         1.7648                           NaN   \n",
       "                                                         1.8334                           NaN   \n",
       "                                                         1.9021                           NaN   \n",
       "                                                         1.9707                           NaN   \n",
       "                                                         2.0393                           NaN   \n",
       "                                                         2.1079                           NaN   \n",
       "                                                         2.1766                           NaN   \n",
       "                                                         2.2452                           NaN   \n",
       "                                                         2.3138                           NaN   \n",
       "                                                         2.3824                           NaN   \n",
       "                                                         2.4510                           NaN   \n",
       "                                                         2.5197                           NaN   \n",
       "                                                         2.5883                           NaN   \n",
       "                                                         2.6569                           NaN   \n",
       "                                                         2.7255                           NaN   \n",
       "                                                         2.7941                           NaN   \n",
       "                                                         2.8628                           NaN   \n",
       "                                                         2.9314                           NaN   \n",
       "                                                         3.0000                           NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                           NaN   \n",
       "                                                         1.0786                           NaN   \n",
       "                                                         1.1472                           NaN   \n",
       "                                                         1.2159                           NaN   \n",
       "                                                         1.2845                           NaN   \n",
       "                                                         1.3531                           NaN   \n",
       "                                                         1.4217                           NaN   \n",
       "                                                         1.4903                           NaN   \n",
       "                                                         1.5590                           NaN   \n",
       "                                                         1.6276                           NaN   \n",
       "                                                         1.6962                           NaN   \n",
       "                                                         1.7648                           NaN   \n",
       "                                                         1.9021                           NaN   \n",
       "                                                         1.9707                           NaN   \n",
       "                                                         2.0393                           NaN   \n",
       "                                                         2.1079                           NaN   \n",
       "                                                         2.1766                           NaN   \n",
       "                                                         2.2452                           NaN   \n",
       "                                                         2.3138                           NaN   \n",
       "                                                         2.5197                           NaN   \n",
       "                                                         2.5883                           NaN   \n",
       "                                                         2.6569                           NaN   \n",
       "                                                         2.7255                           NaN   \n",
       "                                                         2.7941                           NaN   \n",
       "                                                         2.8628                           NaN   \n",
       "                                                         2.9314                           NaN   \n",
       "                                                         3.0000                           NaN   \n",
       "\n",
       "                                                                     \n",
       "                                                                std  \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta        \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN  \n",
       "                                                         1.0786 NaN  \n",
       "                                                         1.1472 NaN  \n",
       "                                                         1.2159 NaN  \n",
       "                                                         1.2845 NaN  \n",
       "                                                         1.3531 NaN  \n",
       "                                                         1.4217 NaN  \n",
       "                                                         1.4903 NaN  \n",
       "                                                         1.5590 NaN  \n",
       "                                                         1.6276 NaN  \n",
       "                                                         1.6962 NaN  \n",
       "                                                         1.7648 NaN  \n",
       "                                                         1.8334 NaN  \n",
       "                                                         1.9021 NaN  \n",
       "                                                         1.9707 NaN  \n",
       "                                                         2.0393 NaN  \n",
       "                                                         2.1079 NaN  \n",
       "                                                         2.1766 NaN  \n",
       "                                                         2.2452 NaN  \n",
       "                                                         2.3138 NaN  \n",
       "                                                         2.3824 NaN  \n",
       "                                                         2.4510 NaN  \n",
       "                                                         2.5197 NaN  \n",
       "                                                         2.5883 NaN  \n",
       "                                                         2.6569 NaN  \n",
       "                                                         2.7255 NaN  \n",
       "                                                         2.7941 NaN  \n",
       "                                                         2.8628 NaN  \n",
       "                                                         2.9314 NaN  \n",
       "                                                         3.0000 NaN  \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN  \n",
       "                                                         1.0786 NaN  \n",
       "                                                         1.1472 NaN  \n",
       "                                                         1.2159 NaN  \n",
       "                                                         1.2845 NaN  \n",
       "                                                         1.3531 NaN  \n",
       "                                                         1.4217 NaN  \n",
       "                                                         1.4903 NaN  \n",
       "                                                         1.5590 NaN  \n",
       "                                                         1.6276 NaN  \n",
       "                                                         1.6962 NaN  \n",
       "                                                         1.7648 NaN  \n",
       "                                                         1.9021 NaN  \n",
       "                                                         1.9707 NaN  \n",
       "                                                         2.0393 NaN  \n",
       "                                                         2.1079 NaN  \n",
       "                                                         2.1766 NaN  \n",
       "                                                         2.2452 NaN  \n",
       "                                                         2.3138 NaN  \n",
       "                                                         2.5197 NaN  \n",
       "                                                         2.5883 NaN  \n",
       "                                                         2.6569 NaN  \n",
       "                                                         2.7255 NaN  \n",
       "                                                         2.7941 NaN  \n",
       "                                                         2.8628 NaN  \n",
       "                                                         2.9314 NaN  \n",
       "                                                         3.0000 NaN  \n",
       "\n",
       "[57 rows x 214 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_powerlaw_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">index_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duration_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">generalization_error_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_loss_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_error_state_evolution</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_generalization_error_erm_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_adversarial_generalization_error_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_angle_to_generalisation_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">A_over_sqrt_qN_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">m_over_sqrt_rhoq_minus_m2_erm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>tau</th>\n",
       "      <th>lam</th>\n",
       "      <th>problem_type</th>\n",
       "      <th>attack_epsilon</th>\n",
       "      <th>data_model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1585</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.2</th>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_0.5</th>\n",
       "      <td>2115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_1.5</th>\n",
       "      <td>2055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_2.5</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.543683e-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_3.5</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.032063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.111418e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.001</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>0.2</th>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_0.5</th>\n",
       "      <td>2116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10000.0000</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.001</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>0.2</th>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_3.5</th>\n",
       "      <td>2088.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.403625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.591084e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.2</th>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_0.5</th>\n",
       "      <td>2180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.600145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.885621e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_1.5</th>\n",
       "      <td>2141.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.730033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.470230e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_2.5</th>\n",
       "      <td>2129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.557398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.090272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.364277e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_3.5</th>\n",
       "      <td>2078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.635296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.851481e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  index_state_evolution  \\\n",
       "                                                                                                                   mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                 \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                2115.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                2055.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                2002.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                1972.0   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                2116.0   \n",
       "...                                                                                                                 ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                2088.0   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                2180.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                2141.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                2129.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                2078.0   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  duration_state_evolution  \\\n",
       "                                                                                                                      mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                    \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                 0.060791   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                 0.143259   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                 0.768748   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                 3.032063   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                 0.091313   \n",
       "...                                                                                                                    ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                18.403625   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                 1.600145   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                 1.730033   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                 7.557398   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                16.635296   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  generalization_error_state_evolution  \\\n",
       "                                                                                                                                  mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                                \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                             0.376116   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                             0.160523   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                             0.064716   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                             0.039534   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                             0.376171   \n",
       "...                                                                                                                                ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                             0.015911   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                             0.018856   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                             0.044702   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                             0.023643   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                             0.018515   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  training_loss_state_evolution  \\\n",
       "                                                                                                                           mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                         \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                      0.005583   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                      0.008649   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                      0.014742   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                      0.019588   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                      0.006459   \n",
       "...                                                                                                                         ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                      0.036114   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                      0.268545   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                      0.196824   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                      0.090272   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                      0.064606   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  training_error_state_evolution  \\\n",
       "                                                                                                                            mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                          \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                   0.000000e+00   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                   0.000000e+00   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                   4.543683e-16   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                   3.111418e-04   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                   0.000000e+00   \n",
       "...                                                                                                                          ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                   1.591084e-02   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                   1.885621e-02   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                   4.470230e-02   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                   2.364277e-02   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                   1.851481e-02   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                   ...  \\\n",
       "                                                                                                   ...   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                          ...   \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5  ...   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5  ...   \n",
       "...                                                                                                ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5  ...   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5  ...   \n",
       "\n",
       "                                                                                                  noiseless_generalization_error_erm_erm  \\\n",
       "                                                                                                                                    mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                                  \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                    NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                    NaN   \n",
       "...                                                                                                                                  ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                                    NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                    NaN   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  noiseless_adversarial_generalization_error_erm  \\\n",
       "                                                                                                                                            mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                                          \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                            NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                            NaN   \n",
       "...                                                                                                                                          ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                                            NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                            NaN   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  noiseless_angle_to_generalisation_erm  \\\n",
       "                                                                                                                                   mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                                 \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                   NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                   NaN   \n",
       "...                                                                                                                                 ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                                   NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                   NaN   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  A_over_sqrt_qN_erm  \\\n",
       "                                                                                                                mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                              \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                NaN   \n",
       "...                                                                                                              ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                NaN   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  m_over_sqrt_rhoq_minus_m2_erm  \\\n",
       "                                                                                                                           mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                         \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                           NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                           NaN   \n",
       "...                                                                                                                         ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                           NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                           NaN   \n",
       "\n",
       "                                                                                                       \n",
       "                                                                                                  std  \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                              \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN  \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN  \n",
       "...                                                                                                ..  \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN  \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN  \n",
       "\n",
       "[239 rows x 214 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_powerlaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([0.0, 0.2], dtype='float64', name='epsilon'),\n",
       " Index([0.0, 0.2], dtype='float64', name='epsilon'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract unique epsilons\n",
    "epsilons = df_powerlaw.index.get_level_values(\"epsilon\").unique()\n",
    "epsilons_beta = df_powerlaw_beta.index.get_level_values(\"epsilon\").unique()\n",
    "epsilons, epsilons_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only attack_epsilon = 0.2\n",
    "df_powerlaw = df_powerlaw.xs(0.2, level=\"attack_epsilon\")\n",
    "df_powerlaw_beta = df_powerlaw_beta.xs(0.2, level=\"attack_epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KFeaturesModel_PowerLaw_Coefficient_0.5',\n",
       "       'KFeaturesModel_PowerLaw_Coefficient_1.5',\n",
       "       'KFeaturesModel_PowerLaw_Coefficient_2.5',\n",
       "       'KFeaturesModel_PowerLaw_Coefficient_3.5'],\n",
       "      dtype='object', name='data_model_name')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_names = df_powerlaw.index.get_level_values(\"data_model_name\").unique()\n",
    "data_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of dataframes for each data_model_name\n",
    "df_dict_beta = {}\n",
    "for data_model_name in data_model_names:\n",
    "\n",
    "    # the data_model_name is given by a string of this form 'KFeaturesModel_PowerLaw_Coefficient_3.5'\n",
    "    # we want to extract the coefficient\n",
    "    # split the string by '_'\n",
    "    split = data_model_name.split(\"_\")\n",
    "    # extract the coefficient\n",
    "    beta = split[-1]\n",
    "    # convert the beta to a float\n",
    "    beta = float(beta)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    df_data_model = df_powerlaw.xs(data_model_name, level=\"data_model_name\")\n",
    "\n",
    "    # for each data_model_name, create a dictionary\n",
    "    eps_dict = {}\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "\n",
    "\n",
    "        eps_df = df_data_model.xs(epsilon, level=\"epsilon\")\n",
    "\n",
    "        alphas = eps_df.index.get_level_values(\"alpha\").unique()\n",
    "        adversarial_error_0 = eps_df[\"adversarial_generalization_error_state_evolution\"][\"mean\"].values\n",
    "        generalization_error_0 = eps_df[\"generalization_error_state_evolution\"][\"mean\"].values\n",
    "        boundary_error_0 = eps_df[\"difference_adv_gen_state_evolution\"][\"mean\"].values\n",
    "        class_preserving = eps_df[\"fair_adversarial_error_state_evolution\"][\"mean\"].values\n",
    "\n",
    "        adversarial_error_erm = eps_df[\"adversarial_generalization_error_erm\"][\"mean\"].values\n",
    "        generalization_error_erm = eps_df[\"generalization_error_erm_erm\"][\"mean\"].values\n",
    "        boundary_error_erm = eps_df[\"difference_adv_gen_erm\"][\"mean\"].values\n",
    "        class_preserving_erm = eps_df[\"fair_adversarial_error_erm\"][\"mean\"].values\n",
    "\n",
    "        adversarial_error_erm_std = eps_df[\"adversarial_generalization_error_erm\"][\"std\"].values\n",
    "        generalization_error_erm_std = eps_df[\"generalization_error_erm_erm\"][\"std\"].values\n",
    "        boundary_error_erm_std = eps_df[\"difference_adv_gen_erm\"][\"std\"].values\n",
    "        class_preserving_erm_std = eps_df[\"fair_adversarial_error_erm\"][\"std\"].values\n",
    "\n",
    "        alphas = np.array(alphas)\n",
    "        adversarial_error_0 = np.array(adversarial_error_0)\n",
    "        generalization_error_0 = np.array(generalization_error_0)\n",
    "        boundary_error_0 = np.array(boundary_error_0)\n",
    "        class_preserving = np.array(class_preserving)\n",
    "\n",
    "        adversarial_error_erm = np.array(adversarial_error_erm)\n",
    "        generalization_error_erm = np.array(generalization_error_erm)\n",
    "        boundary_error_erm = np.array(boundary_error_erm)\n",
    "        class_preserving_erm = np.array(class_preserving_erm)\n",
    "\n",
    "        adversarial_error_erm_std = np.array(adversarial_error_erm_std)\n",
    "        generalization_error_erm_std = np.array(generalization_error_erm_std)\n",
    "        boundary_error_erm_std = np.array(boundary_error_erm_std)\n",
    "        class_preserving_erm_std = np.array(class_preserving_erm_std)\n",
    "\n",
    "        eps_0_dict = {}\n",
    "        eps_0_dict[\"alphas\"] = alphas\n",
    "        eps_0_dict[\"adversarial_error\"] = adversarial_error_0\n",
    "        eps_0_dict[\"generalization_error\"] = generalization_error_0\n",
    "        eps_0_dict[\"boundary_error\"] = boundary_error_0\n",
    "        eps_0_dict[\"class_preserving\"] = class_preserving\n",
    "\n",
    "        eps_0_dict[\"adversarial_error_erm\"] = adversarial_error_erm\n",
    "        eps_0_dict[\"generalization_error_erm\"] = generalization_error_erm\n",
    "        eps_0_dict[\"boundary_error_erm\"] = boundary_error_erm\n",
    "        eps_0_dict[\"class_preserving_erm\"] = class_preserving_erm\n",
    "\n",
    "        eps_0_dict[\"adversarial_error_erm_std\"] = adversarial_error_erm_std\n",
    "        eps_0_dict[\"generalization_error_erm_std\"] = generalization_error_erm_std\n",
    "        eps_0_dict[\"boundary_error_erm_std\"] = boundary_error_erm_std\n",
    "        eps_0_dict[\"class_preserving_erm_std\"] = class_preserving_erm_std\n",
    "\n",
    "\n",
    "        eps_dict[epsilon] = eps_0_dict\n",
    "\n",
    "\n",
    "    df_dict_beta[beta] = eps_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of dataframes for each data_model_name\n",
    "df_dict = {}\n",
    "for epsilon in epsilons:\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    eps_df = df_powerlaw_beta.xs(epsilon, level=\"epsilon\")\n",
    "\n",
    "\n",
    "\n",
    "    # for each data_model_name, create a dictionary\n",
    "    eps_dict = {}\n",
    "\n",
    "\n",
    "    betas = eps_df.index.get_level_values(\"beta\").unique()\n",
    "    adversarial_error_0 = eps_df[\"adversarial_generalization_error_state_evolution\"][\"mean\"].values\n",
    "    generalization_error_0 = eps_df[\"generalization_error_state_evolution\"][\"mean\"].values\n",
    "    boundary_error_0 = eps_df[\"difference_adv_gen_state_evolution\"][\"mean\"].values\n",
    "    class_preserving = eps_df[\"fair_adversarial_error_state_evolution\"][\"mean\"].values\n",
    "\n",
    "    adversarial_error_erm = eps_df[\"adversarial_generalization_error_erm\"][\"mean\"].values\n",
    "    generalization_error_erm = eps_df[\"generalization_error_erm_erm\"][\"mean\"].values\n",
    "    boundary_error_erm = eps_df[\"difference_adv_gen_erm\"][\"mean\"].values\n",
    "    class_preserving_erm = eps_df[\"fair_adversarial_error_erm\"][\"mean\"].values\n",
    "\n",
    "    adversarial_error_erm_std = eps_df[\"adversarial_generalization_error_erm\"][\"std\"].values\n",
    "    generalization_error_erm_std = eps_df[\"generalization_error_erm_erm\"][\"std\"].values\n",
    "    boundary_error_erm_std = eps_df[\"difference_adv_gen_erm\"][\"std\"].values\n",
    "    class_preserving_erm_std = eps_df[\"fair_adversarial_error_erm\"][\"std\"].values\n",
    "\n",
    "    betas = np.array(betas)\n",
    "    adversarial_error_0 = np.array(adversarial_error_0)\n",
    "    generalization_error_0 = np.array(generalization_error_0)\n",
    "    boundary_error_0 = np.array(boundary_error_0)\n",
    "    class_preserving = np.array(class_preserving)\n",
    "\n",
    "    adversarial_error_erm = np.array(adversarial_error_erm)\n",
    "    generalization_error_erm = np.array(generalization_error_erm)\n",
    "    boundary_error_erm = np.array(boundary_error_erm)\n",
    "    class_preserving_erm = np.array(class_preserving_erm)\n",
    "\n",
    "    adversarial_error_erm_std = np.array(adversarial_error_erm_std)\n",
    "    generalization_error_erm_std = np.array(generalization_error_erm_std)\n",
    "    boundary_error_erm_std = np.array(boundary_error_erm_std)\n",
    "    class_preserving_erm_std = np.array(class_preserving_erm_std)\n",
    "\n",
    "    eps_0_dict = {}\n",
    "    eps_0_dict[\"betas\"] = betas\n",
    "    eps_0_dict[\"adversarial_error\"] = adversarial_error_0\n",
    "    eps_0_dict[\"generalization_error\"] = generalization_error_0\n",
    "    eps_0_dict[\"boundary_error\"] = boundary_error_0\n",
    "    eps_0_dict[\"class_preserving\"] = class_preserving\n",
    "\n",
    "    eps_0_dict[\"adversarial_error_erm\"] = adversarial_error_erm\n",
    "    eps_0_dict[\"generalization_error_erm\"] = generalization_error_erm\n",
    "    eps_0_dict[\"boundary_error_erm\"] = boundary_error_erm\n",
    "    eps_0_dict[\"class_preserving_erm\"] = class_preserving_erm\n",
    "\n",
    "    eps_0_dict[\"adversarial_error_erm_std\"] = adversarial_error_erm_std\n",
    "    eps_0_dict[\"generalization_error_erm_std\"] = generalization_error_erm_std\n",
    "    eps_0_dict[\"boundary_error_erm_std\"] = boundary_error_erm_std\n",
    "    eps_0_dict[\"class_preserving_erm_std\"] = class_preserving_erm_std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_dict[epsilon] = eps_0_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasimirtanner/opt/anaconda3/envs/pdm/lib/python3.11/site-packages/matplotlib/axes/_base.py:2503: UserWarning: Warning: converting a masked element to nan.\n",
      "  xys = np.asarray(xys)\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 237.5x240 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "IMG_DIRECTORY = \"./Assets/powerlaw_combined\"\n",
    "if not os.path.exists(IMG_DIRECTORY):\n",
    "    os.makedirs(IMG_DIRECTORY)\n",
    "\n",
    "\n",
    "def save_plot(fig, name, formats=[\"pdf\",\"jpg\"], date=False):\n",
    "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    for f in formats:        \n",
    "        path = \"{}\".format(name) + \"_{}\".format(current_date) + \".\" + f\n",
    "        if not date:\n",
    "            path = \"{}\".format(name) + \".\" + f\n",
    "        fig.savefig(            \n",
    "            os.path.join(IMG_DIRECTORY, path),\n",
    "            format=f,\n",
    "        )\n",
    "\n",
    "\n",
    "def set_size(width, fraction=1, subplots=(1, 1)):\n",
    "    if width == \"thesis\":\n",
    "        width_pt = 426.79135\n",
    "    elif width == \"beamer\":\n",
    "        width_pt = 307.28987\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    golden_ratio = (5**0.5 - 1) / 2\n",
    "\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    fig_height_in = fig_width_in * (golden_ratio) * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n",
    "\n",
    "\n",
    "# width = 1.5 * 458.63788\n",
    "\n",
    "multiplier = 1.25 \n",
    "width = multiplier * 487.8225\n",
    "multiplier = 1.25\n",
    "width = multiplier * 1.5 * 234.8775\n",
    "\n",
    "plt.style.use(\"../latex_ready.mplstyle\")\n",
    "\n",
    "tuple_size = set_size(width, fraction=0.50)\n",
    "tuple_size = (2.375,2.4)\n",
    "\n",
    "multiplier = 0.9\n",
    "second_multiplier = 0.7\n",
    "\n",
    "\n",
    "# import Line2D for custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=1,\n",
    "    sharex=False,\n",
    "    sharey=False,\n",
    "    figsize=( tuple_size[0], tuple_size[1]),\n",
    "    gridspec_kw={\"hspace\": 0.33,\"wspace\": 0},\n",
    ")\n",
    "\n",
    "\n",
    "# ICML adjustments\n",
    "fig.subplots_adjust(left=0.01)\n",
    "fig.subplots_adjust(bottom=0.12)\n",
    "fig.subplots_adjust(top=0.99)\n",
    "fig.subplots_adjust(right=0.82)\n",
    "# plt.subplots_adjust(bottom=0.30)\n",
    "\n",
    "\n",
    "\n",
    "# Create a custom legend\n",
    "custom_legend = []\n",
    "\n",
    "linestyles = [\"solid\", \"dashed\", \"dashdot\", \"dotted\"]\n",
    "\n",
    "\n",
    "for epsilon_idx, epsilon in enumerate(epsilons):\n",
    "\n",
    "    # ax = axes[epsilon_idx]\n",
    "    ax = axes[0]\n",
    "\n",
    "    for df_idx, (key, value) in enumerate(df_dict_beta.items()):\n",
    "\n",
    "        beta = key\n",
    "\n",
    "\n",
    "        eps_dict = value[epsilon]\n",
    "\n",
    "        if beta == 0.5 or beta > 1.5:\n",
    "            continue\n",
    "\n",
    "        alphas = eps_dict[\"alphas\"]\n",
    "        adversarial_error = eps_dict[\"adversarial_error\"]\n",
    "        generalization_error = eps_dict[\"generalization_error\"]\n",
    "        boundary_error = eps_dict[\"boundary_error\"]\n",
    "        class_preserving = eps_dict[\"class_preserving\"]\n",
    "\n",
    "        adversarial_error_erm = eps_dict[\"adversarial_error_erm\"]\n",
    "        generalization_error_erm = eps_dict[\"generalization_error_erm\"]\n",
    "        boundary_error_erm = eps_dict[\"boundary_error_erm\"]\n",
    "        class_preserving_erm = eps_dict[\"class_preserving_erm\"]\n",
    "\n",
    "        adversarial_error_erm_std = eps_dict[\"adversarial_error_erm_std\"]\n",
    "        generalization_error_erm_std = eps_dict[\"generalization_error_erm_std\"]\n",
    "        boundary_error_erm_std = eps_dict[\"boundary_error_erm_std\"]\n",
    "        class_preserving_erm_std = eps_dict[\"class_preserving_erm_std\"]\n",
    "\n",
    "\n",
    "        adversarial_lines = ax.plot(alphas, adversarial_error, linestyle=linestyles[epsilon_idx],color=\"C0\")\n",
    "        ax.plot(alphas, generalization_error, linestyle=linestyles[epsilon_idx],color=\"C1\")\n",
    "        ax.plot(alphas, boundary_error,linestyle=linestyles[epsilon_idx], color=\"C2\")\n",
    "        # ax.plot(alphas, class_preserving,linestyle=linestyles[df_idx], color=\"C3\")\n",
    "\n",
    "        custom_legend.append(Line2D([0],[0],color=\"C0\", linestyle=linestyles[df_idx]))\n",
    "        custom_legend.append(Line2D([0],[0],color=\"C1\", linestyle=linestyles[df_idx]))\n",
    "        custom_legend.append(Line2D([0],[0],color=\"C2\", linestyle=linestyles[df_idx]))\n",
    "        # custom_legend.append(Line2D([0],[0],color=\"C3\", linestyle=linestyles[df_idx]))\n",
    "\n",
    "        ax.errorbar(\n",
    "            alphas,\n",
    "            adversarial_error_erm,\n",
    "            yerr=adversarial_error_erm_std,\n",
    "            fmt=\".\",\n",
    "            markersize=1,\n",
    "            color=\"C0\"\n",
    "        )\n",
    "        ax.errorbar(\n",
    "            alphas,\n",
    "            generalization_error_erm,\n",
    "            yerr=generalization_error_erm_std,\n",
    "            fmt=\".\",\n",
    "            markersize=1,\n",
    "            color=\"C1\"\n",
    "        )\n",
    "        ax.errorbar(\n",
    "            alphas,\n",
    "            boundary_error_erm,\n",
    "            yerr=boundary_error_erm_std,\n",
    "            fmt=\".\",\n",
    "            markersize=1,\n",
    "            color=\"C2\"\n",
    "        )\n",
    "        # axs.errorbar(\n",
    "        #     alphas,\n",
    "        #     class_preserving_erm,\n",
    "        #     yerr=class_preserving_erm_std,\n",
    "        #     fmt=\".\",\n",
    "        #     markersize=1,\n",
    "        #     color=\"C3\"\n",
    "        # )\n",
    "\n",
    "    ax.legend(title=f\"$\\\\beta={1.5}$\")\n",
    "    # Set the major ticks to face inwards\n",
    "    ax.tick_params(axis='both', which='major', direction='in')\n",
    "\n",
    "    # Set the minor ticks to face inwards\n",
    "    ax.tick_params(axis='both', which='minor', direction='in')\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ax.set_ylabel(r\"$E$\", labelpad=0.5)\n",
    "    ax.set_xlabel(r\"$\\alpha$\", labelpad=0.1)\n",
    "    ax.grid(which=\"both\", axis=\"both\", alpha=0.5)\n",
    "\n",
    "    # put the ylabel to the right\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "    \n",
    "\n",
    "\n",
    "    ax = axes[1]\n",
    "\n",
    "\n",
    "    eps_dict = df_dict[epsilon]\n",
    "\n",
    "\n",
    "    betas = eps_dict[\"betas\"]\n",
    "    adversarial_error = eps_dict[\"adversarial_error\"]\n",
    "    generalization_error = eps_dict[\"generalization_error\"]\n",
    "    boundary_error = eps_dict[\"boundary_error\"]\n",
    "    class_preserving = eps_dict[\"class_preserving\"]\n",
    "\n",
    "    adversarial_error_erm = eps_dict[\"adversarial_error_erm\"]\n",
    "    generalization_error_erm = eps_dict[\"generalization_error_erm\"]\n",
    "    boundary_error_erm = eps_dict[\"boundary_error_erm\"]\n",
    "    class_preserving_erm = eps_dict[\"class_preserving_erm\"]\n",
    "\n",
    "    adversarial_error_erm_std = eps_dict[\"adversarial_error_erm_std\"]\n",
    "    generalization_error_erm_std = eps_dict[\"generalization_error_erm_std\"]\n",
    "    boundary_error_erm_std = eps_dict[\"boundary_error_erm_std\"]\n",
    "    class_preserving_erm_std = eps_dict[\"class_preserving_erm_std\"]\n",
    "\n",
    "\n",
    "    adversarial_lines = ax.plot(betas, adversarial_error, linestyle=linestyles[epsilon_idx],color=\"C0\")\n",
    "    ax.plot(betas, generalization_error, linestyle=linestyles[epsilon_idx],color=\"C1\")\n",
    "    ax.plot(betas, boundary_error,linestyle=linestyles[epsilon_idx], color=\"C2\")\n",
    "\n",
    "\n",
    "    # ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "    ax.set_ylabel(r\"$E$\", labelpad=0.5)\n",
    "    ax.set_xlabel(r\"$\\beta$\", labelpad=0.1)\n",
    "    ax.grid(which=\"both\", axis=\"both\", alpha=0.5)\n",
    "\n",
    "    # put the ylabel to the right\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "\n",
    "\n",
    "    # Set the major ticks to face inwards\n",
    "    ax.tick_params(axis='both', which='major', direction='in')\n",
    "\n",
    "    # Set the minor ticks to face inwards\n",
    "    ax.tick_params(axis='both', which='minor', direction='in')\n",
    "\n",
    "\n",
    "\n",
    "error_legend = []\n",
    "\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{adv}}$\",color=\"C0\"))\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{gen}}$\",color=\"C1\"))\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{bound}}$\",color=\"C2\"))\n",
    "# error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{CP}}$\",color=\"C3\"))\n",
    "\n",
    "epsilon_legend = []\n",
    "\n",
    "for idx, (beta, value) in enumerate(df_dict.items()):\n",
    "    epsilon_legend.append(Line2D([0],[0],color=\"black\", linestyle=linestyles[idx], label=r\"$\\beta={}$\".format(beta))) \n",
    "\n",
    "\n",
    "custom_legend = []\n",
    "\n",
    "# mix the two legends\n",
    "for idx in range(len(error_legend)):\n",
    "    \n",
    "    # custom_legend.append(epsilon_legend[idx+1])\n",
    "    custom_legend.append(error_legend[idx])\n",
    "\n",
    "# custom_legend.append(epsilon_legend[-1])\n",
    "\n",
    "# Place the legend at the bottom of the figure\n",
    "# fig.legend(handles=custom_legend, loc='upper center', ncol=3, handlelength=1)\n",
    "\n",
    "fig.align_labels()\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    save_plot(\n",
    "        fig,\n",
    "        f\"powerlaw_combined\",\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
