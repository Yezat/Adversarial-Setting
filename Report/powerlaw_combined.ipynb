{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import inspect\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "\n",
    "from experiment_information import *\n",
    "from data import *\n",
    "from helpers import *\n",
    "from _version import __version__\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import pprint\n",
    "import re\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "# mpl.rcParams['lines.linewidth'] = 1\n",
    "# mpl.rcParams['legend.fontsize'] = 13\n",
    "\n",
    "# mpl.rcParams['axes.titlesize'] = 15\n",
    "# mpl.rcParams['axes.labelsize'] = 13\n",
    "# mpl.rcParams['xtick.labelsize'] = 10\n",
    "# mpl.rcParams['ytick.labelsize'] = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current code version,  103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from _version import __version__\n",
    "df_experiments = None\n",
    "df_state_evolution = None\n",
    "df_erm = None\n",
    "logger = logging.getLogger()\n",
    "# with DatabaseHandler(logger,\"experiments/experiments.db\") as dbHandler:\n",
    "with DatabaseHandler(logger,\"../experiments/experiments.db\") as dbHandler:\n",
    "\n",
    "    df_experiments = dbHandler.get_experiments()\n",
    "    df_state_evolution = dbHandler.get_state_evolutions()\n",
    "    df_state_evolution[\"calibrations\"] = df_state_evolution[\"calibrations\"].apply(lambda x: json.loads(x))\n",
    "    df_erm = dbHandler.get_erms()\n",
    "    df_erm[\"analytical_calibrations\"] = df_erm[\"analytical_calibrations\"].apply(lambda x: json.loads(x))\n",
    "    df_erm[\"erm_calibrations\"] = df_erm[\"erm_calibrations\"].apply(lambda x: json.loads(x))\n",
    "    # delete incomplete experiments (bad, deletes running experiments...)\n",
    "    # dbHandler.delete_incomplete_experiments()\n",
    "\n",
    "# def explode_calibrations(df):\n",
    "#     a = df[\"calibrations\"].apply(pd.Series)\n",
    "#     # drop the original calibrations column\n",
    "#     df = df.drop(columns=[\"calibrations\"])\n",
    "#     # concat the original dataframe with the new dataframe containing the exploded calibrations column\n",
    "#     df = pd.concat([df,a],axis=1)\n",
    "#     # explode both calibrations and ps columns\n",
    "#     df = df.explode([\"calibrations\",\"ps\"])\n",
    "#     # rename the exploded columns\n",
    "#     df = df.rename(columns={\"calibrations\":\"calibration\",\"ps\":\"p_calibration\"})\n",
    "#     return df\n",
    "# df_state_evolution = explode_calibrations(df_state_evolution)\n",
    "# def explode_erm_calibrations(df):\n",
    "#     a = df[\"erm_calibrations\"].apply(pd.Series)\n",
    "#     # drop the original calibrations column\n",
    "#     df = df.drop(columns=[\"erm_calibrations\"])\n",
    "#     b = df[\"analytical_calibrations\"].apply(pd.Series)\n",
    "#     # drop the original calibrations column\n",
    "#     df = df.drop(columns=[\"analytical_calibrations\"])\n",
    "#     # drop the dp and ps columns from b\n",
    "#     b = b.drop(columns=[\"dp\",\"ps\"])\n",
    "#     # rename the columns of b\n",
    "#     b = b.rename(columns={\"calibrations\":\"analytical_calibration\"})\n",
    "#     # rename the columns of a\n",
    "#     a = a.rename(columns={\"calibrations\":\"erm_calibration\"})\n",
    "#     # concat the original dataframe with the new dataframe containing the exploded calibrations column\n",
    "#     df = pd.concat([df,a],axis=1)\n",
    "#     df = pd.concat([df,b],axis=1)\n",
    "#     # explode both calibrations and ps columns\n",
    "#     df = df.explode([\"erm_calibration\",\"analytical_calibration\",\"ps\"])\n",
    "#     # rename the exploded columns\n",
    "#     df = df.rename(columns={\"ps\":\"p_calibration\"})\n",
    "#     return df\n",
    "# df_erm = explode_erm_calibrations(df_erm)\n",
    "\n",
    "def explode_measures(df, new_columns, columns):\n",
    "    for column in columns:\n",
    "        def transform(column):\n",
    "            # replace NaN in the column string by 0\n",
    "            column = column.replace(\"NaN\",\"0\")\n",
    "            # replace null in the column string by 0\n",
    "            column = column.replace(\"null\",\"0\")\n",
    "            # replace Infinity in the column string by np.inf\n",
    "            column = column.replace(\"Infinity\",\"np.inf\")\n",
    "            return eval(column)\n",
    "        df[column] = df[column].apply(transform)\n",
    "\n",
    "    exploded = df.explode(columns).reset_index(drop=True)\n",
    "\n",
    "    for new_column, column in zip(new_columns, columns):\n",
    "        if len(exploded[column].tolist()) > 0:\n",
    "            exploded[[\"attack_epsilon\",new_column]] = pd.DataFrame(exploded[column].tolist(), index=exploded.index)\n",
    "        else:\n",
    "            exploded[new_column] = np.nan\n",
    "            # set attack_epsilon\n",
    "            exploded[\"attack_epsilon\"] = np.nan\n",
    "\n",
    "    exploded = exploded.drop(columns=columns)\n",
    "    return exploded\n",
    "\n",
    "\n",
    "def explode_erm_measures(df):\n",
    "    columns = [\"adversarial_generalization_errors\",\"adversarial_generalization_errors_teacher\",\"adversarial_generalization_errors_overlap\",\"fair_adversarial_errors\",\"test_losses\",\"boundary_loss_test_es\"]\n",
    "    new_columns = [\"adversarial_generalization_error\",\"adversarial_generalization_error_teacher\",\"adversarial_generalization_error_overlap\",\"fair_adversarial_error\",\"test_loss\",\"boundary_loss_test\"]\n",
    "    return explode_measures(df, new_columns, columns)\n",
    "\n",
    "def explode_state_evolution_measures(df):\n",
    "    columns = [\"adversarial_generalization_errors\",\"adversarial_generalization_errors_teacher\",\"fair_adversarial_errors\",\"first_term_fair_errors\",\"second_term_fair_errors\",\"third_term_fair_errors\",\"test_losses\",\"data_model_adversarial_generalization_errors\",\"gamma_robustness_es\",\"boundary_loss_test_es\"]\n",
    "    new_columns = [\"adversarial_generalization_error\",\"adversarial_generalization_error_teacher\",\"fair_adversarial_error\",\"first_term_fair_error\",\"second_term_fair_error\",\"third_term_fair_error\",\"test_loss\",\"data_model_adversarial_generalization_error\",\"gamma_robustness\",\"boundary_loss_test\"] #\n",
    "    # columns = [\"adversarial_generalization_errors\",\"adversarial_generalization_errors_teacher\",\"fair_adversarial_errors\",\"second_term_fair_errors\",\"test_losses\",\"data_model_adversarial_generalization_errors\"]\n",
    "    # new_columns = [\"adversarial_generalization_error\",\"adversarial_generalization_error_teacher\",\"fair_adversarial_error\",\"second_term_fair_error\",\"test_loss\",\"data_model_adversarial_generalization_error\"] #\n",
    "    return explode_measures(df, new_columns, columns)\n",
    "    \n",
    "\n",
    "df_erm = explode_erm_measures(df_erm)\n",
    "\n",
    "df_state_evolution = explode_state_evolution_measures(df_state_evolution)\n",
    "    \n",
    "\n",
    "print(\"Current code version, \", __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from the pickle file\n",
    "df_powerlaw = pd.read_pickle(\"Pickles/powerlaw.pkl\")\n",
    "df_powerlaw_beta = pd.read_pickle(\"Pickles/powerlaw_beta.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">index_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duration_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">generalization_error_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_loss_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_error_state_evolution</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_generalization_error_erm_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_adversarial_generalization_error_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_angle_to_generalisation_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">A_over_sqrt_qN_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">m_over_sqrt_rhoq_minus_m2_erm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>tau</th>\n",
       "      <th>lam</th>\n",
       "      <th>problem_type</th>\n",
       "      <th>attack_epsilon</th>\n",
       "      <th>beta</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"57\" valign=\"top\">1000000.0</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0.2</th>\n",
       "      <th>1.0100</th>\n",
       "      <td>2554.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.394917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0786</th>\n",
       "      <td>2576.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.229608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1472</th>\n",
       "      <td>2562.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.833769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2159</th>\n",
       "      <td>2579.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.150451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2845</th>\n",
       "      <td>2580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.734781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.3531</th>\n",
       "      <td>2559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.605435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4217</th>\n",
       "      <td>2563.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.049522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4903</th>\n",
       "      <td>2569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.688163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5590</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.599281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6276</th>\n",
       "      <td>2573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.424234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6962</th>\n",
       "      <td>2552.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.246767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7648</th>\n",
       "      <td>2557.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.474566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.8334</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.728134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9021</th>\n",
       "      <td>2561.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.755066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9707</th>\n",
       "      <td>2555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.398739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0393</th>\n",
       "      <td>2556.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.512595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1079</th>\n",
       "      <td>2564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.063672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1766</th>\n",
       "      <td>2574.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.778338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2452</th>\n",
       "      <td>2553.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.329678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3138</th>\n",
       "      <td>2565.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.423140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3824</th>\n",
       "      <td>2566.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.160854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4510</th>\n",
       "      <td>2567.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.186757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5197</th>\n",
       "      <td>2568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.171784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5883</th>\n",
       "      <td>2577.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.196321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6569</th>\n",
       "      <td>2570.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.087158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7255</th>\n",
       "      <td>2572.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.113260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7941</th>\n",
       "      <td>2575.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.068408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8628</th>\n",
       "      <td>2578.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.239524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.9314</th>\n",
       "      <td>2581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.360811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0000</th>\n",
       "      <td>2582.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.014006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"27\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"27\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"27\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"27\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"27\" valign=\"top\">0.2</th>\n",
       "      <th>1.0100</th>\n",
       "      <td>2526.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.291322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0786</th>\n",
       "      <td>2529.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.276258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.249811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1472</th>\n",
       "      <td>2527.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.246571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2159</th>\n",
       "      <td>2530.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.272475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.237205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2845</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.418728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.3531</th>\n",
       "      <td>2528.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.232853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.219647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4217</th>\n",
       "      <td>2531.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.290087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.209334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4903</th>\n",
       "      <td>2532.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.384158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5590</th>\n",
       "      <td>2534.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.522384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6276</th>\n",
       "      <td>2535.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.637439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6962</th>\n",
       "      <td>2536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.869876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.165584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7648</th>\n",
       "      <td>2537.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.033793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.155522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9021</th>\n",
       "      <td>2538.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.593936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9707</th>\n",
       "      <td>2539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.928123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0393</th>\n",
       "      <td>2540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.282654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1079</th>\n",
       "      <td>2541.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.676319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.116148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1766</th>\n",
       "      <td>2542.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.098309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2452</th>\n",
       "      <td>2543.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.098448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3138</th>\n",
       "      <td>2544.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.268554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5197</th>\n",
       "      <td>2545.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.234128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5883</th>\n",
       "      <td>2546.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.753136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6569</th>\n",
       "      <td>2547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.346455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7255</th>\n",
       "      <td>2548.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.802316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7941</th>\n",
       "      <td>2549.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.186970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8628</th>\n",
       "      <td>2550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.354544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.9314</th>\n",
       "      <td>2551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.424250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0000</th>\n",
       "      <td>2571.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.509024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                index_state_evolution  \\\n",
       "                                                                                 mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                           \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                2554.0   \n",
       "                                                         1.0786                2576.0   \n",
       "                                                         1.1472                2562.0   \n",
       "                                                         1.2159                2579.0   \n",
       "                                                         1.2845                2580.0   \n",
       "                                                         1.3531                2559.0   \n",
       "                                                         1.4217                2563.0   \n",
       "                                                         1.4903                2569.0   \n",
       "                                                         1.5590                2558.0   \n",
       "                                                         1.6276                2573.0   \n",
       "                                                         1.6962                2552.0   \n",
       "                                                         1.7648                2557.0   \n",
       "                                                         1.8334                2560.0   \n",
       "                                                         1.9021                2561.0   \n",
       "                                                         1.9707                2555.0   \n",
       "                                                         2.0393                2556.0   \n",
       "                                                         2.1079                2564.0   \n",
       "                                                         2.1766                2574.0   \n",
       "                                                         2.2452                2553.0   \n",
       "                                                         2.3138                2565.0   \n",
       "                                                         2.3824                2566.0   \n",
       "                                                         2.4510                2567.0   \n",
       "                                                         2.5197                2568.0   \n",
       "                                                         2.5883                2577.0   \n",
       "                                                         2.6569                2570.0   \n",
       "                                                         2.7255                2572.0   \n",
       "                                                         2.7941                2575.0   \n",
       "                                                         2.8628                2578.0   \n",
       "                                                         2.9314                2581.0   \n",
       "                                                         3.0000                2582.0   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                2526.0   \n",
       "                                                         1.0786                2529.0   \n",
       "                                                         1.1472                2527.0   \n",
       "                                                         1.2159                2530.0   \n",
       "                                                         1.2845                2533.0   \n",
       "                                                         1.3531                2528.0   \n",
       "                                                         1.4217                2531.0   \n",
       "                                                         1.4903                2532.0   \n",
       "                                                         1.5590                2534.0   \n",
       "                                                         1.6276                2535.0   \n",
       "                                                         1.6962                2536.0   \n",
       "                                                         1.7648                2537.0   \n",
       "                                                         1.9021                2538.0   \n",
       "                                                         1.9707                2539.0   \n",
       "                                                         2.0393                2540.0   \n",
       "                                                         2.1079                2541.0   \n",
       "                                                         2.1766                2542.0   \n",
       "                                                         2.2452                2543.0   \n",
       "                                                         2.3138                2544.0   \n",
       "                                                         2.5197                2545.0   \n",
       "                                                         2.5883                2546.0   \n",
       "                                                         2.6569                2547.0   \n",
       "                                                         2.7255                2548.0   \n",
       "                                                         2.7941                2549.0   \n",
       "                                                         2.8628                2550.0   \n",
       "                                                         2.9314                2551.0   \n",
       "                                                         3.0000                2571.0   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                duration_state_evolution  \\\n",
       "                                                                                    mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                              \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                17.394917   \n",
       "                                                         1.0786                18.229608   \n",
       "                                                         1.1472                17.833769   \n",
       "                                                         1.2159                21.150451   \n",
       "                                                         1.2845                22.734781   \n",
       "                                                         1.3531                17.605435   \n",
       "                                                         1.4217                18.049522   \n",
       "                                                         1.4903                18.688163   \n",
       "                                                         1.5590                17.599281   \n",
       "                                                         1.6276                19.424234   \n",
       "                                                         1.6962                17.246767   \n",
       "                                                         1.7648                17.474566   \n",
       "                                                         1.8334                17.728134   \n",
       "                                                         1.9021                17.755066   \n",
       "                                                         1.9707                17.398739   \n",
       "                                                         2.0393                17.512595   \n",
       "                                                         2.1079                18.063672   \n",
       "                                                         2.1766                19.778338   \n",
       "                                                         2.2452                17.329678   \n",
       "                                                         2.3138                18.423140   \n",
       "                                                         2.3824                16.160854   \n",
       "                                                         2.4510                16.186757   \n",
       "                                                         2.5197                16.171784   \n",
       "                                                         2.5883                18.196321   \n",
       "                                                         2.6569                16.087158   \n",
       "                                                         2.7255                16.113260   \n",
       "                                                         2.7941                16.068408   \n",
       "                                                         2.8628                16.239524   \n",
       "                                                         2.9314                17.360811   \n",
       "                                                         3.0000                16.014006   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                 2.291322   \n",
       "                                                         1.0786                 2.276258   \n",
       "                                                         1.1472                 2.246571   \n",
       "                                                         1.2159                 2.272475   \n",
       "                                                         1.2845                 2.418728   \n",
       "                                                         1.3531                 2.232853   \n",
       "                                                         1.4217                 2.290087   \n",
       "                                                         1.4903                 2.384158   \n",
       "                                                         1.5590                 2.522384   \n",
       "                                                         1.6276                 2.637439   \n",
       "                                                         1.6962                 2.869876   \n",
       "                                                         1.7648                 3.033793   \n",
       "                                                         1.9021                 3.593936   \n",
       "                                                         1.9707                 3.928123   \n",
       "                                                         2.0393                 4.282654   \n",
       "                                                         2.1079                 4.676319   \n",
       "                                                         2.1766                 5.098309   \n",
       "                                                         2.2452                 6.098448   \n",
       "                                                         2.3138                 5.268554   \n",
       "                                                         2.5197                 6.234128   \n",
       "                                                         2.5883                 6.753136   \n",
       "                                                         2.6569                 7.346455   \n",
       "                                                         2.7255                 7.802316   \n",
       "                                                         2.7941                 8.186970   \n",
       "                                                         2.8628                 8.354544   \n",
       "                                                         2.9314                 9.424250   \n",
       "                                                         3.0000                 9.509024   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                generalization_error_state_evolution  \\\n",
       "                                                                                                mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                          \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                             0.015902   \n",
       "                                                         1.0786                             0.015902   \n",
       "                                                         1.1472                             0.015902   \n",
       "                                                         1.2159                             0.015902   \n",
       "                                                         1.2845                             0.015902   \n",
       "                                                         1.3531                             0.015902   \n",
       "                                                         1.4217                             0.015902   \n",
       "                                                         1.4903                             0.015902   \n",
       "                                                         1.5590                             0.015902   \n",
       "                                                         1.6276                             0.015902   \n",
       "                                                         1.6962                             0.015902   \n",
       "                                                         1.7648                             0.015902   \n",
       "                                                         1.8334                             0.015902   \n",
       "                                                         1.9021                             0.015902   \n",
       "                                                         1.9707                             0.015902   \n",
       "                                                         2.0393                             0.015902   \n",
       "                                                         2.1079                             0.015902   \n",
       "                                                         2.1766                             0.015902   \n",
       "                                                         2.2452                             0.015902   \n",
       "                                                         2.3138                             0.015902   \n",
       "                                                         2.3824                             0.015902   \n",
       "                                                         2.4510                             0.015902   \n",
       "                                                         2.5197                             0.015902   \n",
       "                                                         2.5883                             0.015902   \n",
       "                                                         2.6569                             0.015902   \n",
       "                                                         2.7255                             0.015902   \n",
       "                                                         2.7941                             0.015902   \n",
       "                                                         2.8628                             0.015902   \n",
       "                                                         2.9314                             0.015902   \n",
       "                                                         3.0000                             0.015902   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                             0.031410   \n",
       "                                                         1.0786                             0.034129   \n",
       "                                                         1.1472                             0.036942   \n",
       "                                                         1.2159                             0.039666   \n",
       "                                                         1.2845                             0.042035   \n",
       "                                                         1.3531                             0.043783   \n",
       "                                                         1.4217                             0.044709   \n",
       "                                                         1.4903                             0.044758   \n",
       "                                                         1.5590                             0.044022   \n",
       "                                                         1.6276                             0.042686   \n",
       "                                                         1.6962                             0.040959   \n",
       "                                                         1.7648                             0.039023   \n",
       "                                                         1.9021                             0.035052   \n",
       "                                                         1.9707                             0.033184   \n",
       "                                                         2.0393                             0.031453   \n",
       "                                                         2.1079                             0.029875   \n",
       "                                                         2.1766                             0.028453   \n",
       "                                                         2.2452                             0.027180   \n",
       "                                                         2.3138                             0.026064   \n",
       "                                                         2.5197                             0.023431   \n",
       "                                                         2.5883                             0.022756   \n",
       "                                                         2.6569                             0.022161   \n",
       "                                                         2.7255                             0.021636   \n",
       "                                                         2.7941                             0.021173   \n",
       "                                                         2.8628                             0.020762   \n",
       "                                                         2.9314                             0.020397   \n",
       "                                                         3.0000                             0.020072   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                training_loss_state_evolution  \\\n",
       "                                                                                         mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                   \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                      0.036130   \n",
       "                                                         1.0786                      0.036130   \n",
       "                                                         1.1472                      0.036130   \n",
       "                                                         1.2159                      0.036130   \n",
       "                                                         1.2845                      0.036130   \n",
       "                                                         1.3531                      0.036130   \n",
       "                                                         1.4217                      0.036130   \n",
       "                                                         1.4903                      0.036130   \n",
       "                                                         1.5590                      0.036130   \n",
       "                                                         1.6276                      0.036130   \n",
       "                                                         1.6962                      0.036130   \n",
       "                                                         1.7648                      0.036130   \n",
       "                                                         1.8334                      0.036130   \n",
       "                                                         1.9021                      0.036130   \n",
       "                                                         1.9707                      0.036130   \n",
       "                                                         2.0393                      0.036130   \n",
       "                                                         2.1079                      0.036130   \n",
       "                                                         2.1766                      0.036130   \n",
       "                                                         2.2452                      0.036130   \n",
       "                                                         2.3138                      0.036130   \n",
       "                                                         2.3824                      0.036130   \n",
       "                                                         2.4510                      0.036130   \n",
       "                                                         2.5197                      0.036130   \n",
       "                                                         2.5883                      0.036130   \n",
       "                                                         2.6569                      0.036130   \n",
       "                                                         2.7255                      0.036130   \n",
       "                                                         2.7941                      0.036130   \n",
       "                                                         2.8628                      0.036130   \n",
       "                                                         2.9314                      0.036130   \n",
       "                                                         3.0000                      0.036130   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                      0.254386   \n",
       "                                                         1.0786                      0.249811   \n",
       "                                                         1.1472                      0.244130   \n",
       "                                                         1.2159                      0.237205   \n",
       "                                                         1.2845                      0.229016   \n",
       "                                                         1.3531                      0.219647   \n",
       "                                                         1.4217                      0.209334   \n",
       "                                                         1.4903                      0.198417   \n",
       "                                                         1.5590                      0.187255   \n",
       "                                                         1.6276                      0.176225   \n",
       "                                                         1.6962                      0.165584   \n",
       "                                                         1.7648                      0.155522   \n",
       "                                                         1.9021                      0.137527   \n",
       "                                                         1.9707                      0.129672   \n",
       "                                                         2.0393                      0.122560   \n",
       "                                                         2.1079                      0.116148   \n",
       "                                                         2.1766                      0.110378   \n",
       "                                                         2.2452                      0.105211   \n",
       "                                                         2.3138                      0.100579   \n",
       "                                                         2.5197                      0.089351   \n",
       "                                                         2.5883                      0.086340   \n",
       "                                                         2.6569                      0.083625   \n",
       "                                                         2.7255                      0.081171   \n",
       "                                                         2.7941                      0.078947   \n",
       "                                                         2.8628                      0.076924   \n",
       "                                                         2.9314                      0.075084   \n",
       "                                                         3.0000                      0.073404   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                training_error_state_evolution  \\\n",
       "                                                                                          mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                    \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                       0.015902   \n",
       "                                                         1.0786                       0.015902   \n",
       "                                                         1.1472                       0.015902   \n",
       "                                                         1.2159                       0.015902   \n",
       "                                                         1.2845                       0.015902   \n",
       "                                                         1.3531                       0.015902   \n",
       "                                                         1.4217                       0.015902   \n",
       "                                                         1.4903                       0.015902   \n",
       "                                                         1.5590                       0.015902   \n",
       "                                                         1.6276                       0.015902   \n",
       "                                                         1.6962                       0.015902   \n",
       "                                                         1.7648                       0.015902   \n",
       "                                                         1.8334                       0.015902   \n",
       "                                                         1.9021                       0.015902   \n",
       "                                                         1.9707                       0.015902   \n",
       "                                                         2.0393                       0.015902   \n",
       "                                                         2.1079                       0.015902   \n",
       "                                                         2.1766                       0.015902   \n",
       "                                                         2.2452                       0.015902   \n",
       "                                                         2.3138                       0.015902   \n",
       "                                                         2.3824                       0.015902   \n",
       "                                                         2.4510                       0.015902   \n",
       "                                                         2.5197                       0.015902   \n",
       "                                                         2.5883                       0.015902   \n",
       "                                                         2.6569                       0.015902   \n",
       "                                                         2.7255                       0.015902   \n",
       "                                                         2.7941                       0.015902   \n",
       "                                                         2.8628                       0.015902   \n",
       "                                                         2.9314                       0.015902   \n",
       "                                                         3.0000                       0.015902   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                       0.031410   \n",
       "                                                         1.0786                       0.034129   \n",
       "                                                         1.1472                       0.036942   \n",
       "                                                         1.2159                       0.039666   \n",
       "                                                         1.2845                       0.042035   \n",
       "                                                         1.3531                       0.043783   \n",
       "                                                         1.4217                       0.044709   \n",
       "                                                         1.4903                       0.044758   \n",
       "                                                         1.5590                       0.044022   \n",
       "                                                         1.6276                       0.042686   \n",
       "                                                         1.6962                       0.040959   \n",
       "                                                         1.7648                       0.039023   \n",
       "                                                         1.9021                       0.035052   \n",
       "                                                         1.9707                       0.033184   \n",
       "                                                         2.0393                       0.031453   \n",
       "                                                         2.1079                       0.029875   \n",
       "                                                         2.1766                       0.028453   \n",
       "                                                         2.2452                       0.027180   \n",
       "                                                         2.3138                       0.026064   \n",
       "                                                         2.5197                       0.023431   \n",
       "                                                         2.5883                       0.022756   \n",
       "                                                         2.6569                       0.022161   \n",
       "                                                         2.7255                       0.021636   \n",
       "                                                         2.7941                       0.021173   \n",
       "                                                         2.8628                       0.020762   \n",
       "                                                         2.9314                       0.020397   \n",
       "                                                         3.0000                       0.020072   \n",
       "\n",
       "                                                                     ...  \\\n",
       "                                                                std  ...   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta        ...   \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN  ...   \n",
       "                                                         1.0786 NaN  ...   \n",
       "                                                         1.1472 NaN  ...   \n",
       "                                                         1.2159 NaN  ...   \n",
       "                                                         1.2845 NaN  ...   \n",
       "                                                         1.3531 NaN  ...   \n",
       "                                                         1.4217 NaN  ...   \n",
       "                                                         1.4903 NaN  ...   \n",
       "                                                         1.5590 NaN  ...   \n",
       "                                                         1.6276 NaN  ...   \n",
       "                                                         1.6962 NaN  ...   \n",
       "                                                         1.7648 NaN  ...   \n",
       "                                                         1.8334 NaN  ...   \n",
       "                                                         1.9021 NaN  ...   \n",
       "                                                         1.9707 NaN  ...   \n",
       "                                                         2.0393 NaN  ...   \n",
       "                                                         2.1079 NaN  ...   \n",
       "                                                         2.1766 NaN  ...   \n",
       "                                                         2.2452 NaN  ...   \n",
       "                                                         2.3138 NaN  ...   \n",
       "                                                         2.3824 NaN  ...   \n",
       "                                                         2.4510 NaN  ...   \n",
       "                                                         2.5197 NaN  ...   \n",
       "                                                         2.5883 NaN  ...   \n",
       "                                                         2.6569 NaN  ...   \n",
       "                                                         2.7255 NaN  ...   \n",
       "                                                         2.7941 NaN  ...   \n",
       "                                                         2.8628 NaN  ...   \n",
       "                                                         2.9314 NaN  ...   \n",
       "                                                         3.0000 NaN  ...   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN  ...   \n",
       "                                                         1.0786 NaN  ...   \n",
       "                                                         1.1472 NaN  ...   \n",
       "                                                         1.2159 NaN  ...   \n",
       "                                                         1.2845 NaN  ...   \n",
       "                                                         1.3531 NaN  ...   \n",
       "                                                         1.4217 NaN  ...   \n",
       "                                                         1.4903 NaN  ...   \n",
       "                                                         1.5590 NaN  ...   \n",
       "                                                         1.6276 NaN  ...   \n",
       "                                                         1.6962 NaN  ...   \n",
       "                                                         1.7648 NaN  ...   \n",
       "                                                         1.9021 NaN  ...   \n",
       "                                                         1.9707 NaN  ...   \n",
       "                                                         2.0393 NaN  ...   \n",
       "                                                         2.1079 NaN  ...   \n",
       "                                                         2.1766 NaN  ...   \n",
       "                                                         2.2452 NaN  ...   \n",
       "                                                         2.3138 NaN  ...   \n",
       "                                                         2.5197 NaN  ...   \n",
       "                                                         2.5883 NaN  ...   \n",
       "                                                         2.6569 NaN  ...   \n",
       "                                                         2.7255 NaN  ...   \n",
       "                                                         2.7941 NaN  ...   \n",
       "                                                         2.8628 NaN  ...   \n",
       "                                                         2.9314 NaN  ...   \n",
       "                                                         3.0000 NaN  ...   \n",
       "\n",
       "                                                                noiseless_generalization_error_erm_erm  \\\n",
       "                                                                                                  mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                            \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                                    NaN   \n",
       "                                                         1.0786                                    NaN   \n",
       "                                                         1.1472                                    NaN   \n",
       "                                                         1.2159                                    NaN   \n",
       "                                                         1.2845                                    NaN   \n",
       "                                                         1.3531                                    NaN   \n",
       "                                                         1.4217                                    NaN   \n",
       "                                                         1.4903                                    NaN   \n",
       "                                                         1.5590                                    NaN   \n",
       "                                                         1.6276                                    NaN   \n",
       "                                                         1.6962                                    NaN   \n",
       "                                                         1.7648                                    NaN   \n",
       "                                                         1.8334                                    NaN   \n",
       "                                                         1.9021                                    NaN   \n",
       "                                                         1.9707                                    NaN   \n",
       "                                                         2.0393                                    NaN   \n",
       "                                                         2.1079                                    NaN   \n",
       "                                                         2.1766                                    NaN   \n",
       "                                                         2.2452                                    NaN   \n",
       "                                                         2.3138                                    NaN   \n",
       "                                                         2.3824                                    NaN   \n",
       "                                                         2.4510                                    NaN   \n",
       "                                                         2.5197                                    NaN   \n",
       "                                                         2.5883                                    NaN   \n",
       "                                                         2.6569                                    NaN   \n",
       "                                                         2.7255                                    NaN   \n",
       "                                                         2.7941                                    NaN   \n",
       "                                                         2.8628                                    NaN   \n",
       "                                                         2.9314                                    NaN   \n",
       "                                                         3.0000                                    NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                                    NaN   \n",
       "                                                         1.0786                                    NaN   \n",
       "                                                         1.1472                                    NaN   \n",
       "                                                         1.2159                                    NaN   \n",
       "                                                         1.2845                                    NaN   \n",
       "                                                         1.3531                                    NaN   \n",
       "                                                         1.4217                                    NaN   \n",
       "                                                         1.4903                                    NaN   \n",
       "                                                         1.5590                                    NaN   \n",
       "                                                         1.6276                                    NaN   \n",
       "                                                         1.6962                                    NaN   \n",
       "                                                         1.7648                                    NaN   \n",
       "                                                         1.9021                                    NaN   \n",
       "                                                         1.9707                                    NaN   \n",
       "                                                         2.0393                                    NaN   \n",
       "                                                         2.1079                                    NaN   \n",
       "                                                         2.1766                                    NaN   \n",
       "                                                         2.2452                                    NaN   \n",
       "                                                         2.3138                                    NaN   \n",
       "                                                         2.5197                                    NaN   \n",
       "                                                         2.5883                                    NaN   \n",
       "                                                         2.6569                                    NaN   \n",
       "                                                         2.7255                                    NaN   \n",
       "                                                         2.7941                                    NaN   \n",
       "                                                         2.8628                                    NaN   \n",
       "                                                         2.9314                                    NaN   \n",
       "                                                         3.0000                                    NaN   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                noiseless_adversarial_generalization_error_erm  \\\n",
       "                                                                                                          mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                                    \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                                            NaN   \n",
       "                                                         1.0786                                            NaN   \n",
       "                                                         1.1472                                            NaN   \n",
       "                                                         1.2159                                            NaN   \n",
       "                                                         1.2845                                            NaN   \n",
       "                                                         1.3531                                            NaN   \n",
       "                                                         1.4217                                            NaN   \n",
       "                                                         1.4903                                            NaN   \n",
       "                                                         1.5590                                            NaN   \n",
       "                                                         1.6276                                            NaN   \n",
       "                                                         1.6962                                            NaN   \n",
       "                                                         1.7648                                            NaN   \n",
       "                                                         1.8334                                            NaN   \n",
       "                                                         1.9021                                            NaN   \n",
       "                                                         1.9707                                            NaN   \n",
       "                                                         2.0393                                            NaN   \n",
       "                                                         2.1079                                            NaN   \n",
       "                                                         2.1766                                            NaN   \n",
       "                                                         2.2452                                            NaN   \n",
       "                                                         2.3138                                            NaN   \n",
       "                                                         2.3824                                            NaN   \n",
       "                                                         2.4510                                            NaN   \n",
       "                                                         2.5197                                            NaN   \n",
       "                                                         2.5883                                            NaN   \n",
       "                                                         2.6569                                            NaN   \n",
       "                                                         2.7255                                            NaN   \n",
       "                                                         2.7941                                            NaN   \n",
       "                                                         2.8628                                            NaN   \n",
       "                                                         2.9314                                            NaN   \n",
       "                                                         3.0000                                            NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                                            NaN   \n",
       "                                                         1.0786                                            NaN   \n",
       "                                                         1.1472                                            NaN   \n",
       "                                                         1.2159                                            NaN   \n",
       "                                                         1.2845                                            NaN   \n",
       "                                                         1.3531                                            NaN   \n",
       "                                                         1.4217                                            NaN   \n",
       "                                                         1.4903                                            NaN   \n",
       "                                                         1.5590                                            NaN   \n",
       "                                                         1.6276                                            NaN   \n",
       "                                                         1.6962                                            NaN   \n",
       "                                                         1.7648                                            NaN   \n",
       "                                                         1.9021                                            NaN   \n",
       "                                                         1.9707                                            NaN   \n",
       "                                                         2.0393                                            NaN   \n",
       "                                                         2.1079                                            NaN   \n",
       "                                                         2.1766                                            NaN   \n",
       "                                                         2.2452                                            NaN   \n",
       "                                                         2.3138                                            NaN   \n",
       "                                                         2.5197                                            NaN   \n",
       "                                                         2.5883                                            NaN   \n",
       "                                                         2.6569                                            NaN   \n",
       "                                                         2.7255                                            NaN   \n",
       "                                                         2.7941                                            NaN   \n",
       "                                                         2.8628                                            NaN   \n",
       "                                                         2.9314                                            NaN   \n",
       "                                                         3.0000                                            NaN   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                noiseless_angle_to_generalisation_erm  \\\n",
       "                                                                                                 mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                           \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                                   NaN   \n",
       "                                                         1.0786                                   NaN   \n",
       "                                                         1.1472                                   NaN   \n",
       "                                                         1.2159                                   NaN   \n",
       "                                                         1.2845                                   NaN   \n",
       "                                                         1.3531                                   NaN   \n",
       "                                                         1.4217                                   NaN   \n",
       "                                                         1.4903                                   NaN   \n",
       "                                                         1.5590                                   NaN   \n",
       "                                                         1.6276                                   NaN   \n",
       "                                                         1.6962                                   NaN   \n",
       "                                                         1.7648                                   NaN   \n",
       "                                                         1.8334                                   NaN   \n",
       "                                                         1.9021                                   NaN   \n",
       "                                                         1.9707                                   NaN   \n",
       "                                                         2.0393                                   NaN   \n",
       "                                                         2.1079                                   NaN   \n",
       "                                                         2.1766                                   NaN   \n",
       "                                                         2.2452                                   NaN   \n",
       "                                                         2.3138                                   NaN   \n",
       "                                                         2.3824                                   NaN   \n",
       "                                                         2.4510                                   NaN   \n",
       "                                                         2.5197                                   NaN   \n",
       "                                                         2.5883                                   NaN   \n",
       "                                                         2.6569                                   NaN   \n",
       "                                                         2.7255                                   NaN   \n",
       "                                                         2.7941                                   NaN   \n",
       "                                                         2.8628                                   NaN   \n",
       "                                                         2.9314                                   NaN   \n",
       "                                                         3.0000                                   NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                                   NaN   \n",
       "                                                         1.0786                                   NaN   \n",
       "                                                         1.1472                                   NaN   \n",
       "                                                         1.2159                                   NaN   \n",
       "                                                         1.2845                                   NaN   \n",
       "                                                         1.3531                                   NaN   \n",
       "                                                         1.4217                                   NaN   \n",
       "                                                         1.4903                                   NaN   \n",
       "                                                         1.5590                                   NaN   \n",
       "                                                         1.6276                                   NaN   \n",
       "                                                         1.6962                                   NaN   \n",
       "                                                         1.7648                                   NaN   \n",
       "                                                         1.9021                                   NaN   \n",
       "                                                         1.9707                                   NaN   \n",
       "                                                         2.0393                                   NaN   \n",
       "                                                         2.1079                                   NaN   \n",
       "                                                         2.1766                                   NaN   \n",
       "                                                         2.2452                                   NaN   \n",
       "                                                         2.3138                                   NaN   \n",
       "                                                         2.5197                                   NaN   \n",
       "                                                         2.5883                                   NaN   \n",
       "                                                         2.6569                                   NaN   \n",
       "                                                         2.7255                                   NaN   \n",
       "                                                         2.7941                                   NaN   \n",
       "                                                         2.8628                                   NaN   \n",
       "                                                         2.9314                                   NaN   \n",
       "                                                         3.0000                                   NaN   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                A_over_sqrt_qN_erm  \\\n",
       "                                                                              mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                        \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                NaN   \n",
       "                                                         1.0786                NaN   \n",
       "                                                         1.1472                NaN   \n",
       "                                                         1.2159                NaN   \n",
       "                                                         1.2845                NaN   \n",
       "                                                         1.3531                NaN   \n",
       "                                                         1.4217                NaN   \n",
       "                                                         1.4903                NaN   \n",
       "                                                         1.5590                NaN   \n",
       "                                                         1.6276                NaN   \n",
       "                                                         1.6962                NaN   \n",
       "                                                         1.7648                NaN   \n",
       "                                                         1.8334                NaN   \n",
       "                                                         1.9021                NaN   \n",
       "                                                         1.9707                NaN   \n",
       "                                                         2.0393                NaN   \n",
       "                                                         2.1079                NaN   \n",
       "                                                         2.1766                NaN   \n",
       "                                                         2.2452                NaN   \n",
       "                                                         2.3138                NaN   \n",
       "                                                         2.3824                NaN   \n",
       "                                                         2.4510                NaN   \n",
       "                                                         2.5197                NaN   \n",
       "                                                         2.5883                NaN   \n",
       "                                                         2.6569                NaN   \n",
       "                                                         2.7255                NaN   \n",
       "                                                         2.7941                NaN   \n",
       "                                                         2.8628                NaN   \n",
       "                                                         2.9314                NaN   \n",
       "                                                         3.0000                NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                NaN   \n",
       "                                                         1.0786                NaN   \n",
       "                                                         1.1472                NaN   \n",
       "                                                         1.2159                NaN   \n",
       "                                                         1.2845                NaN   \n",
       "                                                         1.3531                NaN   \n",
       "                                                         1.4217                NaN   \n",
       "                                                         1.4903                NaN   \n",
       "                                                         1.5590                NaN   \n",
       "                                                         1.6276                NaN   \n",
       "                                                         1.6962                NaN   \n",
       "                                                         1.7648                NaN   \n",
       "                                                         1.9021                NaN   \n",
       "                                                         1.9707                NaN   \n",
       "                                                         2.0393                NaN   \n",
       "                                                         2.1079                NaN   \n",
       "                                                         2.1766                NaN   \n",
       "                                                         2.2452                NaN   \n",
       "                                                         2.3138                NaN   \n",
       "                                                         2.5197                NaN   \n",
       "                                                         2.5883                NaN   \n",
       "                                                         2.6569                NaN   \n",
       "                                                         2.7255                NaN   \n",
       "                                                         2.7941                NaN   \n",
       "                                                         2.8628                NaN   \n",
       "                                                         2.9314                NaN   \n",
       "                                                         3.0000                NaN   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                std   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta         \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.8334 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.3824 NaN   \n",
       "                                                         2.4510 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN   \n",
       "                                                         1.0786 NaN   \n",
       "                                                         1.1472 NaN   \n",
       "                                                         1.2159 NaN   \n",
       "                                                         1.2845 NaN   \n",
       "                                                         1.3531 NaN   \n",
       "                                                         1.4217 NaN   \n",
       "                                                         1.4903 NaN   \n",
       "                                                         1.5590 NaN   \n",
       "                                                         1.6276 NaN   \n",
       "                                                         1.6962 NaN   \n",
       "                                                         1.7648 NaN   \n",
       "                                                         1.9021 NaN   \n",
       "                                                         1.9707 NaN   \n",
       "                                                         2.0393 NaN   \n",
       "                                                         2.1079 NaN   \n",
       "                                                         2.1766 NaN   \n",
       "                                                         2.2452 NaN   \n",
       "                                                         2.3138 NaN   \n",
       "                                                         2.5197 NaN   \n",
       "                                                         2.5883 NaN   \n",
       "                                                         2.6569 NaN   \n",
       "                                                         2.7255 NaN   \n",
       "                                                         2.7941 NaN   \n",
       "                                                         2.8628 NaN   \n",
       "                                                         2.9314 NaN   \n",
       "                                                         3.0000 NaN   \n",
       "\n",
       "                                                                m_over_sqrt_rhoq_minus_m2_erm  \\\n",
       "                                                                                         mean   \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta                                   \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100                           NaN   \n",
       "                                                         1.0786                           NaN   \n",
       "                                                         1.1472                           NaN   \n",
       "                                                         1.2159                           NaN   \n",
       "                                                         1.2845                           NaN   \n",
       "                                                         1.3531                           NaN   \n",
       "                                                         1.4217                           NaN   \n",
       "                                                         1.4903                           NaN   \n",
       "                                                         1.5590                           NaN   \n",
       "                                                         1.6276                           NaN   \n",
       "                                                         1.6962                           NaN   \n",
       "                                                         1.7648                           NaN   \n",
       "                                                         1.8334                           NaN   \n",
       "                                                         1.9021                           NaN   \n",
       "                                                         1.9707                           NaN   \n",
       "                                                         2.0393                           NaN   \n",
       "                                                         2.1079                           NaN   \n",
       "                                                         2.1766                           NaN   \n",
       "                                                         2.2452                           NaN   \n",
       "                                                         2.3138                           NaN   \n",
       "                                                         2.3824                           NaN   \n",
       "                                                         2.4510                           NaN   \n",
       "                                                         2.5197                           NaN   \n",
       "                                                         2.5883                           NaN   \n",
       "                                                         2.6569                           NaN   \n",
       "                                                         2.7255                           NaN   \n",
       "                                                         2.7941                           NaN   \n",
       "                                                         2.8628                           NaN   \n",
       "                                                         2.9314                           NaN   \n",
       "                                                         3.0000                           NaN   \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100                           NaN   \n",
       "                                                         1.0786                           NaN   \n",
       "                                                         1.1472                           NaN   \n",
       "                                                         1.2159                           NaN   \n",
       "                                                         1.2845                           NaN   \n",
       "                                                         1.3531                           NaN   \n",
       "                                                         1.4217                           NaN   \n",
       "                                                         1.4903                           NaN   \n",
       "                                                         1.5590                           NaN   \n",
       "                                                         1.6276                           NaN   \n",
       "                                                         1.6962                           NaN   \n",
       "                                                         1.7648                           NaN   \n",
       "                                                         1.9021                           NaN   \n",
       "                                                         1.9707                           NaN   \n",
       "                                                         2.0393                           NaN   \n",
       "                                                         2.1079                           NaN   \n",
       "                                                         2.1766                           NaN   \n",
       "                                                         2.2452                           NaN   \n",
       "                                                         2.3138                           NaN   \n",
       "                                                         2.5197                           NaN   \n",
       "                                                         2.5883                           NaN   \n",
       "                                                         2.6569                           NaN   \n",
       "                                                         2.7255                           NaN   \n",
       "                                                         2.7941                           NaN   \n",
       "                                                         2.8628                           NaN   \n",
       "                                                         2.9314                           NaN   \n",
       "                                                         3.0000                           NaN   \n",
       "\n",
       "                                                                     \n",
       "                                                                std  \n",
       "alpha     epsilon tau  lam   problem_type attack_epsilon beta        \n",
       "1000000.0 0.0     0.05 0.001 Logistic     0.2            1.0100 NaN  \n",
       "                                                         1.0786 NaN  \n",
       "                                                         1.1472 NaN  \n",
       "                                                         1.2159 NaN  \n",
       "                                                         1.2845 NaN  \n",
       "                                                         1.3531 NaN  \n",
       "                                                         1.4217 NaN  \n",
       "                                                         1.4903 NaN  \n",
       "                                                         1.5590 NaN  \n",
       "                                                         1.6276 NaN  \n",
       "                                                         1.6962 NaN  \n",
       "                                                         1.7648 NaN  \n",
       "                                                         1.8334 NaN  \n",
       "                                                         1.9021 NaN  \n",
       "                                                         1.9707 NaN  \n",
       "                                                         2.0393 NaN  \n",
       "                                                         2.1079 NaN  \n",
       "                                                         2.1766 NaN  \n",
       "                                                         2.2452 NaN  \n",
       "                                                         2.3138 NaN  \n",
       "                                                         2.3824 NaN  \n",
       "                                                         2.4510 NaN  \n",
       "                                                         2.5197 NaN  \n",
       "                                                         2.5883 NaN  \n",
       "                                                         2.6569 NaN  \n",
       "                                                         2.7255 NaN  \n",
       "                                                         2.7941 NaN  \n",
       "                                                         2.8628 NaN  \n",
       "                                                         2.9314 NaN  \n",
       "                                                         3.0000 NaN  \n",
       "          0.2     0.05 0.001 Logistic     0.2            1.0100 NaN  \n",
       "                                                         1.0786 NaN  \n",
       "                                                         1.1472 NaN  \n",
       "                                                         1.2159 NaN  \n",
       "                                                         1.2845 NaN  \n",
       "                                                         1.3531 NaN  \n",
       "                                                         1.4217 NaN  \n",
       "                                                         1.4903 NaN  \n",
       "                                                         1.5590 NaN  \n",
       "                                                         1.6276 NaN  \n",
       "                                                         1.6962 NaN  \n",
       "                                                         1.7648 NaN  \n",
       "                                                         1.9021 NaN  \n",
       "                                                         1.9707 NaN  \n",
       "                                                         2.0393 NaN  \n",
       "                                                         2.1079 NaN  \n",
       "                                                         2.1766 NaN  \n",
       "                                                         2.2452 NaN  \n",
       "                                                         2.3138 NaN  \n",
       "                                                         2.5197 NaN  \n",
       "                                                         2.5883 NaN  \n",
       "                                                         2.6569 NaN  \n",
       "                                                         2.7255 NaN  \n",
       "                                                         2.7941 NaN  \n",
       "                                                         2.8628 NaN  \n",
       "                                                         2.9314 NaN  \n",
       "                                                         3.0000 NaN  \n",
       "\n",
       "[57 rows x 214 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_powerlaw_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">index_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">duration_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">generalization_error_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_loss_state_evolution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_error_state_evolution</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_generalization_error_erm_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_adversarial_generalization_error_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">noiseless_angle_to_generalisation_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">A_over_sqrt_qN_erm</th>\n",
       "      <th colspan=\"2\" halign=\"left\">m_over_sqrt_rhoq_minus_m2_erm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>tau</th>\n",
       "      <th>lam</th>\n",
       "      <th>problem_type</th>\n",
       "      <th>attack_epsilon</th>\n",
       "      <th>data_model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1585</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.2</th>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_0.5</th>\n",
       "      <td>2115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_1.5</th>\n",
       "      <td>2055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_2.5</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.543683e-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_3.5</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.032063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.111418e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.001</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>0.2</th>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_0.5</th>\n",
       "      <td>2116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10000.0000</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.001</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>0.2</th>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_3.5</th>\n",
       "      <td>2088.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.403625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.591084e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Logistic</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.2</th>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_0.5</th>\n",
       "      <td>2180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.600145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.268545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.885621e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_1.5</th>\n",
       "      <td>2141.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.730033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.470230e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_2.5</th>\n",
       "      <td>2129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.557398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.090272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.364277e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFeaturesModel_PowerLaw_Coefficient_3.5</th>\n",
       "      <td>2078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.635296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.851481e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  index_state_evolution  \\\n",
       "                                                                                                                   mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                 \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                2115.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                2055.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                2002.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                1972.0   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                2116.0   \n",
       "...                                                                                                                 ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                2088.0   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                2180.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                2141.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                2129.0   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                2078.0   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  duration_state_evolution  \\\n",
       "                                                                                                                      mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                    \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                 0.060791   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                 0.143259   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                 0.768748   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                 3.032063   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                 0.091313   \n",
       "...                                                                                                                    ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                18.403625   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                 1.600145   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                 1.730033   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                 7.557398   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                16.635296   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  generalization_error_state_evolution  \\\n",
       "                                                                                                                                  mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                                \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                             0.376116   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                             0.160523   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                             0.064716   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                             0.039534   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                             0.376171   \n",
       "...                                                                                                                                ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                             0.015911   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                             0.018856   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                             0.044702   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                             0.023643   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                             0.018515   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  training_loss_state_evolution  \\\n",
       "                                                                                                                           mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                         \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                      0.005583   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                      0.008649   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                      0.014742   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                      0.019588   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                      0.006459   \n",
       "...                                                                                                                         ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                      0.036114   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                      0.268545   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                      0.196824   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                      0.090272   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                      0.064606   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  training_error_state_evolution  \\\n",
       "                                                                                                                            mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                          \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                   0.000000e+00   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                   0.000000e+00   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                   4.543683e-16   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                   3.111418e-04   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                   0.000000e+00   \n",
       "...                                                                                                                          ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                   1.591084e-02   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                   1.885621e-02   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                   4.470230e-02   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                   2.364277e-02   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                   1.851481e-02   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                   ...  \\\n",
       "                                                                                                   ...   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                          ...   \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5  ...   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5  ...   \n",
       "...                                                                                                ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5  ...   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5  ...   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5  ...   \n",
       "\n",
       "                                                                                                  noiseless_generalization_error_erm_erm  \\\n",
       "                                                                                                                                    mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                                  \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                    NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                    NaN   \n",
       "...                                                                                                                                  ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                                    NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                    NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                    NaN   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  noiseless_adversarial_generalization_error_erm  \\\n",
       "                                                                                                                                            mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                                          \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                            NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                            NaN   \n",
       "...                                                                                                                                          ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                                            NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                            NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                            NaN   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  noiseless_angle_to_generalisation_erm  \\\n",
       "                                                                                                                                   mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                                 \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                   NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                   NaN   \n",
       "...                                                                                                                                 ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                                   NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                                   NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                                   NaN   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  A_over_sqrt_qN_erm  \\\n",
       "                                                                                                                mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                              \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                NaN   \n",
       "...                                                                                                              ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                NaN   \n",
       "\n",
       "                                                                                                       \\\n",
       "                                                                                                  std   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                               \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "...                                                                                                ..   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN   \n",
       "\n",
       "                                                                                                  m_over_sqrt_rhoq_minus_m2_erm  \\\n",
       "                                                                                                                           mean   \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                                                         \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                           NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                           NaN   \n",
       "...                                                                                                                         ...   \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5                           NaN   \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5                           NaN   \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5                           NaN   \n",
       "\n",
       "                                                                                                       \n",
       "                                                                                                  std  \n",
       "alpha      epsilon tau  lam   problem_type attack_epsilon data_model_name                              \n",
       "0.1585     0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN  \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN  \n",
       "...                                                                                                ..  \n",
       "10000.0000 0.0     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_3.5 NaN  \n",
       "           0.2     0.05 0.001 Logistic     0.2            KFeaturesModel_PowerLaw_Coefficient_0.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_1.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_2.5 NaN  \n",
       "                                                          KFeaturesModel_PowerLaw_Coefficient_3.5 NaN  \n",
       "\n",
       "[239 rows x 214 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_powerlaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([0.0, 0.2], dtype='float64', name='epsilon'),\n",
       " Index([0.0, 0.2], dtype='float64', name='epsilon'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract unique epsilons\n",
    "epsilons = df_powerlaw.index.get_level_values(\"epsilon\").unique()\n",
    "epsilons_beta = df_powerlaw_beta.index.get_level_values(\"epsilon\").unique()\n",
    "epsilons, epsilons_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only attack_epsilon = 0.2\n",
    "df_powerlaw = df_powerlaw.xs(0.2, level=\"attack_epsilon\")\n",
    "df_powerlaw_beta = df_powerlaw_beta.xs(0.2, level=\"attack_epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KFeaturesModel_PowerLaw_Coefficient_0.5',\n",
       "       'KFeaturesModel_PowerLaw_Coefficient_1.5',\n",
       "       'KFeaturesModel_PowerLaw_Coefficient_2.5',\n",
       "       'KFeaturesModel_PowerLaw_Coefficient_3.5'],\n",
       "      dtype='object', name='data_model_name')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_names = df_powerlaw.index.get_level_values(\"data_model_name\").unique()\n",
    "data_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of dataframes for each data_model_name\n",
    "df_dict_beta = {}\n",
    "for data_model_name in data_model_names:\n",
    "\n",
    "    # the data_model_name is given by a string of this form 'KFeaturesModel_PowerLaw_Coefficient_3.5'\n",
    "    # we want to extract the coefficient\n",
    "    # split the string by '_'\n",
    "    split = data_model_name.split(\"_\")\n",
    "    # extract the coefficient\n",
    "    beta = split[-1]\n",
    "    # convert the beta to a float\n",
    "    beta = float(beta)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    df_data_model = df_powerlaw.xs(data_model_name, level=\"data_model_name\")\n",
    "\n",
    "    # for each data_model_name, create a dictionary\n",
    "    eps_dict = {}\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "\n",
    "\n",
    "        eps_df = df_data_model.xs(epsilon, level=\"epsilon\")\n",
    "\n",
    "        alphas = eps_df.index.get_level_values(\"alpha\").unique()\n",
    "        adversarial_error_0 = eps_df[\"adversarial_generalization_error_state_evolution\"][\"mean\"].values\n",
    "        generalization_error_0 = eps_df[\"generalization_error_state_evolution\"][\"mean\"].values\n",
    "        boundary_error_0 = eps_df[\"difference_adv_gen_state_evolution\"][\"mean\"].values\n",
    "        class_preserving = eps_df[\"fair_adversarial_error_state_evolution\"][\"mean\"].values\n",
    "\n",
    "        adversarial_error_erm = eps_df[\"adversarial_generalization_error_erm\"][\"mean\"].values\n",
    "        generalization_error_erm = eps_df[\"generalization_error_erm_erm\"][\"mean\"].values\n",
    "        boundary_error_erm = eps_df[\"difference_adv_gen_erm\"][\"mean\"].values\n",
    "        class_preserving_erm = eps_df[\"fair_adversarial_error_erm\"][\"mean\"].values\n",
    "\n",
    "        adversarial_error_erm_std = eps_df[\"adversarial_generalization_error_erm\"][\"std\"].values\n",
    "        generalization_error_erm_std = eps_df[\"generalization_error_erm_erm\"][\"std\"].values\n",
    "        boundary_error_erm_std = eps_df[\"difference_adv_gen_erm\"][\"std\"].values\n",
    "        class_preserving_erm_std = eps_df[\"fair_adversarial_error_erm\"][\"std\"].values\n",
    "\n",
    "        alphas = np.array(alphas)\n",
    "        adversarial_error_0 = np.array(adversarial_error_0)\n",
    "        generalization_error_0 = np.array(generalization_error_0)\n",
    "        boundary_error_0 = np.array(boundary_error_0)\n",
    "        class_preserving = np.array(class_preserving)\n",
    "\n",
    "        adversarial_error_erm = np.array(adversarial_error_erm)\n",
    "        generalization_error_erm = np.array(generalization_error_erm)\n",
    "        boundary_error_erm = np.array(boundary_error_erm)\n",
    "        class_preserving_erm = np.array(class_preserving_erm)\n",
    "\n",
    "        adversarial_error_erm_std = np.array(adversarial_error_erm_std)\n",
    "        generalization_error_erm_std = np.array(generalization_error_erm_std)\n",
    "        boundary_error_erm_std = np.array(boundary_error_erm_std)\n",
    "        class_preserving_erm_std = np.array(class_preserving_erm_std)\n",
    "\n",
    "        eps_0_dict = {}\n",
    "        eps_0_dict[\"alphas\"] = alphas\n",
    "        eps_0_dict[\"adversarial_error\"] = adversarial_error_0\n",
    "        eps_0_dict[\"generalization_error\"] = generalization_error_0\n",
    "        eps_0_dict[\"boundary_error\"] = boundary_error_0\n",
    "        eps_0_dict[\"class_preserving\"] = class_preserving\n",
    "\n",
    "        eps_0_dict[\"adversarial_error_erm\"] = adversarial_error_erm\n",
    "        eps_0_dict[\"generalization_error_erm\"] = generalization_error_erm\n",
    "        eps_0_dict[\"boundary_error_erm\"] = boundary_error_erm\n",
    "        eps_0_dict[\"class_preserving_erm\"] = class_preserving_erm\n",
    "\n",
    "        eps_0_dict[\"adversarial_error_erm_std\"] = adversarial_error_erm_std\n",
    "        eps_0_dict[\"generalization_error_erm_std\"] = generalization_error_erm_std\n",
    "        eps_0_dict[\"boundary_error_erm_std\"] = boundary_error_erm_std\n",
    "        eps_0_dict[\"class_preserving_erm_std\"] = class_preserving_erm_std\n",
    "\n",
    "\n",
    "        eps_dict[epsilon] = eps_0_dict\n",
    "\n",
    "\n",
    "    df_dict_beta[beta] = eps_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of dataframes for each data_model_name\n",
    "df_dict = {}\n",
    "for epsilon in epsilons:\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    eps_df = df_powerlaw_beta.xs(epsilon, level=\"epsilon\")\n",
    "\n",
    "\n",
    "\n",
    "    # for each data_model_name, create a dictionary\n",
    "    eps_dict = {}\n",
    "\n",
    "\n",
    "    betas = eps_df.index.get_level_values(\"beta\").unique()\n",
    "    adversarial_error_0 = eps_df[\"adversarial_generalization_error_state_evolution\"][\"mean\"].values\n",
    "    generalization_error_0 = eps_df[\"generalization_error_state_evolution\"][\"mean\"].values\n",
    "    boundary_error_0 = eps_df[\"difference_adv_gen_state_evolution\"][\"mean\"].values\n",
    "    class_preserving = eps_df[\"fair_adversarial_error_state_evolution\"][\"mean\"].values\n",
    "\n",
    "    adversarial_error_erm = eps_df[\"adversarial_generalization_error_erm\"][\"mean\"].values\n",
    "    generalization_error_erm = eps_df[\"generalization_error_erm_erm\"][\"mean\"].values\n",
    "    boundary_error_erm = eps_df[\"difference_adv_gen_erm\"][\"mean\"].values\n",
    "    class_preserving_erm = eps_df[\"fair_adversarial_error_erm\"][\"mean\"].values\n",
    "\n",
    "    adversarial_error_erm_std = eps_df[\"adversarial_generalization_error_erm\"][\"std\"].values\n",
    "    generalization_error_erm_std = eps_df[\"generalization_error_erm_erm\"][\"std\"].values\n",
    "    boundary_error_erm_std = eps_df[\"difference_adv_gen_erm\"][\"std\"].values\n",
    "    class_preserving_erm_std = eps_df[\"fair_adversarial_error_erm\"][\"std\"].values\n",
    "\n",
    "    betas = np.array(betas)\n",
    "    adversarial_error_0 = np.array(adversarial_error_0)\n",
    "    generalization_error_0 = np.array(generalization_error_0)\n",
    "    boundary_error_0 = np.array(boundary_error_0)\n",
    "    class_preserving = np.array(class_preserving)\n",
    "\n",
    "    adversarial_error_erm = np.array(adversarial_error_erm)\n",
    "    generalization_error_erm = np.array(generalization_error_erm)\n",
    "    boundary_error_erm = np.array(boundary_error_erm)\n",
    "    class_preserving_erm = np.array(class_preserving_erm)\n",
    "\n",
    "    adversarial_error_erm_std = np.array(adversarial_error_erm_std)\n",
    "    generalization_error_erm_std = np.array(generalization_error_erm_std)\n",
    "    boundary_error_erm_std = np.array(boundary_error_erm_std)\n",
    "    class_preserving_erm_std = np.array(class_preserving_erm_std)\n",
    "\n",
    "    eps_0_dict = {}\n",
    "    eps_0_dict[\"betas\"] = betas\n",
    "    eps_0_dict[\"adversarial_error\"] = adversarial_error_0\n",
    "    eps_0_dict[\"generalization_error\"] = generalization_error_0\n",
    "    eps_0_dict[\"boundary_error\"] = boundary_error_0\n",
    "    eps_0_dict[\"class_preserving\"] = class_preserving\n",
    "\n",
    "    eps_0_dict[\"adversarial_error_erm\"] = adversarial_error_erm\n",
    "    eps_0_dict[\"generalization_error_erm\"] = generalization_error_erm\n",
    "    eps_0_dict[\"boundary_error_erm\"] = boundary_error_erm\n",
    "    eps_0_dict[\"class_preserving_erm\"] = class_preserving_erm\n",
    "\n",
    "    eps_0_dict[\"adversarial_error_erm_std\"] = adversarial_error_erm_std\n",
    "    eps_0_dict[\"generalization_error_erm_std\"] = generalization_error_erm_std\n",
    "    eps_0_dict[\"boundary_error_erm_std\"] = boundary_error_erm_std\n",
    "    eps_0_dict[\"class_preserving_erm_std\"] = class_preserving_erm_std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_dict[epsilon] = eps_0_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasimirtanner/opt/anaconda3/envs/pdm/lib/python3.11/site-packages/matplotlib/axes/_base.py:2503: UserWarning: Warning: converting a masked element to nan.\n",
      "  xys = np.asarray(xys)\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD/CAYAAAA+CADKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABRlElEQVR4nO2deVxc1dn4v7MPAwzDsENICGTfjJCYxC0xITFq1aqJ0ardVEhbbWvVxKWry5sman997aJBX21rXYN1qUuVibtRQyDaxOyQGPZtmAWG2e/vjwsDJOwMMAP3m8/NzF3mzjMP9znnOec85zkyQRAEJCQkJhzysRZAQkJibJCMX0JigiIZv4TEBEUyfgmJCYpk/BISExTJ+CUkJiiS8UtITFCUA7nI7/dTXV1NdHQ0MplspGWSkAgpBEHAbreTmpqKXD5+6ssBGX91dTXp6ekjLYuEREhTUVHBpEmTxlqMoDEg44+OjgbEH6/X60dUoMFSVVVFWlraWIsR0kg66p++dGSz2UhPTw/YwXhhQD5Mh6tvt9ux2WxERkbS1taGzWbD5XIRERGBzWbDZrMhk8mQyWSBfZ1Oh9PpxGaz4XQ6iYyMDJwDkMvlgf2IiAhcLhc2mw2Hw0FUVFTgnCAIKBSKwL5Wq8XtdqPT6WhtbSU6Ojpwzu/3o1QqA/sajQaPx4PNZqOlpQW9Xh/4LT6fD5VKFbhWrVbj9Xqx2WzY7Xb0ej0tLS3YbDa8Xi9qtTpwrUqlwu/3B/b1ej2tra3YbDY8Hg9arTZwTqlUIghCYD8qKgqHw9GjDjtcy479rvp2Op3odLoB6butrY3IyMjA9YPVd1cdarXagA5bW1vR6/Xd9N2bDk/Vd0869Pl8Perb4/Gg0Wi66bCrvqOjowP6drvd3fStUCgGpe+kpKRu+nY6nTz66KMsXryYVatWdbOD8YJsILH9NpuNmJgYrFZrrzX//5qO4PL6ufm8qcRGaoIuaG80NDSQkJAwat8Xjkg66p++dDSQ5z8cGZDb3x9Oj49/fvENDXY3f/2gjDRDBJeekUL++VnERqqD8RW94nK5RvT+4wFJR/0zEXUUFOPXqhTsvieX9w7V8+TH5ZR8Y+HxD8t56pPjXL04nVWzkshKjGKyUReMr+uGUhmUnzCukXTUPxNRR0Fz+7siCALvH6rn7f217CprosrSBoBeq2RJZhw3LJ3MOdMSUMiH34by+/3javhlJJB01D996Wi8uv0jYvxdEQSBPSea+duu43xa1oTF4QEgJkLFj1ZksSwzjiiNksyEyCF1qFRWVo6r4ZeRQNJR//Slo/Fq/MHzdXY+APpUWPzDbodlMhmLpxpZPNUIQLWljb/vOsHu42Ye3XmU3799CACtSs6sZD0Xzk1izdxkshKigiaaRHARBAFBAL8gIND+KnScAwGh/VW8Fjred9yg40UIfKbL4cB3QE/Hu7xnkHlo+rjc5fUP7l7jgODU/K4W+PNisFeDLh4ufgjmXdnvl7u9fj4ra2RHSSW7j5upt4udLgq5jIvmJZM9OZZj9S0szTKSPTmWNEPEad6B1WolJiZmgD83PHB5fVjbPNjavDjcXlpcXhwuH61uLw63j1aXF5fXj8vjw+X14/T4cHr8uH3i5vH68fj8eHwCbp8fp8sDcjlen4DPL+D1+9tfxX2fX8AvdL7vMGx/4LXz/XjN+/TIFbO4aklWj+fGa80fPLff54V37oE9/wd+L8RMgsv/ApkrBiyMtc3De4fq+ORoIyeaHPy3woLH3ymeWiEnOUbLlivmk5MhFgz43ExPNaJRKgb8PaONzy/Q1OKizuaiscVFg91FQ8er3UVTqwuLw4O1zYPF4aHN4+v1XjIZRKgUaFUKNEp54FWjUqBRyFEr5agUMlQKOSqlHLVCjuD3EaFRoZTLUchlKOUyFAoZCpn4Xi4X38vlMhRyGXIZyGWy9g3kcvG9rP24DPGVLvsyWfuGeJ0oa5dzyALydxxrvypwvHOv8/Pdr+pZH4M53htZsWqmJMX2eE4y/oH+eHcbvPEz2LcDkMGiH8B5d4I+edDCubw+vq628dHhBj4+1kBZQ2ugz0AuA5VCHnDXIjUKEqI03HLBdC4/M5WyhhYO19pJNUSQEqMlSa9FpQh+p1eLy0u9zUmdzUW93Uld+/taq5Maaxt1Nhd1Nidef3c1GyPVJERpSIjWYIxUE6tTEROhIkanxhChwqBTEa1VEalREKVRolMridQo0CoVyAfZUSq1+ftnIrb5R67Dr60Zip+CXf8rNgtSF8JVT4ExY1gCt7q8HKmzc7jWTunJZkpPNFLf4sXm9AaukcsgUqPE3uWYDJidomfD4nQ0SjnljS3MStajUytQyOUoFTIEQcDt9be71H5cXtGtbnF5sTg8NDvcWBweLA43zQ4PTS0uWt3da+kojZLEaA0pBrHASYnRkhwTQYpeS6JeQ2K0lrgo9YgURL3R24MtCAIevweXz9Vtc/vceP1ePH4PHp8n8N7r9+IVvPj8PnyCD6/fi0/wBfYFBHx+H37Bjx+/+Cr4EQQBP+2v7cego29APIfQuR/4F+gvEALy9rXf9Xf1RNfrTv3M8pjlrJizosfPScY/1B/vaIIXroOTnwEymL4GrtgOup5drMHidrtRq9W4vD5qLE4qm9uoaHZQYXYEat7GFtGtdnl9tLnFdvFAUClkaJQKdGoFsTo1MToVsToVhgg1hkgVcZFqkvRaEqO1JOk1JOq1RGlGd7zY5/dhdpqpd9TT5GzC6rKKm9va+d5ppc3XhsPrwOFxBF7bvG2D7zTrAYVMgVwmRyFTIJPJAvsdmwyZ+CqTddsHup3rbBp0eY+su/vf17leGgcDueaWBbdw7uRzezwnGf9wf3zNf+FfN0PDIZAr4fK/wvz1MMzx56amJuLi4gZ8vSAIeH1+Dtba2XmwnvcP17Ov0sq0xCj+edMSsf2sVKBWyoMShxAMbG4bx63HKbeUc9x6nAp7BfWOeuocdTS2NeITunsfEcoI9Go9MZoYYjQxaAQNsZGx6FQ6cVOKW4QqAq1Ci1qhRqPQoFao0Sq0qOQq1Ao1KrlK3BQqlHIlSpkSpVyJQq5AIVMEjHw8xLz39RxJxh+sH3/UBO/dDzVfQvICmHsFnHvb4Hto2glGe7axRWyjz0uL4XCtnV+9tp9bLpjGedPjR/3Btrqs7K3fS2ldKV83fU25tZzGtkZArLVSo1KZop9Coi6RRF0iSbqkwPv4iHjR2BXd51ZIbf7+mYht/tGPaZyeK24nPoVXN8LO38GuP8Glj8KcSwd9O4Vi+L388VEa4qNEg3F6fLg8Pr771G7OSDdw6wXTWDU7ccQKAYvTwuc1n1NSV0JJfQnHmo8hIJAYkcgZiWdw1fSryIzJJNOQyRT9FCKUEYP+jmDoaLwzEXU0+jV/V3w+0fg//4s4PBg3HdY9BSkLgvcdQ0AQBD4+2sif3jtK8Ylm7rxwJj+5YFrQ7u/wOHi/4n3eOv4Wu6p24RW8TNFPITsxm5ykHLKTspkUNWlcuNPjgfFa84+t8XfgssMrG+HQm6DSwcpfwlk3g0LV70dH2qX9oryJtNgIJsXqeObzbyirb+GGZVMGHYHo8Xn4tPpT3ip/iw8qP6DN28YZCWdw8dSLyZ2SS6IucYR+geT2DwTJ7R8rNNFwzbPQfBI++YMYLPT+/0DO92H1fcPuFBwOSzI7O4G8Pj///qqav+06wXnT49mwOJ0VMxP77OFv9bRSeKSQfxz4B/WOeqbHTidvQR4XTb2ItCgpu47E2BEaNf+pnPwCXvgOOBpBGyP2B8z9do+XWiwWDAbDyMvUjsvr4619Nfx91zd8WWHh2ZuWcM60eA5U24jSKJkcJ05bNjvNPHfwOZ4/9DwOj4NLMi/hhjk3MNM4c9Rk7WC0dRSO9KWj8Vrzh6bxgziD44Ot8PHD4PdAyhnw/TdFL6ELbW1tREQMvhMsGFQ2OwKRgz94ejfvH25garyWqJgKTrg+QhN1nPVz1vK9ud8jOXLwEY7BYix1FC70paPRev4LCwvZsmULJSUlI/YdXQld4+/AaRfjA44VQWQi5P5WHB5UihmCQqU929Bi4/73C3nn62q8jgx87li2rZ/J1TnTeO9QHbuPNzMnVc/UuEgmx+mIiei/PyNYhIqOQpmhtPktFgsFBQUAbNq0KXC8sLAQALPZTGZmJrm5uQOWY/Xq1RQVFQ3lJwya0Gjz94U2Gr7zAjR/A29vhlfy4M3bxKbA/HVjLR1+wc/rZa/zaOmjWF1WfrLme9w4/wrcbhUaldhXUdncxit7K3n8w85UUd9dNoX7Lp9Hnc3JPz47QWK0loRoMdY/MVrDlLjIsfpJEgPEZDKdFhxUXl5OUVER27dvB0RjHozxjyahb/wdxE4RC4FdfxaHB1++ET79X+Kv+NuYiVRSV8K24m0caDrAhRkXclvObYFOvMguFft3l2Xw3WUZWB0evjG38k2Tg5QYLQBVljZeKa2iscUdCDtOjNaw+17xgbn8L5/S5vai14oTf/QRKm5dOY3MhCh2lTXydZUNnUYMQY5QKZgSF8nsFD1tbh/H6ltQK+UIMh0VZgcapZxEvfi9To8PuaxzFt9EH1aMj48PvHe5XN1y+nVkPj6VdevWYTabsVgsgWMmk6lb34HBYMBkMpGbm0thYSFms7nbPYxGI+vWjU0lNijjr6qqwmazkZKSQmNjYyC1ssFgoK6uDiAwt95qtQKQnJyM2WwOxODHxcVRU1MDgF6vRy6XB5SXlJSExWLB5XKhVCpJTEykuroaENcOUCqVNE/+NrLrckn5+C5kx99H89gizKv/H7Fnf4+qqioAoqKiUKvVAUUnJCTQ0tJCW1sbcrmc1NRUqqqqEASByMhItFotTU1NgPgQOBwOHA4HMpmMtLQ0qqur8fv96HQ6dDodx6qPsf3Idj6o+4BZhlk8lPMQ8wzzSItKo6amBp/PR0REBNHR0dTX1wPiHxmPByMtGOMgNdVAbW0tiXIvr920gJiYGI6drKbJ4UWp6UzNvXSSFpdMQ31zCzank+N2B20uD5WVlbyzt4bC/zbR5vHRMWnwuiXp/OycZPZVWrjxpaPd/n46tYLdm87FYrFw/XOHOGHufMAVMnj8+mxmx/h48csG/r6nXpy2i4BCBrlzkth0QToVjTZ+9PIxVEolPp8XGaBQyHn9x0uxW5p50HSSY01uhPYJPTIZ3LF2DvNj/XxwzMIzJQ3I5XK8PnHS1cL0WO5enYHFZufHL5ehVqtwe9pnbsplFFyfjdBmY/tnNfy31okgCPh8YjjzD86fxjmpSkorrGz/vA6FQoGn/bMZ8VE8eOkM7HY7t71Whl+uwuNxIwgCcpmcbevOINLfwvN765ErNVw9Tx8oAAsKCrj//vsHYxoBysrKunkCRqMx8HyPlZH3xqCMPy0tLdDmSUpK6nbu1PZS1wUOEhMT+7w2KqpzzPzU9MmnXhsZ2e4OZ74KJ3bh+ddGjEU/g8YSJi39ESTNCVyr03UmDNVouoe8nrpAQ9fv0Wq1orG2k5qaCojBP6+Xvc5Dex5Choz7z7mfy7IuC0xSAUhJSelT/q6JR5KTu3cCzpmW0W1fr9dzd69t9Vh+t24Sv1snyuXy+mlz+1AqZERrVZxtiOONpCTcPj9VNXXEGuMREIiKiiIqKopffkuFpc2D3y/gE8TEHrNSYphk1HGBP5KoaD2+9uQdPr9AVkIUcXFxKHV6rsxxtSf86MzaExkRQUxUJEtneEluau2S2UcgIVpDWpqRmZ4IFjX7u2XumRoXSWxsLFH6GBZmWNo/0/krIyO0GOL0zEj34ZZZu01EMkaqSUlJYopfx8yUzoJMAJL0GmJiYoiJiWFGanP71O/OppROq2aScRKZdeD2+ZHJZIG/1b333ssdd9wRuLZj0Y6hcmpt3xsmk4ny8nIKCwtHpaAI/Q6/fqiuqiS16m14517wuWDh9XDp/4IiuC2aSnsl9312H5/VfMYlmZewafEmjFpj/x8MAaqrqwMFmETP9KWjvp7/goICLBZLoMPv1P3169eTn58fku3+8HP7m5sB0Zuw2Wz4BahJ/xbJ+efi+8cVKL/8J/5Db+D69lM0RYlj6sNx+5NSknjsi8f4+7G/Y9AY+OP5f2SmaiaORgcRceKKNy0tLYBYy/fl9ns8Hux2OyB6E/X19Xi93tN0aDAYAivTAN30rVarMRqN1NbW9qtvlUpFfHw8fr+fysrKQetbpVIFaq3ExETsdjttbW0oFApSUlKorKwERM9No9H0qMNT9d3RdGpsFCcrxcXF4XQ6aW1tPa2ZFRERQVRUFA0NDQEdut3ugL7T0tKora3F5/Oh1WrR6/UBfcfGxuL1eges76ioqMDvSUlJoampiYKCAp555pkB2wdAbm4umzdvDuyXl5eHpOHDOKj5u62xJgjw/oPw8SMg+MUw4fPvHPK9j1uP88tPfsm+xn1cN/s6bj3zVnSq4K89MNJIa/X1T39r9fX0/JtMJrZv347FYiE/Pz/gqncd6hvLDr3+CHvj73F8trkCXrwWavfBwutg1a8heuBBNn7BzwuHXuD/lfw/kiKTeOCcB1iYuDC4go8i0jh//0zE2P6wX8mha6degNh0yP9YTCC6/1/wh9nw4UMDul9tay0bizayZfcWLp92OS9966WwNnzoRUcS3ZiIOhpUzX/gwAGio6NDqs1vt9vRarUkJyf3ONSnbPyapP/kI3M24zbOounSv5MyddZpbf7GxkY+qPuAx448hkah4eezfs6i+EU9DvV1ba+GQ5v/5MmTqFQqqc3fh76dTidOpzOg71Pb/EeOHBl3Nf/4dPtPxeuBHd+Dw2+CQiPOIJy+OnDa5rbxwGcP8PaJt7ko4yLuXXovMZrxsxaA5Pb3j+T2j1eUKrj2OVj3NMgVsOMHcPANAPbW72X96+v5pOoTtp63lW3Lt40rw5eQ6I3wCe/thcEk72TelTBtFbz6Y7wvXseXiVnkRXqZm3AGT619ilZPKx6/B5V89CbdjAaD0tEEZSLqKOyN3+l0Dmq6qkel4+NlN7KjZT96l4Ucp4rHcu7Bq43j269+G4VcwZLkJZyTdg7npp1LalT4B8cMVkcTkYmoo7AP8qmursbpdPba4QedQT5lTWXctuc2bB4bqCBTm8zZ5mrkj5+D/dz72Ja9jYPOg3xS9QkPfvGgmMvvmo9pbWrF4rKQHJMclh1+FRUVtLa2Sh1+fei7sbGR1tbWgL6HGuQTToR9h99AAlicXrEXd+vurRQeLWRx8mK2nbeNeF08VBTDPy4DjwNWPwDn3AqInYBfN37NstRleP1eVheuJlmXzOXTLueiqReFVb+AFOTTP0MJ8gl3wt74+0IQBF4re42Hix8mRhNDnaOOTYs3sX7G+u5TWNua4fWfw8FXYdEPYdVvIaLTuL1+L++dfI/Xy17nk6pPkMvkrEhfwQPnPBCWEX8SgyNcn//+CPs2f28TMirsFfzus9/xRc0XKGQKYjQxPHfJc8yInXH6TSJiYcPfYc9T8MYv4KsX4fqXYcoyAJRyJWsy1rAmYw2NbY28Wf4m+xr3BXLo/+6z3zHbOJvzJ50/pum6ekOa2NM/oaqjhx9+GIPBgNFo5Mor+1/2fjCEvfH7/aevu1dcW8wtO28JTP/8Vua3uGfJPf3X0ot+CDI5vHEbPH0RnH8HrLinW/bg+Ih4vjf3e4F9h8fBN7ZveOXoK9z/+f3MNs7m3LRzuXnBzUNaYGMk6ElHEt0JVR298MILFBYWkpGR0e34zp07sVqtwyoQwr7Dr6WlhZqamm4dfi1tLchlcjw+D3fOuZMNCzbQYmvB3Gbuf1bf3GtwRU4l+uVrkX/0EJS9R/Xap/DLlD12Vrldbu6bex/2GXbKhXLePvo2b5e9zbWTr0WhV/DznT9HJVeRnZLN9OjpxMniiFRGjmqHX0tLizSrbwD6DsasvmCzYcOG0wwfYNWqVQBs3LgRmUzGY489Nuh7h32b3+VyodFoqLBV8OAXD3JWyln89cu/kqHP4KHlDzE1ZurQbmyvg79dJOYO3PAsZK2EljowDC6pwyN7HqGkroSD5oN4/WL2mmcueoaFiQt5/+T7VLZUMjl6MkmRSSTpkjBoDEFPqdWhI4ne6UtHY/n8P/zww4HEIi+//DLHjx8nNzeXhQsXBq5ZtGgRe/bsGfS9w97tb2ho4KDvIL/69FcIgsCn1Z+yfsZ6Ni3ehFapHfqNo5Mg/xMxc/AL34Hs78LeZ2DBNXDuzyF++oBuc/ui2wFw+VyBVXanGcSlv/bU7eHFwy/i8nVmoclbkMetZ97KIfMhntz3JAaNIbClRKWwarJY4h+3HidCGRFYdVcp7/1P2dDQIIX39kOo6qhrPsCrrrqKu+66i/LycoBAATDUfAFhbfwen4fHjzzOaxWvoVOK7flt52/joqkXBecL1DpY/3f490+h5GmY8204ZoIvn4U5l8OKuyBx9oBupVFomB03m9lxndffufhObl90Ow2OBuod9dQ76knXi55Fm7cNi9PCCesJLC4LVpeVKfopAeO/+t9X4/Q5A/fSKrQ8e8mzzIidwV+//CvvV7yPRqFBq9AieAQuc17G5dMu57j1OH/7+m+B5bc7OkNvXnAzAM8dfI42b1tg+W2FXMGqyatIjkxmf+N+DpsPB5bllsvkTI6ezMLEhdjddj6t+hRkIKfzfIe8xbXF2N12ZMiQyWTIkDE7bjaJukQq7ZUctx4HOhOJGrVG5sTNwePzUFxbDKc4Q2cln4VSruRg00Gsbmu3cxn6DJIjk2lsa6TMUtbtXJQ6irlxcwHYXbMbgLiIODSEpmdUUlLChg0bAmnxpk2bdlo7Pysra0j3DmvjL7eW83bV2yhkCtKj03lkxSNM0U8J7pcolHDZn0EdCbsLIPd34ipCn/4Rar4Sjb+qFCwnxaaBdnBuoVwmF13+yO45Ec9MPJMnL3yy2zGPzxN4/8SaJ2j1tNLiacHhcdDqaSVJJ95jasxUzE4zLp8Ll9dFq7w18DmH18Gx5mN4/B48fg9evxej1hgw/pePvkxta62YKFPw4Rf8zDLOIjkymaJvinhq/1PdZLpy+pUsTFxIXWsdd37UPXGKSq6i9IZSALYVb+OQ+VC38w8vf5gLMy5k58mdPLzn4W7nVkxawZ9W/Qm7x06+Kf80vX127WdEqaP4Y+kf2VW9q9u5e5bcw7WzruWz6s+455N7up1bkLCAZy9+FoAb370RgMuyLuPe7HtP+45QYPv27RQUFATy/5vN5m6FAQw983JYtvn3NexjUtQk/mf3//CfE/9hw8wN3Ln4ztPWpQ8qggDv3S9mCVp+l5ghSPCLi4fsvE88LldBxjmQuQKmrYbkeSMnzyAI5nJdgiAgIOBvz86LTDRyn9+H0+fsdh4IBENZXVa8fm+3BJxRqii0Si0OjwO7297tnEahIVYbi8/vo94hduJ1PZ8cmYxcJqexrbFbswkgRh1DlDoKh8eB2dmZPFNAQC1XBwraCnsFADqlDoVLEZLLdT300EPk5eVRVFSEyWQKJPmMjY0lNzeX1atXU1JSMvIdfmM9n1+hUPDkV0/y9LGn0av1uP1ubpx0I5fOuHRA4b3BSN0d/dWTqD58EPu876G8+Pe42nufFfYqUuz/xfnfV1HX7aXtrJ+hWn4b1i//TdR/n0Y5aSEewzRalLF4o9NJnr5w1Hr7v/76a4xGo9Tb34e+a2pqArH94TCfv6MgMJlM7N27N5DOfDCETc3f4m7hV5/+CtNJE3LkTI+dzh9W/AG5TT76HTW7n4C37oCcH8Alfzh9FWG/X1xfUKmBE5/Ap49C3X6wiYUTU8+H7/0bPE7455WgTwVdXPtmFFOPqSLEpoTgB40e1FGBJcoGizSfv3/CeT7/Qw89xJ13Dj5XZVi0+W1uG9e+cS1VLaLxrJ+5PuDmC9H9ll3B56ybQaWD134iBgVd8gh0bXfJ5SBvb4JknCtuAK4WsFaIBg3ifILoFLBVQ+1+cVVih1k0fhDvf/yjzvsqNOJ3Zd8Ah96ED7eCMkIsZFQRkLwAVt4LPq9YOCnUoFCRJlfBERWcfYvYX3HoLTCXgVwpyi+Tw6TFkLoQrJVw/GPx93Sc08Z0Jj85/Db4veJxZOJ1U84Wr6k/KH6+o3dOBhimiCMjbRao3tt+XCaeVKgDUZRUFIO3swMTgKS5YmFoOQmWiu7nIhMgYQZ42jrv25UpZ4uvtftEvXclbhpEJYCtBppPQGQCaWlD6zQLBYaaIDQsjL/KXoXVZUWtUHPfOfexNmNt4Fxtbe1pC2WMCmdeJxrx67eAQgVrf9+9AOgJTVT30QGdEdb9X/dr/P5OT2LtVjG2wN0CLrv4EKfltH82XnzvcYK3rf213Xj8XtEgfB7wufG521DKZbD4RtFID/4bDr0hnhf8IPjETMepC8VOzFc3dpcpYVan8b98kyhPV/I/EldR3v0E7Dnl9yz9Caz9H2g8As98u/s5XTxsau+N/9dNoiF25fqXYVou7H0WPvx993MLNsCVBWLB+XQPozu/bR8BeOM2qCzufu6KAjhjg6iDt+6AM66ldulvxuY5CgJTpw4tliVk3X6P38Mjex6hxd3C28ffJsuQxUPLHzqtN3/MXdo9T4kP2LJbYM0D/RcAY8CgdNTRZBEEQOj0UtTtq904zF3Otb9GxIoFYJtF9Ga6ntdEiec9TrEgA/EciN6DYbL43nJSLIy6Ep0sfq/DLE6+6oo6SozF8LrB8s3pv6MjDsNyErztHYIdj3p0klgItjVDSwNooqm0+cLW7R8qIVnz1zvque3929jXuA8BgWtmXsMdi+/osTdfqx1GIE8wWPRD8PvEGkSuEIcCQ6wAGJSOujZZekLXxypFEQZx6wmVVlxstTc6CoHevrO371Wq+w646uu+EbHiBmjdjb1fN04JOePfU7uHn3/wc+xuO1qFlgfOfYA1GWt6vT4kSuKzbhZrrXfuFof7Vv4ypAqAkNBRiDMRdRRSE3sSEhK466O7sLlsZERl8KfcP6GwK6isrOwzk09CQsKoDfX1mskn/TImrfZA0a+xtrbhPef2kMnkc+jQIWmob5hDfeORkGjz29w2vrF+w5P7nuS9ive4ZuY13Ln4TtSK/oe2xrzNfyofPSwGA636DZz3i7GWBghBHYUg4TzUN1TG3O0/ZD7ET3b+hGZnMxqFhj+u+COrpqwa8OdjY2NHULohcP4d4HPDzt+BUgvLfjzWEoWejkKQiaijMTX+l4+8zP2f349P8DHTOJNHL3h00NlyvV7vCEk3DFbcLQ67vXO32CG1+KYxFSckdRRiTEQdjZnxP/j5g7xw+AUAbphzA7fl3DakfPl2uz3Q7g0ZZDKx19/rhjdvF4Nzsm8YM3FCUkchxkTU0ZgYf3FtMW8ffxudUscjKx7h3LRzx0KMkUUmg7VbwOeC128Vo/AWXD3WUklIBBhV43+j7A3+b///ccxyjLOSz2LLeVtI1CUO656hmHQxgEwGFz8iegCv5IuBMHOvGHUxQlpHIcJE1NGoGL/L5+K3u37LG+VvIEPGj874EfkL8lHIFcO+d319PcnJoZcxN4BcDpc9KnYCFt4oFgRnbBhVEcZSRyaTCYvFQnl5OdnZ2UPOOtMXpaWl3HzzzZSUlPR7HUB2djbl5eVYLBays7OBMHiORoARN/6TtpPkF+VT2VKJXq3nTyv/RHZSdtDuHxYdNXIFXPG4OJHllXwxBHbRD0bt68dKRyaTiUWLFgXmyefk5PRroIOlsLCQzMzMgGH3RUdiDBBTX+3YsSNwLiyeoyAzosbv9Dq595N7qWyp5Kzks/jDij8EfaWbsElMKVfAZX8SY9Xf+LlYACz7yah89Vjp6NQkIkZjH6HBQ2QwM9pycnICQWKnJu4Im+coiIxIhJ/L5+Klgy/xdtXbVDmq2DhzI5elXYbL6sIX5wtq6m6Hw3Fa6u4xifBjgGv1zb8VvcuP/p17sJtrsS7IQ6PVjmiEn8PhGPXU3W+99RazZ88OLIZx7733sm7dOsxm84hE+AG43e4+I/ysVistLS1oNBo8Hk83fSsUipBM3T2SBD3Cr6y5jLyiPOrb6snQZ/CHFX9geuzAMt0OhbCNXuuIBDz7p7D6vhGdCzAWOiosLGTdunWsXi1OBc7MzGT79u0j9n0ymYz+HuVt27aRmZkJQHFxMfn5+YF9KcJvGAiCwPOHnmdr8Vb8gp+1GWu5/5z7h5c+ezxz/h1iE+A/d4HLBhc/LI4GjDOKiooAWL9+fY+5BC0WC1u2bOnzHnFxcWzatGnYsuTl5QW+PzMzk9WrV1NWVtb3h8YxQTP+rbu38uyhZ1HL1Tx43oOsnbq2/w8FgWAlphwTlv4INNHw759BwxG4+u8QNbyhz54YbR31ZOSZmZns2bPntN5+g8HA1q1bR0WujhGHDnnKy8spLy8nMzMzvJ+jIRIU429xt/Ba2WtMM0zj8dzHT0tDPZKE6hprA+bM68GYBS99F7Yvhw3/hEk5Qf2K0dZRT0ZeWlpKfv7pKbhHq+YvLS1l1apVgT6jDjo6IcP+ORoCQTH+KHUUz1z0DFNjpgZl7H4w2Gy28G+HTVkG+R+KBcDTa8WkoEEMBx5tHZWWlpKZmRloT5tMpm77XQlmzX+qx1FaWorBYAh8d9fvMZlMrFu3LnD9uHiOBknQ3P5psdOCdauJiT4Vvv8mvL1JzAtYvVfMCzjEjL1jSXZ2NiaTCaPRGBgtGKnOPpPJFOhX2LJlC4sXLw4M/3Xsb9q0CYPBwKJFi9i2bRsGg4GysrJu4/wTkZCYzz8cfD4fCsXoehsjzp6n4a07IWUBXProsBf/GG0dmUymEYnkG0n60lEoP//DQd7/JaFNx9jyuGLRD+CH/xGz9W4/H9795enppwfBaOqoI6ov3BiXz1E/hL3xu93usRZhZJi0CDZ+Iubh3/0E/GWJmKt/CIymjoK5NNhoMm6foz4Ie+NXq8OvTTxglGo473b48eeQNEdcKvy5a6C5h1TVfTCaOhrqAhJjzbh+jnoh7I1/JOLFQw7jVPjOS3D1M+KiGn/KgVd/DHUHBvbxiaCjYTIRdRT2xt8R4z7ukclgzmVwy25Y9Wsoex8eWwb/vArKP+hckKIHJoyOhsFE1FFIpe4eysQes9mMQqEIn4k9wUjdveTH1E76Frryd4g58A8U/7gcd9wsWubegP6s72B2eLtN7OnQg5S6u3d9t7W1SRN7eiKUhzrsdjvR0dFjLcbYIQhizb/rUSh7T1w0JHOF6CXMvBgi4yUdDYC+dBTKz/9wGPPU3RLDRCaDrAvEzVopjggceF2cL/Dvn8GUc1BNXQXTL4CkeaCQ/uQSImFf84ftlN6RpqVBXIX24L8Rjn+IzO8VlxVPy4H0JeI2aVHfa+9NIKQpvRLjh6gEMVho0Q+oOlHGJHkDVHwBFbuh9O/w8cPidZEJED/jlG0aRKeGZWixxMAJ+5rf4/GgUo2/efDB5DQdCQI0HxfnDzQcgcYj0HgUmo6Ki410EJkgzjnQp4mv0cmgi4MIo/iqM7a/N4qpycOYvp6jUH7+h0PY1/wWi4WEhISxFiOkOU1HMhkYM8WtK34fWCugqQxs1WCvAVuV+P7k5+J+WzMIPUx/latAEwXqaDFHgSZKTFaijBCX5w68akEVIS5kolCJSU2VavFVoQa5sodNIW4yBcjkne/lcnG/tw3a38va92XtGZO6vLbrw9LiJSFlYjUfw9r4XS4XW7ZsYcuWLRMyAeNAGJSO5AqIzRC33vD7wWkRCwGHGRxN4nt3C7js7a8tnfteJ7TYxFePU0xc6nWKS5r73O2vLvCPbfbcNx0rufb+FybUcxTWbn+oyhVKhI2O/H7we8RCwO8Fn7fzvd8jeiWCX9z8PhB84itC+3Gh+3mEzmOnvYf2/0AQcDhayTrvKg5XWXrUUdjocJCEdc0vMY6Qy0GuAUa/5vXabNS29FsHjjvCPrxXQkJiaAyo5u9oGXSEm4YKHfKEmlyhhKSj/ulPRx3HB9BCDisG1OavrKwkPT19NOSRkAhZKioqxlVA2YCM3+/3U11dTXR0NLIRXFxCQiIUEQQBu91Oamoqcvn4aSkPyPglJCTGH+OnGJOQkBgU48r4CwoKMJlMgWWYJU6nsLCQwsJCNm/ePNaihDQWi6XHRUbGEyE9zm+xWAKG3HXFlsLCQgDMZjOZmZnk5uZiMpkAcd31jgc8XPPJDYbB6KiwsBCDwUBubi7l5eUUFBSQl5c3JnKPJoPRUQcmkymQyGS8EtI1v8lkOi2lcnl5OUVFRaxbt468vLzAKiwdq8SAmJmluLh41OUdCwajo3Xr1gUe8LKysrBMsT0UBqMjYMJUHCFt/OvWrSMrK6vbMZPJ1C01tMFgCNT6HempJhKD1VHH+ZycnMCileOdweiotLR0wuglpI2/J8rKyoiLiwvsG41GLBYL2dnZATfNYrGwePHisRJxzOlNRyB6SBaLhby8PEpLS8dIwrGnPx0VFhZSXl4+rnUUdsbfE2azmdzcXCwWCyaTifLy8gnhtg0Gs9lMeXk569evZ/v27eTk5Iz7Nu1gMZvNZGdns27dOsxm87j3JEO6w68nsrKyuv1ROjproLMzJ9zWiQs2vekoMzOTsrKysRMshOjrOQLIy8sb952hYVfz5+bmduvMKy8vn/DGfiqSjvpH0lGIR/iZTCa2b98eGHPtcOW7DtEYjcYJ7eJLOuofSUc9E9LGLyEhMXKEndsvISERHCTjl5CYoEjGLyExQZGMX0JigiIZv4TEBCXsgnwmGh2z0YxGI8XFxYEJKBaLpVtsuoTEYJGMP4TZtm0b0Bm5WFxcHJiWO1Fm5EmMHJLxhyjl5eVs2bKF5ubmwLGsrCyKi4vJysqacNFoEsFHavOHKKWlpafV7kajEZPJxNVXXz1GUkmMJyTjD1EMBsNpbfry8nIWLVoktfUlgoIU3hvCbN68maysrMBss0WLFrF582ZWr1494eLQJYKPZPwSEhMUye2XkJigSMYvITFBGdBQn7Rcl8REZrwu1zUg46+urpYW6pSY8Iy3hToHZPzR0dGA+OP1en2P11RVVZGWlhY8yUYYSd6RZTzJa7PZSE9PD9jBeGFAxt/h6uv1+l6NPyIiApVKFTzJRhhJ3pFlPMo73pq8QQvvfW7XMXSRUcG63Yhjt9vDqiQfrrwj/eCeevcOeXv72l6Pt9/p1PMd8ssC+53Xy2SnHhePyWXi3Tre0/4q7zgX2JcRK3cyfUrqwH/wOCBoxv970wnaPP5g3U5CYlR5YO0UyfiHStGPFpKclBSs2404tXV1kry9EIyor7raOhJ7kVfo8g29hZh1Pd5xvSB0yiYI4lFBIHBQQAhc03He336g470gdH/1t7/SZh3Grw1Pgmb8qclJYTUMIsk7sqSmhJe8fr9urEUYdYJm/N9743sIyvCJFHa73ajV6rEWY8CMlLyy01rrQ7zPKY10l8uFRqMZ0P27frbr9T0dl9HZwJd1/JPJAsc7jsll8m7n5DL5ae8VMkXgupXGlaycs3I4Kgg7gmb8Ou8M9hyYgTGmFaO+ldgYB7H6VpSK0CwQWltbiYyMHGsxBkwoyDuYaSAOhYMIXcSg7hlw7wNufvd90X3vPCa69p3Xdj0mtPv6PsHX7Zxf8OPH3/m+fXPGOAf828YLQTP+m+ffSKSnnq+rbeypaMHnF5iRFMW7ty0H4JW9lcxNjWFaQhRy+dgPmVitVmJiYsZajAEjyTuyWK1Sm3/IzEkz8IfpYm+p0+PjSJ2dFqcXgKYWF3fs+C8+v0C0VsmZk2PJmRzLzedPRacem2RC4TQGDZK8waC0tJSbb76ZkpKS086ForwjTdB6ZLou96xVKVgwycDZ0+IBiIvS8N/frOG5m5eQf34mCpnoCWiVCgDu+/cB/vrBMb6qsODzj04zIdyWp5bkHR4d6/KVlpb2eD7U5B0NRq3ajdQoOTsrnrOzxAJBEARkMhl+v8BJs4MXi0+y7T+HidYqOXdaPL/61hxSDf23GSXGNxaLhc2bN5Ofn092djYgJjlZvHjxoBKaSMlPTmdAyTxsNhsxMTFYrdZew3uH2xvt8fn5b6WFT4818cmxRv72g8Xo1Eq2/ecQSoWclbMSWZAWE7T+Aqm3f2QJtrwFBQWUlJSwefNmMjMzAyvv3n333YFCYSDIZLIeOy77kncgz384EjTjb2pqIi4uLugC3v2vfbz532psTi+J0RounJvMj1ZkDdsrGCl5R4rxJO9Q1yKwWCxs2bIFIPCZUwuF/ujN+PuSd7waf9Dc/ra2tmDdqhtbrpzP/ZfPpeSbZt49UMc7X9dy68ppALy6twp9hJJzpsWjae8/GCgjJe9IMV7kHc5aBAaDga1bt1JeXk5+fj45OTnk5eX1WCgES97xTNA6/GRyGW6fO1i364ZSIWdJZhy/+tYcPt50AYl6LQAvFlfww7/tYdEDJu7c8RUfHWnA6xvY/AKFYnCFxVgzHuTtWIugw/Chcy2C8vLyAWclzszMZPv27VgsFvLz8wOFwurVq8nJyQmavKNNYWHhkOUfCkEz/kpZJat2rOLh4oc5bj0erNueRteor+duXsK7t53PD87OoPiEme8+tZsjdS0A1Nmc+PsYOUhJSRkxGUeC8SBvsNYi6Kj5DQYD27dvB8ROwKKiInbu3Bk0efvDYrGwbdu2gDfTQWFhIYWFhRQUFGAymQZ8v3Xr1mE0Ggctx1AJmtuvbFFyedblvFb2Gn8/8HcWJS3i+3O/z/L05cH6itOQyWTMSIrmF2tmctvqGRyqtTMrWZz2+v2ni7G1ebh8YSpXZqcxLbH7dNjKysqwysoyHuQNxloEmzdvBggY/WDb/NBz38JQ9GsymU7rKygvL6eoqCgg3+rVq0N2daWgGX9SRBJ3TL+Dn2b/lJ0nd1J4pJCjlqMsT19Os7MZv+AnLmLkOqxkMhmzU8TOGEEQuO/yubyyt4pnvzjJXz8oY35aDI/fkEOaNHw4ZuTm5lJUVERBQUHAUPPy8ti8eTOFhYV9Dsf11Nu/Y8cO8vPzycvL6/e7TSYTRUVFAGzZsqXPoUKXy4XL5Qrs22y2Hq9bt24dZrMZi8XS7Xu6FiwGgwGTyURubi6FhYWnxRMYjcYxG4YclPFXVVVhs9lISUmhsbERj8eDRqPBYDDgcDiorKwkJiaGc+PPZb5qPoIg4PV6+cvuv/DKN69w0aSLyM/OR2bvzAwkl8sDyktKSsJiseByuVAqlSQmJlJdXQ2IqcSUSmVg7brExERsNhtOpxOFQkFycjJVVVUAREVFMTdRS8riWG7KjuFAs4y391XjsTVS7VCw40ArOq+NlV4/xphotFotTU1NAMTHx+NwOHA4HMhkMtLS0qiursbv96PT6dDpdDQ2NgIQFxeHy+WipUVsakyaNImamhp8Ph8RERFER0dTX18PiH9kj8eD3W4HIDU1lfr6erxeb0CHdXV1gPjA+P3+wEOXkpKC2+2msrIStVqN0WiktrYWIBBC2xGempycjNlsxu12o1KpiI+Pp6amZkj6VqlUgYc1MTERu91OW1sbCoWClJQUKisrA/rWaDTddOjz+aisrEQul5OamkpVVRWCILB58+ZuOtRoNPz+97+ntbU1kEqrQ98RERF4vV5uv/12rrvuOq6//nrcbjc//vGPOeOMM3j88cepra2lsrISrVaLXq8P6Ds2Nhav1xvQ98qVK5k3bx633nprQN8d8hsMBmQyWWC/oKCA+++/fzCmEaCsrKybJ2A0GgP6DrVYg6AN9bW1tRER0XOtanVZef7Q8zx78Fla3C1cnHkxG8/YSHr06CcF9fr8XPvE5xSfaEavVXLZwlSuyp7EwnRDSKdp6ku/oUg4y9tTzZ+ent7j819QUIDFYgl0Ym7evJm4uLjAftdRif4wmUzk5+ezdevWUSkogtbh11Hq90SMJoaNZ2zknave4ReLfsHnNZ/T4hZrS5/fFywRBoRSIWfHxrN57rqZXL90CqYD9WzY/jm29nkIDrd3VOUZKH3pNxQJZ3k1Gk0gX2VfeSt7Iisrq9u+2WwecF9Ebm4uZWVlo+YhjOqsGp1Kxw1zbuDaWdeilCvx+X1c99Z1ZCdlkzc/D4PWMGqyTI7Vsmn+JG5fM5MjdXZiIlQ4PT7O+f17LEw3sH5ROqtmJw46fkBiYpObmxvolASxAzBUO/wG5fYfOHCA6OjoHtv8lZWVqFSqPtugarWauLi4QBtUG6nl+WPP88zhZ5DL5Nw07yYuSroIwSsMu82vVqsD7dWEhARaWlpoa2sLtEGPHz+OSqUiMjIy0OZ3ef18XOmmsKSK/TUt6LUKrsxO54fZBuQIY9rmr66uRiaThU2bv7m5GZ/Pd1qbvycdOp1OWltbT+tjiYiIICoqioaGhoAO3W53QN9paWnU1tbi8/n6bfP3p2+n04nT6Qzou6mpiYKCAp555hkAjhw5cprb3xFi3BFv0FFjd0wiMpvNY9qh1x9Ba/N3/NCh0NTWxONfPU7hkULmxM/hnxf9c8Tb3/3Je6zezo6SSr5pdPD4DTkIgsALxRWsmZNEXJRmRGXrieHodywYT/KO1/DeoBl/MMahT1hPUNNaw7LUZTS2NdLqaWWKfsqw7tkbg5X3WH0LF/3vRwCsnJXI+px0VsxMQKkYnTx142GcP5TpS97xavxBe3KDkawxIyaDZanLAHhy35Nc+dqV/PXLv+Lyufr55OAZrLzTEqP44p5c7r5oNifNbdz0jz2se/yzoMvVG+GUDBMkecOBoLX5O9pPg2nz99UG9cq8vF77Ok9//TSJ2kTuOPMOzk49O2ht/o42aNc2Pwx8nP9IgwO3IoKlk6M5Wm3mV/85wbVLM1mSrCBKLQt6m79D3+HS5u/QYbi0+U/V90Da/OFO0Nz+kVqbrdxazoOfP0hpXSlvXvkmqVHBWVghmPIeq7ez9T+Hef9QPTKZ2Cy4ZvFkLpiVGJT7w/ha+y4U6W+tPsnt74PBZHYdDJkxmTy55kle+NYLpEal4vF5+KDig2F/XzDlnZYYzRPfXcTn96zirotmU21x8uY+sba1Oz18Ud7U5ySjgTBS+h0pJHlDn+Cl7taN3KIHMpmMmcaZALxX8R53fHgHK9NX8sulvyRBlzCke46EvPFRGm48dyo3njsVt1ecWrzzYD0/f/FL0gwRfPvMVK448/RJRgNhJPU7Ekjyhj5jOs4/1Nj+T+o/4bEjj+H2ucmbnseFky4kJSVl2OP8EPzY/tq6OvbVtPLBiTb+c6AOu9PHlfPjePjas6RxfkKnzT+Ucf5wJ6SG+gaDxWlha/FW3ih/g4LVBYFRgoEyFkNRLq+P9w81EBOhYllWHJ8cbaTg43K+vTCV1XOSiNb2nj56PA2dhSITcahvbJLmBwGD1sCW87Zw7axrmR8/H4Di2mIWJS0K2Qk6GqWCtfOSA/tyOTjdPn7x0leolXJWzEjg+qVTOH/G0JoyEhKDIWgdfmOVXHJBwgJkMhn7G/fzw3d+yK3v3Uq9o77fz4VCMsyzs+J5aeMydt21kk0XzqTO5mR/tei+n2hs5e19NbS5xYlPoSDvYJDkDX2C5vY3NzcTGxsbdAEHw/sn3+e+z+/D7XNz95K7uWTqJb16AaEgb0/4/QJyuYwnPy7ngTcPEqFSsGJmAudP1XPpoqlEacLDWQtV/fZGX/JKbj99J/OoqKigtbV1VDr8oOcgn+ny6fxl8V94svxJ7v74bhqaGlidsrrHDr8OeUe6w2+oQT5XnxHP3NhZfFBmYddJB3fvr2XvSTN3rJqKShdNVU0dhghlyHb41dXV0draGjYdfo2NjbS2tgI9d/iNR0I+yGeofFT5EUtSlqBRaDjSfITphundvIBQk7c/Sg4eJyUlmVRDBE9/epz73zjAogwja+YksXpOElPiQmvF4XDT70QM8gma8Ycq9Y561r68lrOSz+I3y35DSlR4ZcHtiQa7C9PBOooO1PHJsUbcXj/552dy98Wz8fj8yGUyFCGwEvJ4IZyf/74ImvFXV1eTmhqc0Ntg81HlR9z32X3Y3XZuX3Q762aso7amNmTl7Yne9Nvq8vLx0QaS9FrOnBzL619V8+vX9rN8RgIrZyWyfEYCBt3oL/MVys9DT/Ql71ga/8MPP4zBYMBoNHLllVcG9d5B6z3y+we2WMZYcP6k83nl8lf4Q8kfuP/z+6lz1HFFwhVjLdag6E2/kRola+d1ejNzU/XcsHQK7x2q57Uvq5HL4IfnTOWX35oTWAF5NLyCUH4eeiJU5X3hhRcoLCwkIyOj2/GdO3ditVqHVSAEzfhDPVljtDqa3yz7DWsz1jI5ejJql5qjzUdJj05Hq9SOtXj9MlD9ZiVEcfuamdy+Rhw6fP9QPQnRYvKRz8ub+PGzpZw7LZ7zpsdz3oyEEUtlHurPw6mEqrwbNmw4zfABVq1aBcDGjRuRyWQ89thjg7530Iw/KioqWLcaUZakLAHAoXDw07d+ikwm45dLf8nZqWePsWR9MxT9Jum1XHPW5MB+eqyO752dwcdHG7jnlX34BVg7NzmQqcjc6g5alqJweR46CFV5u3ZSv/zyyxw/fpzc3FwWLlwIwOOPP97vGoe9EbShvsOHD2M0Gsd0qG8wsf3Hjh7j1/N+zWNHHyO/KJ8VSSu4efrNzEibERJDfafG9h87doyYmJhhxfYb9HrylqVy9WwdNmcaZS1KXG3iegsnLB6u/+cBsuK0ZE+K4qyp8SzKMKLytgb0PZihvhMnThAVFRU2Q301NTWB2j+Uhvq6LgBy1VVXcdddd1FeXg4QKACGnCBUGABWq1UABKvV2us1FRUVA7lVyNAhr9/vF1479ppw3vPnCd958ztjLFXvjLR+LQ638EpppXDHS18K527dKUzZ/IZw9padgfMvFZ8U9lVaBI/XN6D7hevz0BMDef5Hio0bNwo2my2w/8QTT5x2TUFBwZDuHbTefofDETrTIlsaoPkEuGyAAAJgnApxWeK5hoO0KfVExE8BrQFkMqwuK/WOeqbHTudY8zEqWypZPml5yMwTGG391tucVFudLEw3YG3zsPgBE26fH51awcJ0A4umxJK/PIvIXiIOQ+p5GAB9yTuWvf1yuRyZTEZmZia5ubmYzWaefPJJoqM7p4U/+eST3HTTTYO+d9Da/G63e3T/2O5WqCqBii+g8RhYK+GqJ0CfCu/cDft2dL9++V1wwd1Q8xU8exWB7h2FGlKzibnxHWI0MfBFAW9Z9/FEzQcsS1nKpsWbmRY7bfR+Vy+Mtn4T9drAUugxESr++9s17K+ysuebZkq+aeaVL6v46arpANy54yuUCjk5U2LJmRJLRpxu9J+HYRKq8m7dupW8vDyKioowmUyUlJQQExNDbGwsubm5rF69mpKSkiEZf/hM6W1pgPqvIXMF+P3wUCa0NYMmBhJnQUw6rPo1xE6BhiPgc4E2BmRycVNHgVYPXhfYqqgv30dihAAt9SBXwOIbweeBR2YhOBr5MCKCh+KMVCkVrJt6ET9ZcjexMqV4nzHwBkJ5iuxvX/+aXWWNgeXR4yLVbLtkCquyZ1BtaSNSrSRG1/t05VAg3Kb0mkymwLZ37158vsGvfBXas0SsVXDw33DwdfhmFyhUcHclKDXw7cfAMBkSZonG25WEGb3fU6kBYyZuhxpO/WMrVHDnMWQtdayo+5qza/fzXNVOnq0vZaPgg5d+gK/hEIrJSyF9KWScA4lzxbm5E5jfXjYXAKvDQ2lFM6XfNJMaI44aPPjmQd7cV8Nko475aTHMS4th9ZzEIWUzkugkNzc30NH30EMPDekeQav5BUEITvvYZQdNNDitsC0TkEHWBTDncpiWC9HJ/d5iIAxGXq/fi1KupOXQm2zYcz9XeBR8p+ooOq8LNvwTZl8K5nJQRUJ0UlDkG468oUCHvMcbW/myopl9lTb2V1n5utrKby6by9WL0nnn61peLK5gToqeOal6ZqfomWzUjUlocl/6DcWavyvHjx9n6tSpg/5c0NJ4HT58GIPBMLShPnMj2oqPMJa/BtV7qb72PZRqLYm2fdQo0hA0+qAP9e3fvx+DwTCoWX0+pY9/lP2Df5X9i2hlFDemrmDtjO/h8Wsxvr8JXdmbeIwzcaadjX/GWiKmL6e+UbzvcIf6jhw5QnR0dNik8Tp58iQ6ne60oT6NNgKNNgKbxcxnJ2y8fsjKwVo7jS0eAC6Zn8K9FyRja/PwzlE78ycbiVO4MOqUxMXFjdhQX11dHRqNJqBvKY1XOyPW5vd54aNtUPoM2Ksh9UzI+QGccS0oRzYefTht6Ep7JY999RhvlL/B8knLeXTlo2KfxPEP4dhOOFYErQ1wyR/EvoSWBlBpRY9mDOQdCwYrb4PdxcEaG5EaBTlTjOyvsrLu8V04PWLYbUyEivlpMfzzJjFIq/RkM0l6LSl6LfIgeArh1uYPBkFr82u1AwyRFQSoLoW0HFAo4cSnMONCyPk+pC4Mljj9MmB5e2BS9CQePPdBNi7YiMPrAKCk9SS7fQ185+LfE6P6izgSYWx3xT5+GPY8BRnnwcyLxC1mcIY8HHnHgsHKmxCtISG6M33ZvLQYvv7dWirMDg7V2ilraKHVJS6fLggC3/u/3dhdXiJUCqbGR5KZEMnmtbNIN+qotzuJUCn6zIk4XHnHA0Gr+Tvc+l7xeeDrV+CzP4vDbXkfiDW9IIxJ73m/8g6Slw6/xLbibSjlStbPWM81s64hLap9fnjzN3D4bTj8FnzzKfi9cPHDcNbN4HGKw439dBoGW96RZiTlFQSBCnMbxxrslDe0UtbQSnlDC3+69kwS9Vp++vxeXv+qmvgoNRlxkUyJi+TK7DTOmRaPw+3F4xVOG33oS97xWvOPjttf/CR89Ijo2metgrNvgcwLxsToOxgJN7qxrZFnDjzDjiM7aHG38PDyh1mTsab7RU4rHDNBykIx6Oijh6D4/2DGWpj1LZh6njgiMQryjiRjKe/hWjuHam0cb2zlmyYHxxtb+e6yKVyZPYnXvqziZy98iV6rZHKcjslGHStmJHJ2ikxy+4OGrUZs50bEgsMM01bC0p9A0pwR+8qxJj4inttybmPjGRt5s/xNzko+C4B/fP0PlHIll2VdRpQ2BuZd1fmhabngaIbDb0LJ06COhgsfEJtBEkNiZnI0M5N77l9ZMjWOP3/nTE6aHZxscnDS7KDS0gYpoRfgM9IErebvyIdH4zHY9b/w1Qtw3h2wYnPQhQ4GAXlHgd/u+i2vHnsVrVLLZVmXce2sa5kac8rQjCBA/QE49BZMPR8mL4G9z8JXz8PMi3CkL0c3ad6oyBsMRlO/waAvecdrzR8047eX7yF6z6Nw4HWISoRlPxF77rWhqSyr1RoYJhsN6lrr2HFkBzuO7MDsNPPWFW+Rrk/v+0NHTfDF4+Iogs8N8TPh/DtgwdWjI/QwGG39Dpe+5B2vxh80t7/NXEV07T649I+w4BrR5Q9h7Hb7qD6cSZFJ3HLmLeQtyOPzms9J16cjCAI/2fkTspOyuSzrMhJ1p6zqOz1X3FwtNBYXEt+4u7M/4JgJvnwepq8Rmw6RoZV3frT1O1zCTd5gELyJPck5cMue00NtJbqhVqg5f9L5ALR524jVxvL4V4/zp71/4uzUs7l82uXkTs5FKe/yp9FE4czIhXO/33nM64Kmo7C/EJDBpEVwVl5YeAUSoUHQIvxqa2uRyWRhk8yjoqICmUwWEnn7PXIPX1i/4F+H/0WDs4FXL3kVmSDj65qvmaSbRGpqKg0NDXi93tMi/AwKJ4oTHyAceQdXymKiV/4C28H30JY+iWfK+UQtuJQah2JI+h5OhF9LSwtOpzNsknn4fL7AtVKEXxcG0uapra0lOTk4cfejQajKa3VZidHEUNtay5rCNaRHp3Nx5sUsjlrMWdPOGthNyj+EnfeJwVSCH+JnwJnXwzk/G1nhuxCq+u2NvuSV2vz94PV6g3WrUSFU5Y3RiJ5TQkQCBWsKeKv8LZ498CyPex4n+2g2f1v7t/4n+GQuh8yd4hDr8Y+g/P3Ocw1H4OUbxRGFqcsh/SyIMAT9d4Sqfnsj3OQNBkEz/o5JEeFCqMurkCtYmrKUpSlLuXfpvbx54E3alG3IZDIcHge3vHcLyyctZ82UNb0vRKIzwtxvi1tXEufA/pfFaEtkMH01XNee/KSlAaKGv0pwqOv3VMJN3mAQNLff4/GgUoV2woauhLO8NS01/M/u/+HTqk/x+D3Mj5/PhRkX8t053x34tF9BEKchn/xMHEZc9EPRU9g2VcyTkHqmuKUsFOckKAZXT4Szfk9lvLr94ZPJJ8iMB3lb3C18WPkh7554F7ffzWO5j+Hz+3hq/1OcN+k8ZsbOHFwOALcDjr4LFbuh5ktxDobfJyZQUSjhvQdAHSkWCKkLxejNQcgbykiz+iTCiih1FJdkXsIlmZfQUYZX2Ct4ev/TPLr3UVIjU1k5eSUXpF/A4uTF/RcEal33ZoLfD7aqzlq/+kvRU3CLve3EZsDVz0DKAjGHojqyzwJBIrQImvF3zS8eDow3eTsMOyMmgw83fEhxXTHvnXyPd0+8y67qXbz27dcAePfEuyxKXoRRa+z/S+VyMHSJQry+UCwQmo6JnkH1XtC3z1x891fw9b8gdiqkLiQhbg5oLoeEmUP4taNPuD0PwSBobr/NZgsrl2iiyOsX/DS1NZGgS6CmpYY1L69Bhoz5CfNZPmk556ady2zj7OGnCDOXQ+UesUCo/hKh5ktkF22F7O+KId+f/1UsCBJmt7/OAn3orJjcl37Hq9svtfnDhGDJ29jWyMeVH/Nx1cfsqt6FRqHh/avfRy6Ts6t6F3Pj5gaGG4cl78lvmJSaLIYjH/8ISv4ODYehsT2z8qxvwTXPihmY//1ziJsmbsapovcQlTiqU76lNr/EuCc+Ip4rpl/BFdOvwOPzUNFSgVwmx+628yPTjwBYEL+ApalLWZK8hIWJC7uHGg8UuaJzHsLU88UNxA7E5hNi8BGA0wZtZvjyOTHfA4BCA/fWisb/7i/FpoYhXRyFiEmH+OmgCs2FNcOJoNX8Pp8PhSJ84voleU+ntrWWT6o+YVf1LnbX7qbN08an136KVqnl3RPvkhadxqzYWSgGMH9jSPK6W8WCoaUOslaKxwpvFJsS1krRYwC44VUxo/Oep8QMSfq09i0VUs6A5HmDzhDVl7zjteYPmvHX19eTmJjY47lQRJK3b/yCnwp7BVP0U/ALfla+tJImZxN6tZ6zks9iScoSLs68GL16lJ4Hv19MimqtEMOVtXr46kU48KpYMNiqwdEIS38Ma7dAZQn8/VIx1Xt0iphSPXYqrPqVeL+Tn4NKJzYvdPHUN5l7lXe8Gn9Ql+sKJyR5+0YukzNFPyXwvmhdEf9t/C9f1HzBFzVfsLV4K7lTxEUjXj7yMkq5kiUpS0iOTB4ZeeVy0YC7rotwxgZx68DjFAOWQOxMvOAesNeInoS9FhxNnde+cJ1YWADMW4d76e+CK28YELRZfUePHkWv14fNrL4DBw6g1+tDYlbfQJfojoyMDJm8/YYEA021os7u338/u+p2AZCmS2NpylJWGVYx1TA1dGf1yVownzyIoq0JXcJk6tVTUCqVAX1Ls/raGYjb4/V6A8oLByR5g0uzs5ndtbsDnsEj5z/CrPhZPHvwWU5YT5CTnENOYg4JuuHPGxgJ+tKv5Pb3Q21tbVgNnUnyBpdYbSwXZlzIhRkXAgTm+rd52/is5jNeOPwCAFP0U7gt5zZWTV6Fx+dBKVeGxDJkoa7fkSB0qxKJccFN82/ipvk30eBooKS+hNK6UhIixNr/uUPP8dT+pzgz8UzOTDyThYkLmWOcg0oRPhOCwpmgGX+45T+T5B1ZTpU3QZfA2oy1rM1YGzi2KHkRVpeVLxu+5M97/4zT52TDzA38cukvaWxr5Kv6rzgj8QziI+JHXd6JgFTzS4wZc+PmMjdOXN7b4/NwyHyISJWYPntP3R7u/PBOANKi0lgQv4Blqcu4YvoVYybveCNoxm+1WomODp811yV5R5bByqtSqJifMD+wvzZjLQsTFvJVw1d81fAV+xr28Vn1Z1wx/QpaPa3kvZvH3Pi5zI+fz7z4eUzRT0Eu63vJs2DKOx4ImvHLvG3ilM8wQdVYD/LGsRZjwExEeZOBZHUSF6atgbQ14rTl6i9pdTYzWRXNrpPv8/yh5wEwqqJ5b/mfUcjklDQfJlUbR7I2bsCdiarGekg0itOaJwhBM/5EuRUKVgXrdiNOUv+XhBSSvNBhxonAlvb3VrmMA2o1NcomFE9cgADcOnkSdoWcWJ+POS43c9xuvmOzE+/z9y1v4oejulL0WBM047coE0nI+zBYtxtxmi3NxBrCJ/GEJG/PxADLuuzLgFecZg7YTnDAfpwDthP8y3acDZfeB1ojWw//k/LWamZHT2FWdAZz9BlMikjAarUSGz9jxOUNKYQBYLVaBUCwWq09nnc6ncJtt90mOJ3OgdxuzJHkHVlCTV6/3y/4/X5BEAThxUMvCreYbhFWvbRKmPe3ecK8v80Tnt3/bJ/y9vf8hytBifALtwgoSd6RJVzkbWpr4pD5EEnKJKYnTx83z/dAkYb6JCYscRFxnJN2TmAOxURj6GMjEhISYc2Aav6OlkFvJWTH8XApQSV5R5bxJm/H8QG0kMOKAbX5KysrSU/vZy15CYlxTkVFxbia/DMg4/f7/VRXVxMdHR0SM7AkJEYTQRCw2+2kpqYil4+flvKAjF9CQmL8MX6KMQkJiUEhGb+ExARlwOP8FouFgoICADZt2tTjNYWFhQCYzWYyMzPJzc0NgohDYyDyrl+/nrvvvhuAF198ka1bt46afD1RWFiI2WympKSE9evX96i/UNLxQOQNJR0XFhaSmZnJnj17AMjLy+vxGggN/Y44Aw0F3LFjh7Bp0yZh69atPZ4vKysT8vLyAvu5ublDDDoMDv3JKwiCkJ2dLRgMBiE3N1dobm4ePeF6oKSkRNixY4cgCILQ3NwsGAyG064JJR0PRF5BCB0dNzc3C9nZ2YH3PT36oaTf0WDAbv+6devIysrq9bzJZOq22KHBYMBkMg2nXBoW/ckLcPfdd9Pc3ExRUdGYL9RoNpspKioCRN0ZjUZKS0u7XRNKOh6IvBA6OjYYDJSUlABQXl7eY40eSvodDYIW3ltWVkZcXFxg32g0BlJEhyrFxcUAgfTUPbmBo0Vubm63B9JsNpOdnd3tmlDS8UDkhdDSMUBBQQFFRUXs2LHjtHOhpN/RYERj+zv+4KFK1/ZnVlYWV1999Zh7AAD5+fk88cQTA7o2FHTcl7yhpuO8vDwyMzPZvHkz27dv7/f6UNDvSBG03v5TXeyODpNQpbCwkM2bNwf2DQYD5eXlYyiRSGFhIatXr2bdunWnnQtFHfclb6jpuKMWz83N5aWXXjrNpQ9F/Y4kwzb+rgrtcPGg93bVWNMhb2ZmJqtXr+52vCe3dTTpaHOuW7eO0tLSgKGEqo77kzeUdFxQUMCWLVsC+0ajEaPRGJALQk+/I82AI/xMJhPbt2/HYrGQn58fKOmzsrIoKSnBYDB0GyYxGo091gajxWDkLS4uJj8/f0xL+fLycnJycgL7FoslMJEkFHU8WHnHWscWiyVQWBUVFREXFxcYAg5F/Y4GUnivhMQERYrwk5CYoEiZfMIEk8mExWKhvLyc7Ozscd0WlRgdJOMPA0wmE4sWLQoMkeXk5AQCViQkhork9ocBFoul29h4Ry+1hMRwkIw/xDGZTN1c/G3btpGfnz+GEkmMFyS3P8TpqPU7xsszMzN7naUoITEYpJo/TCgqKqKoqAiz2Tyu480lRg/J+EOYU9v6QLf56BISw0Ey/hBmz549pw3plZaWjut4c4nRQzL+EKZrvDyInX+ZmZmS8UsEBSm8N4QxmUyUl5djNBpDZj68xPhB6u0PcSRjlxgpJLc/ROmI6pOQGCkk4w9Reurpl5AIJlKbX0JigiLV/BISExTJ+CUkJiiS8UtITFAk45eQmKBIxi8hMUGRjF9CYoIiGb+ExARFMn4JiQnK/wdJUFJPuFbnPwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 237.5x240 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "IMG_DIRECTORY = \"./Assets/powerlaw_combined\"\n",
    "if not os.path.exists(IMG_DIRECTORY):\n",
    "    os.makedirs(IMG_DIRECTORY)\n",
    "\n",
    "\n",
    "def save_plot(fig, name, formats=[\"pdf\",\"jpg\"], date=False):\n",
    "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    for f in formats:        \n",
    "        path = \"{}\".format(name) + \"_{}\".format(current_date) + \".\" + f\n",
    "        if not date:\n",
    "            path = \"{}\".format(name) + \".\" + f\n",
    "        fig.savefig(            \n",
    "            os.path.join(IMG_DIRECTORY, path),\n",
    "            format=f,\n",
    "        )\n",
    "\n",
    "\n",
    "def set_size(width, fraction=1, subplots=(1, 1)):\n",
    "    if width == \"thesis\":\n",
    "        width_pt = 426.79135\n",
    "    elif width == \"beamer\":\n",
    "        width_pt = 307.28987\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    golden_ratio = (5**0.5 - 1) / 2\n",
    "\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    fig_height_in = fig_width_in * (golden_ratio) * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n",
    "\n",
    "\n",
    "# width = 1.5 * 458.63788\n",
    "\n",
    "multiplier = 1.25 \n",
    "width = multiplier * 487.8225\n",
    "multiplier = 1.25\n",
    "width = multiplier * 1.5 * 234.8775\n",
    "\n",
    "plt.style.use(\"../latex_ready.mplstyle\")\n",
    "\n",
    "tuple_size = set_size(width, fraction=0.50)\n",
    "tuple_size = (2.375,2.4)\n",
    "\n",
    "multiplier = 0.9\n",
    "second_multiplier = 0.7\n",
    "\n",
    "\n",
    "# import Line2D for custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=1,\n",
    "    sharex=False,\n",
    "    sharey=False,\n",
    "    figsize=( tuple_size[0], tuple_size[1]),\n",
    "    gridspec_kw={\"hspace\": 0.33,\"wspace\": 0},\n",
    ")\n",
    "\n",
    "\n",
    "# ICML adjustments\n",
    "fig.subplots_adjust(left=0.01)\n",
    "fig.subplots_adjust(bottom=0.12)\n",
    "fig.subplots_adjust(top=0.99)\n",
    "fig.subplots_adjust(right=0.82)\n",
    "# plt.subplots_adjust(bottom=0.30)\n",
    "\n",
    "\n",
    "\n",
    "# Create a custom legend\n",
    "custom_legend = []\n",
    "\n",
    "linestyles = [\"solid\", \"dashed\", \"dashdot\", \"dotted\"]\n",
    "\n",
    "\n",
    "for epsilon_idx, epsilon in enumerate(epsilons):\n",
    "\n",
    "    # ax = axes[epsilon_idx]\n",
    "    ax = axes[0]\n",
    "\n",
    "    for df_idx, (key, value) in enumerate(df_dict_beta.items()):\n",
    "\n",
    "        beta = key\n",
    "\n",
    "\n",
    "        eps_dict = value[epsilon]\n",
    "\n",
    "        if beta == 0.5 or beta > 1.5:\n",
    "            continue\n",
    "\n",
    "        alphas = eps_dict[\"alphas\"]\n",
    "        adversarial_error = eps_dict[\"adversarial_error\"]\n",
    "        generalization_error = eps_dict[\"generalization_error\"]\n",
    "        boundary_error = eps_dict[\"boundary_error\"]\n",
    "        class_preserving = eps_dict[\"class_preserving\"]\n",
    "\n",
    "        adversarial_error_erm = eps_dict[\"adversarial_error_erm\"]\n",
    "        generalization_error_erm = eps_dict[\"generalization_error_erm\"]\n",
    "        boundary_error_erm = eps_dict[\"boundary_error_erm\"]\n",
    "        class_preserving_erm = eps_dict[\"class_preserving_erm\"]\n",
    "\n",
    "        adversarial_error_erm_std = eps_dict[\"adversarial_error_erm_std\"]\n",
    "        generalization_error_erm_std = eps_dict[\"generalization_error_erm_std\"]\n",
    "        boundary_error_erm_std = eps_dict[\"boundary_error_erm_std\"]\n",
    "        class_preserving_erm_std = eps_dict[\"class_preserving_erm_std\"]\n",
    "\n",
    "\n",
    "        adversarial_lines = ax.plot(alphas, adversarial_error, linestyle=linestyles[epsilon_idx],color=\"C0\")\n",
    "        ax.plot(alphas, generalization_error, linestyle=linestyles[epsilon_idx],color=\"C1\")\n",
    "        ax.plot(alphas, boundary_error,linestyle=linestyles[epsilon_idx], color=\"C2\")\n",
    "        # ax.plot(alphas, class_preserving,linestyle=linestyles[df_idx], color=\"C3\")\n",
    "\n",
    "        custom_legend.append(Line2D([0],[0],color=\"C0\", linestyle=linestyles[df_idx]))\n",
    "        custom_legend.append(Line2D([0],[0],color=\"C1\", linestyle=linestyles[df_idx]))\n",
    "        custom_legend.append(Line2D([0],[0],color=\"C2\", linestyle=linestyles[df_idx]))\n",
    "        # custom_legend.append(Line2D([0],[0],color=\"C3\", linestyle=linestyles[df_idx]))\n",
    "\n",
    "        ax.errorbar(\n",
    "            alphas,\n",
    "            adversarial_error_erm,\n",
    "            yerr=adversarial_error_erm_std,\n",
    "            fmt=\".\",\n",
    "            markersize=1,\n",
    "            color=\"C0\"\n",
    "        )\n",
    "        ax.errorbar(\n",
    "            alphas,\n",
    "            generalization_error_erm,\n",
    "            yerr=generalization_error_erm_std,\n",
    "            fmt=\".\",\n",
    "            markersize=1,\n",
    "            color=\"C1\"\n",
    "        )\n",
    "        ax.errorbar(\n",
    "            alphas,\n",
    "            boundary_error_erm,\n",
    "            yerr=boundary_error_erm_std,\n",
    "            fmt=\".\",\n",
    "            markersize=1,\n",
    "            color=\"C2\"\n",
    "        )\n",
    "        # axs.errorbar(\n",
    "        #     alphas,\n",
    "        #     class_preserving_erm,\n",
    "        #     yerr=class_preserving_erm_std,\n",
    "        #     fmt=\".\",\n",
    "        #     markersize=1,\n",
    "        #     color=\"C3\"\n",
    "        # )\n",
    "\n",
    "    ax.legend(title=f\"$\\\\beta={1.5}$\",framealpha=0)\n",
    "    # Set the major ticks to face inwards\n",
    "    ax.tick_params(axis='both', which='major', direction='in')\n",
    "\n",
    "    # Set the minor ticks to face inwards\n",
    "    ax.tick_params(axis='both', which='minor', direction='in')\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ax.set_ylabel(r\"$E$\", labelpad=0.5)\n",
    "    ax.set_xlabel(r\"$\\alpha$\", labelpad=0.1)\n",
    "    ax.grid(which=\"both\", axis=\"both\", alpha=0.5)\n",
    "\n",
    "    # put the ylabel to the right\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "    \n",
    "\n",
    "\n",
    "    ax = axes[1]\n",
    "\n",
    "\n",
    "    eps_dict = df_dict[epsilon]\n",
    "\n",
    "\n",
    "    betas = eps_dict[\"betas\"]\n",
    "    adversarial_error = eps_dict[\"adversarial_error\"]\n",
    "    generalization_error = eps_dict[\"generalization_error\"]\n",
    "    boundary_error = eps_dict[\"boundary_error\"]\n",
    "    class_preserving = eps_dict[\"class_preserving\"]\n",
    "\n",
    "    adversarial_error_erm = eps_dict[\"adversarial_error_erm\"]\n",
    "    generalization_error_erm = eps_dict[\"generalization_error_erm\"]\n",
    "    boundary_error_erm = eps_dict[\"boundary_error_erm\"]\n",
    "    class_preserving_erm = eps_dict[\"class_preserving_erm\"]\n",
    "\n",
    "    adversarial_error_erm_std = eps_dict[\"adversarial_error_erm_std\"]\n",
    "    generalization_error_erm_std = eps_dict[\"generalization_error_erm_std\"]\n",
    "    boundary_error_erm_std = eps_dict[\"boundary_error_erm_std\"]\n",
    "    class_preserving_erm_std = eps_dict[\"class_preserving_erm_std\"]\n",
    "\n",
    "\n",
    "    adversarial_lines = ax.plot(betas, adversarial_error, linestyle=linestyles[epsilon_idx],color=\"C0\")\n",
    "    ax.plot(betas, generalization_error, linestyle=linestyles[epsilon_idx],color=\"C1\")\n",
    "    ax.plot(betas, boundary_error,linestyle=linestyles[epsilon_idx], color=\"C2\")\n",
    "\n",
    "\n",
    "    # ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "    ax.set_ylabel(r\"$E$\", labelpad=0.5)\n",
    "    ax.set_xlabel(r\"$\\beta$\", labelpad=0.1)\n",
    "    ax.grid(which=\"both\", axis=\"both\", alpha=0.5)\n",
    "\n",
    "    # put the ylabel to the right\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "\n",
    "\n",
    "    # Set the major ticks to face inwards\n",
    "    ax.tick_params(axis='both', which='major', direction='in')\n",
    "\n",
    "    # Set the minor ticks to face inwards\n",
    "    ax.tick_params(axis='both', which='minor', direction='in')\n",
    "    ax.legend(title=f\"$\\\\alpha\\\\gg1$\",loc=\"upper right\",framealpha=0)\n",
    "\n",
    "\n",
    "\n",
    "error_legend = []\n",
    "\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{adv}}$\",color=\"C0\"))\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{gen}}$\",color=\"C1\"))\n",
    "error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{bound}}$\",color=\"C2\"))\n",
    "# error_legend.append(Line2D([0],[0],label=r\"$E_{\\mathrm{CP}}$\",color=\"C3\"))\n",
    "\n",
    "epsilon_legend = []\n",
    "\n",
    "for idx, (beta, value) in enumerate(df_dict.items()):\n",
    "    epsilon_legend.append(Line2D([0],[0],color=\"black\", linestyle=linestyles[idx], label=r\"$\\beta={}$\".format(beta))) \n",
    "\n",
    "\n",
    "custom_legend = []\n",
    "\n",
    "# mix the two legends\n",
    "for idx in range(len(error_legend)):\n",
    "    \n",
    "    # custom_legend.append(epsilon_legend[idx+1])\n",
    "    custom_legend.append(error_legend[idx])\n",
    "\n",
    "# custom_legend.append(epsilon_legend[-1])\n",
    "\n",
    "# Place the legend at the bottom of the figure\n",
    "# fig.legend(handles=custom_legend, loc='upper center', ncol=3, handlelength=1)\n",
    "\n",
    "fig.align_labels()\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    save_plot(\n",
    "        fig,\n",
    "        f\"powerlaw_combined\",\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
